{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 0.5\n",
      "2 0.75\n",
      "3 0.375\n",
      "4 0.5625\n",
      "we did it\n",
      "0 1\n",
      "1 0.5\n",
      "2 0.25\n",
      "3 0.125\n",
      "4 0.0625\n",
      "5 0.03125\n",
      "6 0.015625\n",
      "7 0.0078125\n",
      "8 0.00390625\n",
      "9 0.001953125\n",
      "10 0.0009765625\n",
      "11 0.00048828125\n",
      "12 0.000244140625\n",
      "13 0.0001220703125\n",
      "14 6.103515625e-05\n",
      "15 3.0517578125e-05\n",
      "16 1.52587890625e-05\n",
      "we did it\n",
      "0 1\n",
      "1 0.5\n",
      "we did it\n",
      "0 1\n",
      "1 0.5\n",
      "2 0.25\n",
      "3 0.125\n",
      "4 0.0625\n",
      "5 0.03125\n",
      "6 0.015625\n",
      "7 0.0078125\n",
      "8 0.00390625\n",
      "9 0.001953125\n",
      "10 0.0009765625\n",
      "11 0.00048828125\n",
      "12 0.000244140625\n",
      "13 0.0001220703125\n",
      "14 6.103515625e-05\n",
      "15 3.0517578125e-05\n",
      "we did it\n",
      "0 1\n",
      "1 0.5\n",
      "we did it\n",
      "0 1\n",
      "1 0.5\n",
      "2 0.25\n",
      "3 0.125\n",
      "4 0.0625\n",
      "5 0.03125\n",
      "6 0.015625\n",
      "7 0.0078125\n",
      "8 0.00390625\n",
      "9 0.001953125\n",
      "10 0.0009765625\n",
      "11 0.00048828125\n",
      "12 0.000244140625\n",
      "13 0.0001220703125\n",
      "14 6.103515625e-05\n",
      "15 3.0517578125e-05\n",
      "16 1.52587890625e-05\n",
      "17 7.62939453125e-06\n",
      "we did it\n",
      "0 1\n",
      "1 0.5\n",
      "we did it\n",
      "0 1\n",
      "1 0.5\n",
      "2 0.25\n",
      "3 0.125\n",
      "4 0.0625\n",
      "5 0.03125\n",
      "6 0.015625\n",
      "7 0.0078125\n",
      "8 0.00390625\n",
      "9 0.001953125\n",
      "10 0.0009765625\n",
      "11 0.00048828125\n",
      "12 0.000244140625\n",
      "13 0.0001220703125\n",
      "14 6.103515625e-05\n",
      "15 3.0517578125e-05\n",
      "16 1.52587890625e-05\n",
      "we did it\n",
      "0 1\n",
      "1 0.5\n",
      "we did it\n",
      "0 1\n",
      "1 0.5\n",
      "2 0.25\n",
      "3 0.125\n",
      "4 0.0625\n",
      "5 0.03125\n",
      "6 0.015625\n",
      "7 0.0078125\n",
      "8 0.00390625\n",
      "9 0.001953125\n",
      "10 0.0009765625\n",
      "11 0.00048828125\n",
      "12 0.000244140625\n",
      "13 0.0001220703125\n",
      "14 6.103515625e-05\n",
      "we did it\n",
      "(18,)\n",
      "(15,)\n",
      "(17,)\n",
      "(16,)\n",
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "#Samson Koelle\n",
    "#Meila group\n",
    "#021419\n",
    "\n",
    "\n",
    "#rootdirectory = '/Users/samsonkoelle/Downloads/manigrad-100818/mani-samk-gradients'\n",
    "#f = open(rootdirectory + '/code/source/packagecontrol.py')\n",
    "#source = f.read()\n",
    "#exec(source)\n",
    "#f = open(rootdirectory + '/code/source/sourcecontrol.py')\n",
    "#source = f.read()\n",
    "#exec(source)\n",
    "#f = open(rootdirectory + '/code/source/RigidEthanol.py')\n",
    "#source = f.read()\n",
    "#exec(source)\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "import random\n",
    "import sys\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "now = datetime.datetime.now().strftime(\"%B_%d_%Y_%H_%M_%S\")\n",
    "workingdirectory = os.popen('git rev-parse --show-toplevel').read()[:-1]\n",
    "sys.path.append(workingdirectory)\n",
    "os.chdir(workingdirectory)\n",
    "#print(os.getcwd())\n",
    "from codes.experimentclasses.RigidEthanolPCA import RigidEthanolPCA\n",
    "from codes.otherfunctions.multirun import get_coeffs_reps_tangent\n",
    "from codes.otherfunctions.multirun import get_grads_reps_pca2_tangent\n",
    "from codes.otherfunctions.multiplot import plot_reg_path_ax_lambdasearch_tangent\n",
    "from codes.otherfunctions.get_dictionaries import get_atoms_4\n",
    "from codes.flasso.Replicate import Replicate\n",
    "from codes.otherfunctions.get_grads_tangent import get_grads_tangent\n",
    "from codes.otherfunctions.multirun import get_support_recovery_lambda\n",
    "from codes.otherfunctions.multirun import get_lower_interesting_lambda\n",
    "import matplotlib.pyplot as plt\n",
    "from codes.otherfunctions.multirun import get_coeffs_and_lambdas\n",
    "from codes.geometer.RiemannianManifold import RiemannianManifold\n",
    "from collections import Counter\n",
    "\n",
    "#set parameters\n",
    "n = 10000 #number of data points to simulate\n",
    "nsel = 50 #number of points to analyze with lasso\n",
    "itermax = 1000 #maximum iterations per lasso run\n",
    "tol = 1e-10 #convergence criteria for lasso\n",
    "#lambdas = np.asarray([0,.01,.1,1,10,100], dtype = np.float16)#lambda values for lasso\n",
    "#lambdas = np.asarray(np.hstack([np.asarray([0]),np.logspace(-3,1,11)]), dtype = np.float16)\n",
    "#lambdas = np.asarray(np.hstack([np.asarray([0]),np.logspace(-3,0,7), np.logspace(0,2,5),np.logspace(2,3,2)]), dtype = np.float16)\n",
    "lambdas = np.asarray(np.hstack([np.asarray([0]),np.logspace(-2,1,15)]), dtype = np.float16)\n",
    "n_neighbors = 1000 #number of neighbors in megaman\n",
    "n_components = 3 #number of embedding dimensions (diffusion maps)\n",
    "#diffusion_time = 1. #diffusion time controls gaussian kernel radius per gradients paper\n",
    "#diffusion_time =.05 #(yuchia suggestion)\n",
    "diffusion_time =.25 #(yuchia suggestion)\n",
    "dim = 2 #manifold dimension\n",
    "dimnoise = 2\n",
    "cores = 3 #number of cores for parallel processing\n",
    "cor = 0.0 #correlation for noise\n",
    "var = 0.00001 #variance scaler for noise\n",
    "ii = np.asarray([0,0,0,0,1,1,1,2]) # atom adjacencies for dihedral angle computation\n",
    "jj = np.asarray([1,2,3,4,5,6,7,8])\n",
    "\n",
    "#run experiment\n",
    "atoms4 = np.asarray([[6,1,0,4],[4,0,2,8],[7,6,5,1],[3,0,2,4]],dtype = int)\n",
    "\n",
    "m = 3\n",
    "new_MN = True\n",
    "new_grad = True\n",
    "savename = 'rigidethanol_032520'\n",
    "savefolder = 'rigidethanol'\n",
    "loadfolder = 'rigidethanol'\n",
    "loadname = 'rigidethanol_032520'\n",
    "nreps = 5\n",
    "atoms4,p = get_atoms_4(9,ii,jj)\n",
    "folder = workingdirectory + '/Figures/rigidethanol/' + now + 'n' + str(n) + 'nsel' + str(nsel) + 'nreps' + str(nreps)\n",
    "os.mkdir(folder)\n",
    "\n",
    "if new_MN == True:\n",
    "    experiment = RigidEthanolPCA(dim, cor,var,ii,jj, cores, False, atoms4)\n",
    "    #projector  = np.load(workingdirectory + '/untracked_data/chemistry_data/ethanolangles022119_pca50_components.npy')\n",
    "    #experiment.M = experiment.load_data()  # if noise == False then noise parameters are overriden\n",
    "\t#experiment.Mpca = RiemannianManifold(np.load(workingdirectory + '/untracked_data/chemistry_data/ethanolangles022119_pca50.npy'), dim)\n",
    "    experiment.M, experiment.Mpca, projector = experiment.generate_data(noise=False)\n",
    "    experiment.q = m\n",
    "    experiment.m = m\n",
    "    experiment.dimnoise = dimnoise\n",
    "    experiment.projector = projector\n",
    "    experiment.Mpca.geom = experiment.Mpca.compute_geom(diffusion_time, n_neighbors)\n",
    "    experiment.N = experiment.Mpca.get_embedding3(experiment.Mpca.geom, m, diffusion_time, dim)\n",
    "    with open(workingdirectory + '/untracked_data/embeddings/' + savefolder + '/' + savename + '.pkl' ,\n",
    "             'wb') as output:\n",
    "         pickle.dump(experiment, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "lambda_max = 1\n",
    "max_search = 30\n",
    "\n",
    "experiment.p = p# + experiment.d\n",
    "experiment.atoms4 = atoms4\n",
    "experiment.itermax = itermax\n",
    "experiment.tol = tol\n",
    "experiment.dnoise = dim\n",
    "experiment.nreps = nreps\n",
    "experiment.nsel = nsel\n",
    "experiment.folder = folder\n",
    "experiment.m = dim\n",
    "replicates = {}\n",
    "selected_points_save = np.zeros((nreps,nsel))\n",
    "for i in range(nreps):\n",
    "    selected_points = np.random.choice(list(range(n)),nsel,replace = False)\n",
    "    selected_points_save[i] = selected_points\n",
    "    replicates[i] = Replicate()\n",
    "    replicates[i].nsel = nsel\n",
    "    replicates[i].selected_points = selected_points\n",
    "    replicates[i].df_M,replicates[i].dg_M,replicates[i].dg_w ,replicates[i].dg_w_pca ,replicates[i].dgw_norm  = get_grads_tangent(experiment, experiment.Mpca, experiment.M, selected_points, False)\n",
    "    replicates[i].xtrain, replicates[i].groups = experiment.construct_X(replicates[i].dg_M)\n",
    "    replicates[i].ytrain = experiment.construct_Y(replicates[i].df_M)#,list(range(nsel)))\n",
    "    replicates[i].coeff_dict = {}\n",
    "    replicates[i].coeff_dict[0] = experiment.get_betas_spam2(replicates[i].xtrain, replicates[i].ytrain, replicates[i].groups, np.asarray([0]), nsel, experiment.dim, itermax, tol)\n",
    "    replicates[i].combined_norms = {}\n",
    "    replicates[i].combined_norms[0] = np.linalg.norm(np.linalg.norm(replicates[i].coeff_dict[0][:, :, :, :], axis=2), axis=1)[0,:]\n",
    "    replicates[i].higher_lambda,replicates[i].coeff_dict,replicates[i].combined_norms = get_support_recovery_lambda(experiment, replicates[i],  lambda_max, max_search,dim)\n",
    "    replicates[i].lower_lambda,replicates[i].coeff_dict,replicates[i].combined_norms = get_lower_interesting_lambda(experiment, replicates[i],  lambda_max, max_search)\n",
    "    #= experiment.get_betas_spam2(replicates[i].xtrain, replicates[i].ytrain, replicates[i].groups, lambdas, len(selected_points), n_embedding_coordinates, itermax, tol)\n",
    "\n",
    "for i in range(nreps):\n",
    "    replicates[i].coeffs, replicates[i].lambdas_plot = get_coeffs_and_lambdas(replicates[i].coeff_dict, replicates[i].lower_lambda, replicates[i].higher_lambda)\n",
    "\n",
    "#nreps = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_support(coeffs, dim):\n",
    "    selected_functions = np.asarray(np.where(np.sum(np.sum(coeffs ** 2, axis=1), axis=1) > 0))\n",
    "\n",
    "    sls = np.where(np.asarray(list(Counter(selected_functions[0]).values())) == dim)[0]\n",
    "    if len(sls) > 0:\n",
    "        selection_lambda = np.min(sls)\n",
    "        selected_functions_at_selection_lambda = selected_functions[1][\n",
    "            np.where(selected_functions[0] == selection_lambda)[0]]\n",
    "\n",
    "        return (selected_functions_at_selection_lambda)\n",
    "    else:\n",
    "        return(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supports = {}\n",
    "for i in range(nreps):\n",
    "    #print(i)\n",
    "    supports[i] = get_support(replicates[i].coeffs, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 6]),\n",
       " 1: array([3, 9]),\n",
       " 2: array([3, 9]),\n",
       " 3: array([0, 9]),\n",
       " 4: array([3, 9])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    coeffs = replicates[0].coeffs\n",
    "    selected_functions = np.asarray(np.where(np.sum(np.sum(coeffs ** 2, axis=1), axis=1) > 0))\n",
    "\n",
    "    sls = np.where(np.asarray(list(Counter(selected_functions[0]).values())) == dim)[0]\n",
    "    if len(sls) > 0:\n",
    "        selection_lambda = np.min(sls)\n",
    "        selected_functions_at_selection_lambda = selected_functions[1][\n",
    "            np.where(selected_functions[0] == selection_lambda)[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = replicates[0]\n",
    "sls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "selpt = np.array([ 0,  1,  3,  5,  7,  9, 11, 13, 15, 16, 18, 20, 22, 24, 26, 28, 30,\n",
    "       31, 33, 35, 37, 39, 41, 43, 45])\n",
    "selpt = selpt[:10]\n",
    "#selpt = selpt[[0,2,4,6,8]]\n",
    "#selpt = selpt[[1,3,5,7,9]]\n",
    "xtrain,groups = experiment.construct_X(replicates[0].dg_M[selpt])\n",
    "ytrain = construct_Y(experiment,np.repeat([np.identity(2)], axis = 0, repeats = len(selpt)))\n",
    "cs = experiment.get_betas_spam2(xtrain, ytrain, groups, np.asarray([.45*r.lambdas_plot[17]]), len(selpt), 2, itermax, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        ,   0.        ,   8.88433016,\n",
       "         0.        ,   0.        , 260.66335141,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "selpt = np.array([ 0,  1,  3,  5,  7,  9, 11, 13, 15, 16, 18, 20, 22, 24, 26, 28, 30,\n",
    "       31, 33, 35, 37, 39, 41, 43, 45])\n",
    "selpt = selpt[:10]\n",
    "xtrain,groups = experiment.construct_X(replicates[0].dg_M[selpt][:,[3,6,9],:])\n",
    "ytrain = construct_Y(experiment,np.repeat([np.identity(2)], axis = 0, repeats = len(selpt)))\n",
    "cs = experiment.get_betas_spam2(xtrain, ytrain, groups, np.asarray([.45*r.lambdas_plot[17]]), len(selpt), 2, itermax, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.89097954, 260.57872876,   0.        ])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/samsonkoelle/Desktop/abadxtrain',xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n",
      "converged 0.253125\n"
     ]
    }
   ],
   "source": [
    "cs = experiment.get_betas_sam(xtrain, ytrain, groups, np.asarray([.45*r.lambdas_plot[sls[0]]]), 10, 2, itermax, .1*tol, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.08346247, 246.59361781,   0.        ])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    from codes.flasso.GLMaccelerated import GLM\n",
    "    def fhatlambda(self,lamb,betanew,betaold):\n",
    "        xs = self.xs\n",
    "        ys = self.ys\n",
    "        #print(ys.shape,'fhatlam')\n",
    "        #print(self._L2loss(betaold,xs,ys),self._L2loss(betanew,xs,ys),'old','new') \n",
    "        output = self._L2loss(betaold,xs,ys) + np.dot(self._grad_L2loss(betaold,xs,ys).transpose(),(betanew-betaold)) + (1/(2*lamb)) * np.linalg.norm(betanew-betaold)**2\n",
    "        return(output)    \n",
    "\n",
    "    def _prox(self,beta, thresh):\n",
    "        \"\"\"Proximal operator.\"\"\"\n",
    "        \n",
    "        #print(thresh, beta)\n",
    "        #print('beginprox', beta[0:2],thresh)\n",
    "        group_ids = np.unique(self.group)\n",
    "        result = np.zeros(beta.shape)\n",
    "        result = np.asarray(result, dtype = float)\n",
    "        #print('gids',group_ids)\n",
    "        for i in range(len(group_ids)):\n",
    "            gid = i \n",
    "            #print(self.group)\n",
    "            idxs_to_update = np.where(self.group == gid)[0]\n",
    "            #print('idx',idxs_to_update)\n",
    "            #print('norm', np.linalg.norm(beta[idxs_to_update]))\n",
    "            if np.linalg.norm(beta[idxs_to_update]) > 0.:\n",
    "                #print('in here', len(idxs_to_update))\n",
    "                potentialoutput = beta[idxs_to_update] - (thresh / np.linalg.norm(beta[idxs_to_update])) * beta[idxs_to_update]\n",
    "                posind = np.where(beta[idxs_to_update] > 0.)[0]\n",
    "                negind = np.where(beta[idxs_to_update] < 0.)[0]\n",
    "                po = beta[idxs_to_update].copy()\n",
    "                #print('potention', potentialoutput[0:2])\n",
    "                po[posind] = np.asarray(np.clip(potentialoutput[posind],a_min = 0., a_max = 1e15), dtype = float)\n",
    "                po[negind] = np.asarray(np.clip(potentialoutput[negind],a_min = -1e15, a_max = 0.), dtype = float)\n",
    "                result[idxs_to_update] = po\n",
    "        #print('end', result[0:2])\n",
    "        return result\n",
    "\n",
    "    #_btalgorithm(yk,lamb,.5,1000, rl)\n",
    "    def _btalgorithm(self,bet,lam,b,maxx,rl):\n",
    "        \n",
    "        #print('lam',lam)\n",
    "        X = self.xs\n",
    "        y = self.ys\n",
    "        grad_beta = self._grad_L2loss(beta = bet, X = X, y = y)\n",
    "        for i in range(maxx):\n",
    "            betn = bet - lam * grad_beta\n",
    "            z = self._prox(betn, lam * rl)\n",
    "            fz = self._L2loss(z,X,y)\n",
    "            #print(fz,'fz')\n",
    "            fhatz = self.fhatlambda(lam,z, bet)\n",
    "            if fz <= fhatz:\n",
    "            #print(fhatz - fz)\n",
    "            #if 0 <= 1:\n",
    "                break\n",
    "            lam = b*lam\n",
    "        return(z,lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n",
      "converged 0.253125\n"
     ]
    }
   ],
   "source": [
    "        max_iter = itermax\n",
    "        learning_rate = 1.\n",
    "        n = 50\n",
    "        q = 2\n",
    "        lambdas = np.asarray([.45*r.lambdas_plot[sls[0]]])\n",
    "        #def get_betas_sam(self, xtrain, ytrain, groups, lambdas, n, q, max_iter, tol, learning_rate):\n",
    "\n",
    "        p = len(np.unique(groups))\n",
    "        models = GLM(xs=xtrain, ys=ytrain,\n",
    "                     tol=tol,\n",
    "                     group=groups,\n",
    "                     learning_rate=learning_rate,\n",
    "                     max_iter=max_iter,\n",
    "                     # reg_lambda=np.logspace(np.log(100), np.log(0.01), 5, base=np.exp(1)))\n",
    "                     reg_lambda=lambdas,\n",
    "                     parameter=.5)\n",
    "        models.fit()\n",
    "        nlam = len(lambdas)\n",
    "        #organizedbetas = np.zeros((nlam, q, n, p))\n",
    "        #for l in range(nlam):\n",
    "        #    organizedbetas[l, :, :, :] = np.reshape(models.fit_[l]['beta'], (q, n, p))\n",
    "        # return(models, organizedbetas)\n",
    "        #return (organizedbetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #def _grad_L2loss(beta, X, y):\n",
    "        X = xtrain\n",
    "        y = ytrain\n",
    "        beta = models.fit_[0]['beta']\n",
    "        #print(beta.shape,X.shape,y.shape)\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, np.newaxis]\n",
    "        n_samples = np.float(X.shape[0])\n",
    "        z = np.dot(X, beta)\n",
    "        #grad_beta = 1. / n_samples * np.transpose(np.dot(np.transpose(z - y), X))\n",
    "        grad_beta = np.transpose(np.dot(np.transpose(z - y), X))\n",
    "        #print('gb',grad_beta.shape)\n",
    "        #return grad_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07787797, -0.08164005, -0.00492303,  0.0026874 , -0.00180239,\n",
       "       -0.074917  ])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.transpose(z - y)[0,[0,1,30,31]],  X[[0,1,20,21]][:,[0,1,2,30,31,32]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.61441095],\n",
       "       [ 1.53289937],\n",
       "       [ 0.        ],\n",
       "       [-0.03431378],\n",
       "       [ 0.06243387],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[[0,1,2,30,31,32],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22268263,  0.01000106,  0.22977193, -0.0274415 ,  0.00081364])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.43478758, 267.03090621,   0.        ])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(np.reshape(beta, (q, 10, p)), axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the distance to the target vector is  would be improved \n",
    "Gain in l2 loss is sublinear when distance is less than $\\frac{\\lambda}{2}$ to target, so we won't get closer than this. \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "l = \\arg \\min  \\| Y - X \\beta \\|_2^2 + \\sum_{j = 1}^p \\|beta_j\\|_2 \\\\\n",
    "\\nabla l (\\beta = [4.2,...]) \\\\\n",
    "= \\arg \\min \\sum \\| I - X \\beta \\|_2^2 + \\sum_{j = 1}^p \\|  [ \\beta_1, \\dotsc \\beta_{dd} ,...] \\|_2\n",
    "\\end{eqnarray*}\n",
    "\n",
    "If we add weight to the already nonzero group, then we have loss increased by \n",
    "\\begin{eqnarray*}\n",
    "\\end{eqnarray*}\n",
    "since l2 norm is less than l1 norm, new coefficients will be added in the same group. We will increase coefficients in the same group versus add a new group when the gradient is greater in the group. For every point, the l2 gradient is the correlation of the features with the loss $X^T (I_d - X \\beta) \\in \\mathbb R^{d \\times p}$, which, when $\\beta$ is small due to high $\\lambda$, will scale with $X^T$.\n",
    "\n",
    "Why is a new coefficient added when we can decrease loss substantially with the first coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,groups = experiment.construct_X(replicates[0].dg_M[selpt][:,[3,6,9],:])\n",
    "ytrain = construct_Y(experiment,np.repeat([np.identity(2)], axis = 0, repeats = len(selpt)))\n",
    "cs = experiment.get_betas_spam2(xtrain, ytrain, groups, np.asarray([.45*r.lambdas_plot[17]]), len(selpt), 2, itermax, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = np.asarray([[[1,0],[1,0.1],[0,.5]]])#.5]]])\n",
    "xtrain,groups = experiment.construct_X(Xtest)\n",
    "ytrain = construct_Y(experiment,np.repeat([np.identity(2)], axis = 0, repeats = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = experiment.get_betas_spam2(xtrain, ytrain, groups, np.asarray([r.lambdas_plot[17]]), 1, 2, 100*itermax, .001*tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.11955952,  0.31884468,  0.        ]],\n",
       "\n",
       "        [[-0.00678796,  0.03867242,  0.        ]]]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "converged 0.5625\n"
     ]
    }
   ],
   "source": [
    "    #def get_betas_sam(self, xtrain, ytrain, groups, lambdas, n, q, max_iter, tol, learning_rate):\n",
    "    lambdas = np.asarray([r.lambdas_plot[17]])\n",
    "    n= 1\n",
    "    q =2\n",
    "    max_iter = itermax\n",
    "    learning_rate = 1.\n",
    "    p = len(np.unique(groups))\n",
    "    models = GLM(xs=xtrain, ys=ytrain,\n",
    "                 tol=tol,\n",
    "                 group=groups,\n",
    "                 learning_rate=learning_rate,\n",
    "                 max_iter=max_iter,\n",
    "                 # reg_lambda=np.logspace(np.log(100), np.log(0.01), 5, base=np.exp(1)))\n",
    "                 reg_lambda=lambdas,\n",
    "                 parameter=.5)\n",
    "    models.fit()\n",
    "    nlam = len(lambdas)\n",
    "    organizedbetas = np.zeros((nlam, q, n, p))\n",
    "    for l in range(nlam):\n",
    "        organizedbetas[l, :, :, :] = np.reshape(models.fit_[l]['beta'], (q, n, p))\n",
    "    # return(models, organizedbetas)\n",
    "    #return (organizedbetas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11975375],\n",
       "       [ 0.31865201],\n",
       "       [ 0.        ],\n",
       "       [-0.00679489],\n",
       "       [ 0.0386602 ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.fit_[l]['beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 1. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.1, 0.5, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 1. , 1. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.1, 0.5]])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43840576],\n",
       "       [0.0318652 ],\n",
       "       [0.03186531],\n",
       "       [0.00386602]])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(xtrain, models.fit_[l]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "err= np.asarray([[1,0,0,1]]).transpose() - np.dot(xtrain, models.fit_[l]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.56159424]\n",
      " [-0.0318652 ]\n",
      " [-0.03186531]\n",
      " [ 0.99613398]] 1.0411998254222614\n"
     ]
    }
   ],
   "source": [
    "print(err, np.linalg.norm(err**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups\n",
    "#group = self.group\n",
    "group_ids = np.unique(groups)\n",
    "L1penalty = 0.0\n",
    "for group_id in group_ids:\n",
    "    L1penalty += np.linalg.norm(models.fit_[l]['beta'][groups == group_id], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4409350188813433"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56159424],\n",
       "       [ 0.55840772],\n",
       "       [-0.0159326 ],\n",
       "       [-0.03186531],\n",
       "       [ 0.06774809],\n",
       "       [ 0.49806699]])"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(xtrain.transpose(), err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11975375],\n",
       "       [ 0.31865201],\n",
       "       [ 0.        ],\n",
       "       [-0.00679489],\n",
       "       [ 0.0386602 ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.fit_[l]['beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bettt = models.fit_[l]['beta'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "bettt[0,0] = bettt[0,0] + bettt[1,0]\n",
    "bettt[3,0] = bettt[3,0] + bettt[4,0]\n",
    "bettt[1,0] = 0.\n",
    "bettt[4,0] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "err= np.asarray([[1,0,0,1]]).transpose() - np.dot(xtrain, bettt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.56159424]\n",
      " [ 0.        ]\n",
      " [-0.03186531]\n",
      " [ 1.        ]] 1.0485564738990558\n"
     ]
    }
   ],
   "source": [
    "print(err, np.linalg.norm(err**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#groups\n",
    "#group = self.group\n",
    "group_ids = np.unique(groups)\n",
    "L1penalty = 0.0\n",
    "for group_id in group_ids:\n",
    "    L1penalty += np.linalg.norm(bettt[groups == group_id], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43956229119586826"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10689735, 0.09744196, 0.09748166, 0.10039989, 0.09195794,\n",
       "       0.09195385, 0.10517544, 0.09638328, 0.09649321, 0.09160783,\n",
       "       0.0918076 , 0.09084874])"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dg_M, axis = 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11165893, 0.10160898, 0.10156451, 0.07206007, 0.06551289,\n",
       "       0.06544481, 0.10983474, 0.10015332, 0.10019698, 0.05076601,\n",
       "       0.05060818, 0.05074339])"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dg_M, axis = 2)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14131968, 0.14022741, 0.13973233, 0.13370804, 0.135019  ,\n",
       "       0.1351492 , 0.14222888, 0.14236823, 0.14219136, 0.05114664,\n",
       "       0.05214419, 0.05164038])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dgw_norm, axis = 2)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00020433, 0.01033738, 0.        ])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 1. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.1, 0.5, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 1. , 1. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.1, 0.5]])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067811865476"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm([0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambdas\n",
    "bet = beta\n",
    "rl = .45*r.lambdas_plot[sls[0]]\n",
    "lam  = learning_rate\n",
    "b = .5\n",
    "maxx = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        models = GLM(xs=xtrain, ys=ytrain,\n",
    "                     tol=tol,\n",
    "                     group=groups,\n",
    "                     learning_rate=learning_rate,\n",
    "                     max_iter=max_iter,\n",
    "                     # reg_lambda=np.logspace(np.log(100), np.log(0.01), 5, base=np.exp(1)))\n",
    "                     reg_lambda=lambdas,\n",
    "                     parameter=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "betanw , lamnew = models._btalgorithm(bet,lam,b,maxx,rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.50664508  0.          0.          0.          0.          0.\n",
      "  0.72580604  0.          0.          0.          0.          0.        ]\n",
      "[-1.50664508  0.          0.          0.          0.          0.\n",
      "  0.72580604  0.          0.          0.          0.          0.        ]\n",
      "9126.702529783111\n",
      "9126.702529783111\n"
     ]
    }
   ],
   "source": [
    "print(bet[:12,0])\n",
    "print(betanw[:12,0])\n",
    "print(models._loss(betanw, rl, X, y))\n",
    "print(models._loss(beta, rl, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ye\n"
     ]
    }
   ],
   "source": [
    "        X = xtrain\n",
    "        y = ytrain\n",
    "        self = models\n",
    "        grad_beta = self._grad_L2loss(beta = bet, X = X, y = y)\n",
    "        for i in range(maxx):\n",
    "            #i = 0\n",
    "            betn = bet - lam * grad_beta\n",
    "            z = self._prox(betn, lam * rl)\n",
    "            fz = self._L2loss(z,X,y)\n",
    "            #print(fz,'fz')\n",
    "            fhatz = self.fhatlambda(lam,z, bet)\n",
    "            if fz <= fhatz:\n",
    "            #print(fhatz - fz)\n",
    "            #if 0 <= 1:\n",
    "                print('ye')\n",
    "                break\n",
    "            lam = b*lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.333539204206318e-08\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(models._loss(betanw, rl, X, y)-(models._loss(betn, rl, X, y)))\n",
    "print(models._loss(betanw, rl, X, y)-(models._loss(z, rl, X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08119172]\n",
      " [-0.07437537]\n",
      " [ 0.07440127]\n",
      " [ 0.07642865]\n",
      " [ 0.07018519]\n",
      " [-0.07018645]\n",
      " [-0.08012824]\n",
      " [ 0.07355039]\n",
      " [ 0.07364105]\n",
      " [-0.00427723]\n",
      " [-0.00435048]\n",
      " [ 0.00432978]]\n",
      "[[ 0.00674645]\n",
      " [ 0.00231735]\n",
      " [-0.00193286]\n",
      " [ 0.00375295]\n",
      " [-0.00494534]\n",
      " [ 0.00456414]\n",
      " [-0.00270096]\n",
      " [-0.00594962]\n",
      " [-0.00557325]\n",
      " [-0.09107378]\n",
      " [-0.09126416]\n",
      " [ 0.09030777]]\n"
     ]
    }
   ],
   "source": [
    "print(grad_beta[:12])\n",
    "print(grad_beta[600:612])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.50664508e+00],\n",
       "       [ 1.73168655e-11],\n",
       "       [-1.73228963e-11],\n",
       "       ...,\n",
       "       [-6.81472178e-13],\n",
       "       [ 6.82072290e-13],\n",
       "       [-6.83296003e-13]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5934.63465043,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  337.54009811,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(np.reshape(beta, (q, n, p)), axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = np.reshape(betn, (q, n, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.32104819e+03, 3.50632423e-02, 3.50720848e-02, 4.61117159e-02,\n",
       "       3.27236197e-02, 3.26805756e-02, 5.13146710e+02, 3.54904149e-02,\n",
       "       3.56162614e-02, 6.18929274e-02, 6.12525866e-02, 6.08514436e-02])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(ll, axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5934.35229507,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  337.54304466,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll2 = np.reshape(z, (q, n, p))\n",
    "np.linalg.norm(np.linalg.norm(ll2, axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08119172]\n",
      " [-0.07437537]\n",
      " [ 0.07440127]\n",
      " [ 0.07642865]\n",
      " [ 0.07018519]\n",
      " [-0.07018645]\n",
      " [-0.08012824]\n",
      " [ 0.07355039]\n",
      " [ 0.07364105]\n",
      " [-0.00427723]\n",
      " [-0.00435048]\n",
      " [ 0.00432978]]\n",
      "[[ 0.00674645]\n",
      " [ 0.00231735]\n",
      " [-0.00193286]\n",
      " [ 0.00375295]\n",
      " [-0.00494534]\n",
      " [ 0.00456414]\n",
      " [-0.00270096]\n",
      " [-0.00594962]\n",
      " [-0.00557325]\n",
      " [-0.09107378]\n",
      " [-0.09126416]\n",
      " [ 0.09030777]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00674645],\n",
       "       [ 0.00231735],\n",
       "       [-0.00193286],\n",
       "       [ 0.00375295],\n",
       "       [-0.00494534],\n",
       "       [ 0.00456414],\n",
       "       [-0.00270096],\n",
       "       [-0.00594962],\n",
       "       [-0.00557325],\n",
       "       [-0.09107378],\n",
       "       [-0.09126416],\n",
       "       [ 0.09030777]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta = betn\n",
    "thresh = lam * rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        #print(thresh, beta)\n",
    "        #print('beginprox', beta[0:2],thresh)\n",
    "        group_ids = np.unique(self.group)\n",
    "        result = np.zeros(beta.shape)\n",
    "        result = np.asarray(result, dtype = float)\n",
    "        #print('gids',group_ids)\n",
    "        for i in range(len(group_ids)):\n",
    "            gid = i \n",
    "            #print(self.group)\n",
    "            idxs_to_update = np.where(self.group == gid)[0]\n",
    "            #print('idx',idxs_to_update)\n",
    "            #print('norm', np.linalg.norm(beta[idxs_to_update]))\n",
    "            if np.linalg.norm(beta[idxs_to_update]) > 0.:\n",
    "                #print('in here', len(idxs_to_update))\n",
    "                potentialoutput = beta[idxs_to_update] - (thresh / np.linalg.norm(beta[idxs_to_update])) * beta[idxs_to_update]\n",
    "                posind = np.where(beta[idxs_to_update] > 0.)[0]\n",
    "                negind = np.where(beta[idxs_to_update] < 0.)[0]\n",
    "                po = beta[idxs_to_update].copy()\n",
    "                #print('potention', potentialoutput[0:2])\n",
    "                po[posind] = np.asarray(np.clip(potentialoutput[posind],a_min = 0., a_max = 1e15), dtype = float)\n",
    "                po[negind] = np.asarray(np.clip(potentialoutput[negind],a_min = -1e15, a_max = 0.), dtype = float)\n",
    "                result[idxs_to_update] = po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            i = 9\n",
    "            gid = i \n",
    "            #print(self.group)\n",
    "            idxs_to_update = np.where(self.group == gid)[0]\n",
    "            #print('idx',idxs_to_update)\n",
    "            #print('norm', np.linalg.norm(beta[idxs_to_update]))\n",
    "            if np.linalg.norm(beta[idxs_to_update]) > 0.:\n",
    "                #print('in here', len(idxs_to_update))\n",
    "                potentialoutput = beta[idxs_to_update] - (thresh / np.linalg.norm(beta[idxs_to_update])) * beta[idxs_to_update]\n",
    "                posind = np.where(beta[idxs_to_update] > 0.)[0]\n",
    "                negind = np.where(beta[idxs_to_update] < 0.)[0]\n",
    "                po = beta[idxs_to_update].copy()\n",
    "                #print('potention', potentialoutput[0:2])\n",
    "                po[posind] = np.asarray(np.clip(potentialoutput[posind],a_min = 0., a_max = 1e15), dtype = float)\n",
    "                po[negind] = np.asarray(np.clip(potentialoutput[negind],a_min = -1e15, a_max = 0.), dtype = float)\n",
    "                result[idxs_to_update] = po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbb = (thresh / np.linalg.norm(beta[idxs_to_update])) * beta[idxs_to_update]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.linalg.norm(np.linalg.norm(ll2, axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9126.702464945178"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bbb\n",
    "models._loss(betn, rl, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.50663754,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.72580582,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:12,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9126.702465008511"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bbb\n",
    "models._loss(z, rl, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.54723340e+00],\n",
       "       [ 3.37150347e-02],\n",
       "       [-3.37294878e-02],\n",
       "       ...,\n",
       "       [-1.45116953e-03],\n",
       "       [ 1.44880952e-03],\n",
       "       [-1.44938987e-03]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1065627 ,  0.09743893, -0.09748091, -0.10025701, -0.09189179,\n",
       "         0.0919014 ,  0.10508428, -0.09628175, -0.09640844,  0.00750803,\n",
       "         0.00760803, -0.00756092],\n",
       "       [-0.00845189, -0.00076783,  0.00038222, -0.00535444,  0.00348726,\n",
       "        -0.00310545,  0.00437813,  0.00442277,  0.00404394,  0.09129963,\n",
       "         0.09149182, -0.09053357],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[0].xtrain[:5,:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1065627 , -0.00845189],\n",
       "       [ 0.09743893, -0.00076783],\n",
       "       [-0.09748091,  0.00038222],\n",
       "       [-0.10025701, -0.00535444],\n",
       "       [-0.09189179,  0.00348726],\n",
       "       [ 0.0919014 , -0.00310545],\n",
       "       [ 0.10508428,  0.00437813],\n",
       "       [-0.09628175,  0.00442277],\n",
       "       [-0.09640844,  0.00404394],\n",
       "       [ 0.00750803,  0.09129963],\n",
       "       [ 0.00760803,  0.09149182],\n",
       "       [-0.00756092, -0.09053357]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[0].dg_M[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selpt = [0,1,4,5,6,36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,groups = experiment.construct_X(replicates[0].dg_M[selpt])\n",
    "ytrain =  construct_Y(experiment,np.repeat([np.identity(2)], axis = 0, repeats = len(selpt)))\n",
    "cs = experiment.get_betas_spam2(xtrain, ytrain, groups, np.asarray([.33*r.lambdas_plot[13]]), len(selpt), 2, itermax, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        ,    0.        , 2372.53693096,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  277.45489815,    0.        ])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n",
      "converged 0.115\n"
     ]
    }
   ],
   "source": [
    "        max_iter = itermax\n",
    "        learning_rate = 1.\n",
    "        n = 50\n",
    "        q = 2\n",
    "        lambdas = np.asarray([.23 * r.lambdas_plot[sls[0]]])\n",
    "        #def get_betas_sam(self, xtrain, ytrain, groups, lambdas, n, q, max_iter, tol, learning_rate):\n",
    "\n",
    "        p = len(np.unique(groups))\n",
    "        models = GLM(xs=xtrain, ys=ytrain,\n",
    "                     tol=tol,\n",
    "                     group=groups,\n",
    "                     learning_rate=learning_rate,\n",
    "                     max_iter=max_iter,\n",
    "                     # reg_lambda=np.logspace(np.log(100), np.log(0.01), 5, base=np.exp(1)))\n",
    "                     reg_lambda=lambdas,\n",
    "                     parameter=.5)\n",
    "        models.fit()\n",
    "        nlam = len(lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 83  11  89  17  82  10  81   9  88  16 142  70 143  71 141  69  84  12\n",
      "  19  91  20  92  90  18  13  85  14  86  34 106  35 107  33 105 117  45\n",
      " 119  47 118  46  59 131  57 129  58 130  87  15 139  67 140  68 138  66\n",
      " 112  40 113  41 111  39   5  77   4  76 136  64 137  65 133  61 134  62\n",
      " 125  53 124  52 127  55 128  56   7  79   8  80  97  25  98  26   2  74\n",
      "   1  73 122  50 121  49 109  37 110  38 115  43 116  44   3  75 135  63\n",
      " 123  51 132  60 126  54   6  78 120  48   0  72  96  24 114  42 108  36\n",
      " 101  29 100  28 103  31 104  32  99  27 102  30  95  23  93  21  94  22]\n",
      "[11 11  5  5 10 10  9  9  4  4 10 10 11 11  9  9  0  0  7  7  8  8  6  6\n",
      "  1  1  2  2 10 10 11 11  9  9  9  9 11 11 10 10 11 11  9  9 10 10  3  3\n",
      "  7  7  8  8  6  6  4  4  5  5  3  3  5  5  4  4  4  4  5  5  1  1  2  2\n",
      "  5  5  4  4  7  7  8  8  7  7  8  8  1  1  2  2  2  2  1  1  2  2  1  1\n",
      "  1  1  2  2  7  7  8  8  3  3  3  3  3  3  0  0  6  6  6  6  0  0  0  0\n",
      "  0  0  6  6  0  0  5  5  4  4  7  7  8  8  3  3  6  6 11 11  9  9 10 10]\n",
      "[0.00195111 0.00195111 0.00196153 0.00196153 0.00198314 0.00198314\n",
      " 0.002008   0.002008   0.00213023 0.00213023 0.00265408 0.00265408\n",
      " 0.0026737  0.0026737  0.00286675 0.00286675 0.00313455 0.00313455\n",
      " 0.00331081 0.00331081 0.00348289 0.00348289 0.00468138 0.00468138\n",
      " 0.00479665 0.00479665 0.00496707 0.00496707 0.00537547 0.00537547\n",
      " 0.00539455 0.00539455 0.00551369 0.00551369 0.00752056 0.00752056\n",
      " 0.00760914 0.00760914 0.00763905 0.00763905 0.01027592 0.01027592\n",
      " 0.01033867 0.01033867 0.01035616 0.01035616 0.01056978 0.01056978\n",
      " 0.01738903 0.01738903 0.01743463 0.01743463 0.01873472 0.01873472\n",
      " 0.02626056 0.02626056 0.0262632  0.0262632  0.0285197  0.0285197\n",
      " 0.03190937 0.03190937 0.0319253  0.0319253  0.03269667 0.03269667\n",
      " 0.03271612 0.03271612 0.03272996 0.03272996 0.03276105 0.03276105\n",
      " 0.03324395 0.03324395 0.03327593 0.03327593 0.03341041 0.03341041\n",
      " 0.03341928 0.03341928 0.03348923 0.03348923 0.03351391 0.03351391\n",
      " 0.03366084 0.03366084 0.03367291 0.03367291 0.03369988 0.03369988\n",
      " 0.03370481 0.03370481 0.03381782 0.03381782 0.03383859 0.03383859\n",
      " 0.03385213 0.03385213 0.03386427 0.03386427 0.03388043 0.03388043\n",
      " 0.03392242 0.03392242 0.03436989 0.03436989 0.03540339 0.03540339\n",
      " 0.03543319 0.03543319 0.03552394 0.03552394 0.03559104 0.03559104\n",
      " 0.03608697 0.03608697 0.03612438 0.03612438 0.03639243 0.03639243\n",
      " 0.03667591 0.03667591 0.03683567 0.03683567 0.03687889 0.03687889\n",
      " 0.04116078 0.04116078 0.04116272 0.04116272 0.04165982 0.04165982\n",
      " 0.04170893 0.04170893 0.04475941 0.04475941 0.04531968 0.04531968\n",
      " 0.0709801  0.0709801  0.07262262 0.07262262 0.07334858 0.07334858]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.48250917,  0.48250917,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.17803603,  0.17803603,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.48036158,  0.48036158,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.57890257,\n",
       "       -0.57890257, -0.59631213, -0.59631213,  0.59681356,  0.59681356,\n",
       "        5.46377814,  5.46377814,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -5.55608763, -5.55608763, -5.59718475, -5.59718474,\n",
       "       -5.6416412 , -5.6416412 ,  0.        ,  0.        ,  5.67150479,\n",
       "        5.67150479,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.75390947,\n",
       "        0.75390947,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.argsort(np.abs(grad_beta[:,0])))\n",
    "grad_beta = _grad_L2loss(np.expand_dims(models.fit_[0]['beta'][:,0],1) , xtrain, ytrain)\n",
    "print(np.asarray(groups)[np.argsort(np.abs(grad_beta[:,0]))])\n",
    "print(np.abs(grad_beta[:,0])[np.argsort(np.abs(grad_beta[:,0]))])\n",
    "models.fit_[0]['beta'][:,0][np.argsort(np.abs(grad_beta[:,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.argsort(np.abs(grad_beta[:,0]))[4]\n",
    "#1, then 6 #83, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.59718475],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.57890257],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.48250917],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.17803603],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-5.6416412 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.75390947],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 5.67150479],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.48036158],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-5.55608763],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.59681356],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 5.46377814],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.59631213],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-5.59718474],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.57890257],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.48250917],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.17803603],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-5.6416412 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.75390947],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 5.67150479],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.48036158],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-5.55608763],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.59681356],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 5.46377814],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.59631213],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.fit_[0]['beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 12, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[0].dg_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(replicates[0].dgw_norm, axis = 0), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72863687, 0.66580155, 0.66585824, 0.70990654, 0.65074203,\n",
       "       0.65054299, 0.72693777, 0.66583147, 0.66643814, 0.55899138,\n",
       "       0.55761593, 0.5568596 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(replicates[0].dg_M, axis = 0), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10689735, 0.08197996, 0.11165893, 0.1021662 , 0.08904118,\n",
       "       0.10682174, 0.10604182, 0.0760441 , 0.10208558, 0.11083858,\n",
       "       0.10469692, 0.1046882 , 0.10654019, 0.10647507, 0.10509333,\n",
       "       0.10304713, 0.1049818 , 0.10271747, 0.10794985, 0.09441638,\n",
       "       0.10692433, 0.10286922, 0.106731  , 0.11034037, 0.09696434,\n",
       "       0.1052683 , 0.10565527, 0.11406819, 0.10156304, 0.10424137,\n",
       "       0.10567594, 0.10174003, 0.10509754, 0.10175644, 0.09951485,\n",
       "       0.10413707, 0.11293181, 0.10531116, 0.10031467, 0.10085789,\n",
       "       0.07059007, 0.10190611, 0.10160176, 0.1157418 , 0.10910521,\n",
       "       0.1016394 , 0.1035248 , 0.10130181, 0.10447883, 0.09995063])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dg_M, axis = 2)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10517544, 0.10681406, 0.10983474, 0.10065144, 0.11031344,\n",
       "       0.10662045, 0.10506277, 0.11073202, 0.10192637, 0.08102379,\n",
       "       0.10349074, 0.10321548, 0.10400889, 0.10545206, 0.1027385 ,\n",
       "       0.10085787, 0.10402423, 0.10070244, 0.09525458, 0.1029463 ,\n",
       "       0.10502873, 0.10093451, 0.10468439, 0.11016705, 0.10410926,\n",
       "       0.10355573, 0.10384863, 0.11433169, 0.10136071, 0.10312895,\n",
       "       0.10538773, 0.09984718, 0.10333107, 0.10084292, 0.10046261,\n",
       "       0.10306825, 0.05940794, 0.10388809, 0.10050406, 0.09968671,\n",
       "       0.11202381, 0.10274482, 0.10105668, 0.11099936, 0.0980789 ,\n",
       "       0.10541583, 0.10248608, 0.10077212, 0.10316825, 0.10002404])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dg_M, axis = 2)[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.88205473, 2.88421814, 0.60748664, 0.63692693, 1.31554453,\n",
       "       0.62523409, 1.74910043, 0.62505822, 2.49384737, 0.60586352,\n",
       "       0.65059963, 0.85728958, 2.54389169, 2.57975948, 0.63558644,\n",
       "       0.68410452, 0.80004081, 1.17572387, 0.70254405, 0.80670082,\n",
       "       2.14882834, 2.95308133, 1.79763542, 1.31245075, 0.60696329,\n",
       "       0.70407986, 2.50180394, 1.06286587, 0.62698432, 0.66632216,\n",
       "       2.07720693, 0.66557191, 3.13993365, 1.07471968, 0.76376069,\n",
       "       0.85547695, 0.60571009, 0.73070569, 1.08125822, 2.96087502,\n",
       "       0.73060207, 0.61310664, 2.10922832, 0.7628363 , 2.96676161,\n",
       "       2.49113607, 0.61090717, 1.07747542, 1.31491882, 0.68520966])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dg_w, axis = 2)[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70487059, 0.7331523 , 0.80320969, 0.65771164, 0.82799515,\n",
       "       0.74120661, 0.61073401, 0.75108842, 0.61357498, 0.60326412,\n",
       "       0.61441658, 0.91586275, 0.71123505, 0.62491323, 0.97649153,\n",
       "       0.9574321 , 0.63008917, 0.96590125, 0.60473077, 0.71760742,\n",
       "       0.98970468, 0.97131401, 0.98767544, 0.73249004, 0.71188684,\n",
       "       0.97035535, 0.91371248, 0.79146095, 0.61306313, 0.61000754,\n",
       "       0.62663215, 0.85793442, 0.61846517, 0.61199008, 0.67094956,\n",
       "       0.67903886, 0.62016807, 0.96186291, 0.65806185, 0.60486685,\n",
       "       0.79706227, 0.69866888, 0.66778524, 0.7708264 , 0.61611036,\n",
       "       0.70690898, 0.64216082, 0.59475728, 0.88503935, 0.60025389])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dg_w, axis = 2)[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61989046, 0.63747513, 0.60812194, 1.53863921, 0.62779038,\n",
       "       0.63663275, 0.80117544, 1.49403788, 0.62712927, 0.60892443,\n",
       "       2.93857689, 0.70477579, 2.50955443, 0.66258204, 0.9143043 ,\n",
       "       1.80816429, 0.61291875, 0.63748786, 3.10417066, 0.76808003,\n",
       "       2.05397149, 0.60492094, 0.84790783, 2.12329885, 0.73569489,\n",
       "       0.97540119, 1.50751449, 0.70874823, 0.61812747, 0.66212689,\n",
       "       0.90532393, 3.01337048, 0.84823751, 0.66261021, 0.60850242,\n",
       "       1.07889712, 0.60875675, 2.04793809, 0.61761064, 0.65085275,\n",
       "       0.62482115, 1.31139266, 0.60432903, 1.05913774, 0.60579554,\n",
       "       1.06234876, 1.19290846, 0.73178199, 1.79987224, 0.61693959])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[1].dg_w, axis = 2)[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.54415722, 2.53539198, 0.47940482, 0.48997332, 0.95873234,\n",
       "       0.49094169, 1.30978965, 0.49089529, 2.01826821, 0.47786481,\n",
       "       0.50658879, 0.63420858, 2.11772702, 2.13820229, 0.49741347,\n",
       "       0.51436694, 0.59822648, 0.82204827, 0.53788229, 0.58538064,\n",
       "       1.67684186, 2.57745695, 1.3507313 , 0.92438106, 0.47920728,\n",
       "       0.53885908, 2.06286072, 0.77044597, 0.48572377, 0.51606961,\n",
       "       1.61462004, 0.50448761, 2.86438997, 0.75790408, 0.55853108,\n",
       "       0.63285334, 0.4777907 , 0.55506813, 0.76054617, 2.63192732,\n",
       "       0.55473322, 0.48294856, 1.64309131, 0.57397297, 2.63757865,\n",
       "       2.06189867, 0.48198988, 0.75990862, 0.95851848, 0.51589457])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dg_w_pca, axis = 2)[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15239286, 0.13752868, 0.14131968, 0.13634625, 0.13579083,\n",
       "       0.14464488, 0.15474709, 0.1360581 , 0.1611547 , 0.14029824,\n",
       "       0.13674431, 0.13756707, 0.14562656, 0.13764267, 0.13697116,\n",
       "       0.13493314, 0.13595909, 0.13332481, 0.14845877, 0.13382397,\n",
       "       0.13720669, 0.13791729, 0.13652633, 0.1389468 , 0.13583425,\n",
       "       0.13685671, 0.13950889, 0.14035492, 0.15740309, 0.13729085,\n",
       "       0.16317899, 0.13745027, 0.14110935, 0.13299514, 0.14861477,\n",
       "       0.13618684, 0.14271898, 0.13685211, 0.15045297, 0.13908222,\n",
       "       0.13598674, 0.13633581, 0.13472106, 0.14439595, 0.15164087,\n",
       "       0.1373567 , 0.13683318, 0.15054926, 0.13602085, 0.14983791])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dgw_norm, axis = 2)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10689735, 0.08197996, 0.11165893, 0.1021662 , 0.08904118,\n",
       "       0.10682174, 0.10604182, 0.0760441 , 0.10208558, 0.11083858,\n",
       "       0.10469692, 0.1046882 , 0.10654019, 0.10647507, 0.10509333,\n",
       "       0.10304713, 0.1049818 , 0.10271747, 0.10794985, 0.09441638,\n",
       "       0.10692433, 0.10286922, 0.106731  , 0.11034037, 0.09696434,\n",
       "       0.1052683 , 0.10565527, 0.11406819, 0.10156304, 0.10424137,\n",
       "       0.10567594, 0.10174003, 0.10509754, 0.10175644, 0.09951485,\n",
       "       0.10413707, 0.11293181, 0.10531116, 0.10031467, 0.10085789,\n",
       "       0.07059007, 0.10190611, 0.10160176, 0.1157418 , 0.10910521,\n",
       "       0.1016394 , 0.1035248 , 0.10130181, 0.10447883, 0.09995063])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(replicates[0].dg_M, axis = 2)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mpca = experiment.Mpca\n",
    "Mangles = experiment.M\n",
    "planar_angles = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from codes.geometer.TangentBundle import TangentBundle\n",
    "from codes.geometer.ShapeSpace import ShapeSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_points= np.asarray(selected_points_save[0], dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #def get_grads_tangent(experiment, Mpca, Mangles, selected_points, planar_angles = False):\n",
    "    dimnoise = experiment.dimnoise\n",
    "    dim = experiment.dim\n",
    "    cores = experiment.cores\n",
    "\n",
    "    tangent_bases = Mpca.get_wlpca_tangent_sel(Mpca, selected_points, dimnoise)\n",
    "    subM = RiemannianManifold(Mpca.data[selected_points], dim)\n",
    "    subM.tb = TangentBundle(subM, tangent_bases)\n",
    "    #N.tangent_bundle = TangentBundle(N, np.swapaxes(N.geom.rmetric.Hvv[:,:dim,:],1,2))\n",
    "    if planar_angles == False:\n",
    "        dg_x = experiment.get_dx_g_full(Mangles.data[selected_points])\n",
    "    else:\n",
    "        dg_x = experiment.get_dx_torsionsangles_full(Mangles.data[selected_points])\n",
    "\n",
    "    W = ShapeSpace(experiment.positions, Mangles.data)\n",
    "    dw = W.get_dw(cores, experiment.atoms3, experiment.natoms, selected_points)\n",
    "    dg_w = experiment.project(np.swapaxes(dw, 1, 2),\n",
    "                              experiment.project(dw, dg_x))\n",
    "\n",
    "    dg_w_pca = np.asarray([np.matmul(experiment.projector, dg_w[j].transpose()).transpose() for j in range(len(selected_points))])\n",
    "    dgw_norm = experiment.normalize(dg_w_pca)\n",
    "    dg_M = experiment.project(subM.tb.tangent_bases, dgw_norm)\n",
    "    #return (np.repeat([np.identity(dim)], axis = 0, repeats = len(selected_points)), dg_M, dg_w, dg_w_pca, dgw_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10689735, 0.08197996, 0.11165893, 0.1021662 , 0.08904118,\n",
       "       0.10682174, 0.10604182, 0.0760441 , 0.10208558, 0.11083858,\n",
       "       0.10469692, 0.1046882 , 0.10654019, 0.10647507, 0.10509333,\n",
       "       0.10304713, 0.1049818 , 0.10271747, 0.10794985, 0.09441638,\n",
       "       0.10692433, 0.10286922, 0.106731  , 0.11034037, 0.09696434,\n",
       "       0.1052683 , 0.10565527, 0.11406819, 0.10156304, 0.10424137,\n",
       "       0.10567594, 0.10174003, 0.10509754, 0.10175644, 0.09951485,\n",
       "       0.10413707, 0.11293181, 0.10531116, 0.10031467, 0.10085789,\n",
       "       0.07059007, 0.10190611, 0.10160176, 0.1157418 , 0.10910521,\n",
       "       0.1016394 , 0.1035248 , 0.10130181, 0.10447883, 0.09995063])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(dg_M, axis = 2)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09160783, 0.07307055, 0.05076601, 0.0518946 , 0.09402157,\n",
       "       0.05197887, 0.11628068, 0.05196439, 0.11527739, 0.05072534,\n",
       "       0.05365533, 0.06652064, 0.10686521, 0.11993983, 0.05274222,\n",
       "       0.05432942, 0.06316492, 0.08219427, 0.05691813, 0.06122827,\n",
       "       0.13120166, 0.08053616, 0.11862001, 0.08931462, 0.05077311,\n",
       "       0.05699857, 0.11820461, 0.07927291, 0.05142888, 0.05468624,\n",
       "       0.12437817, 0.05320416, 0.00627287, 0.07705005, 0.05881856,\n",
       "       0.06657065, 0.05070329, 0.05864455, 0.07774421, 0.06931033,\n",
       "       0.05866051, 0.05124647, 0.12215777, 0.06065655, 0.07895984,\n",
       "       0.12161527, 0.05107726, 0.0769435 , 0.09790492, 0.05446227])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(dg_M, axis = 2)[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dgw_norm = experiment.normalize(replicates[0].dg_w_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21000756, 0.15702371, 0.15725543, 0.22957896, 0.17238303,\n",
       "       0.17230106, 0.23047675, 0.17251899, 0.1731826 , 0.2380244 ,\n",
       "       0.23712767, 0.23665776])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(dgw_norm, axis = 0)**2, axis = 1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50, 12)\n"
     ]
    }
   ],
   "source": [
    "gammas = np.sum(np.sum(replicates[0].dg_w_pca**2, axis = 2), axis = 0)**(.5)\n",
    "normed = np.swapaxes(replicates[0].dg_w_pca,1,2) / gammas\n",
    "print(normed.shape)\n",
    "normed= np.swapaxes(normed,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(normed**2, axis = 2), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        differential = replicates[0].dg_w_pca\n",
    "        n = differential.shape[0]\n",
    "        # could be p, or q\n",
    "        p = differential.shape[1]\n",
    "        d = differential.shape[2]\n",
    "\n",
    "        gammas = np.sum(np.sum(differential ** 2, axis=2), axis=0) ** (.5)\n",
    "        normed = np.swapaxes(differential, 1, 2) / gammas\n",
    "        #print(normed.shape)\n",
    "        normed = np.swapaxes(normed, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(normed**2, axis = 2), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from codes.otherfunctions.multirun import get_cosines\n",
    "fig, axes_all = plt.subplots(2,figsize=(15,15))\n",
    "fig.suptitle('Cosines for each replicate')\n",
    "for i in range(2):\n",
    "    #full = np.concatenate([replicates[i].dg_M, np.swapaxes(replicates[i].df_M,1,2)],1)\n",
    "    asdf = get_cosines(replicates[i].dg_M)\n",
    "    axes_all[i].imshow(asdf)\n",
    "#fig.savefig(folder + '/cosines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    output = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    dg = replicates[0].dg_M\n",
    "    n = dg.shape[0]\n",
    "    p = dg.shape[1]\n",
    "    d = dg.shape[2]\n",
    "\n",
    "    coses = np.zeros((n, p, p))\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            for k in range(p):\n",
    "                coses[i, j, k] = cosine_similarity(dg[i, j, :], dg[i, k,\n",
    "                                                                :])  # sklearn.metrics.pairwise.cosine_similarity(X = np.reshape(dg[:,i,:], (1,d*n)),Y = np.reshape(dg[:,j,:], (1,d*n)))[0][0]\n",
    "    # cos_summary = np.abs(coses).sum(axis = 0) / n\n",
    "    cos_summary = np.sum(coses ** 2, axis=0) / n\n",
    "    #return (cos_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16050133,  0.08340455, -0.00384155,  0.02507418, -0.06804237,\n",
       "       -0.02218222,  0.10535787, -0.00422018,  0.14696215,  0.00255905,\n",
       "       -0.03145519,  0.05181962,  0.15713145, -0.12956094, -0.02138226,\n",
       "       -0.03951252,  0.05260132, -0.09126729,  0.03668117, -0.08040316,\n",
       "        0.11031779, -0.10663713,  0.09605069, -0.09458794, -0.00073424,\n",
       "       -0.03642544, -0.12020165, -0.05316855, -0.02222705, -0.03376008,\n",
       "        0.10149517, -0.04195251, -0.06490992, -0.08428714, -0.05728615,\n",
       "       -0.05193801,  0.01941895, -0.04097264,  0.09653019, -0.07500382,\n",
       "       -0.04432987, -0.01024113, -0.16519721, -0.02623311, -0.11990064,\n",
       "        0.13634061,  0.01883037, -0.08594354, -0.08441232, -0.0477385 ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coses[:,0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16050133,  0.08340455, -0.00384155,  0.02507418, -0.06804237,\n",
       "       -0.02218222,  0.10535787, -0.00422018,  0.14696215,  0.00255905,\n",
       "       -0.03145519,  0.05181962,  0.15713145, -0.12956094, -0.02138226,\n",
       "       -0.03951252,  0.05260132, -0.09126729,  0.03668117, -0.08040316,\n",
       "        0.11031779, -0.10663713,  0.09605069, -0.09458794, -0.00073424,\n",
       "       -0.03642544, -0.12020165, -0.05316855, -0.02222705, -0.03376008,\n",
       "        0.10149517, -0.04195251, -0.06490992, -0.08428714, -0.05728615,\n",
       "       -0.05193801,  0.01941895, -0.04097264,  0.09653019, -0.07500382,\n",
       "       -0.04432987, -0.01024113, -0.16519721, -0.02623311, -0.11990064,\n",
       "        0.13634061,  0.01883037, -0.08594354, -0.08441232, -0.0477385 ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coses[:,0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    coeffs = replicates[0].coeffs\n",
    "    selected_functions = np.asarray(np.where(np.sum(np.sum(coeffs ** 2, axis=1), axis=1) > 0))\n",
    "\n",
    "    sls = np.where(np.asarray(list(Counter(selected_functions[0]).values())) == dim)[0]\n",
    "    if len(sls) > 0:\n",
    "        selection_lambda = np.min(sls)\n",
    "        selected_functions_at_selection_lambda = selected_functions[1][\n",
    "            np.where(selected_functions[0] == selection_lambda)[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = replicates[0]\n",
    "cs = experiment.get_betas_spam2(r.xtrain, r.ytrain, r.groups, np.asarray([r.lambdas_plot[17]]), 50, 2, itermax, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5229.54935117,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  430.69493978,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = replicates[0]\n",
    "cs = experiment.get_betas_spam2(r.xtrain, r.ytrain, r.groups, np.asarray([r.lambdas_plot[17]]), 50, 2, itermax, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    def get_betas_spam2(self, xs, ys, groups, lambdas, n, q, itermax, tol):\n",
    "\n",
    "        # n = xs.shape[0]\n",
    "        p = len(np.unique(groups))\n",
    "        lambdas = np.asarray(lambdas, dtype=np.float64)\n",
    "        yadd = np.expand_dims(ys, 1)\n",
    "        groups = np.asarray(groups, dtype=np.int32) + 1\n",
    "        W0 = np.zeros((xs.shape[1], yadd.shape[1]), dtype=np.float32)\n",
    "        Xsam = np.asfortranarray(xs, dtype=np.float32)\n",
    "        Ysam = np.asfortranarray(yadd, dtype=np.float32)\n",
    "        coeffs = np.zeros((len(lambdas), q, n, p))\n",
    "        for i in range(len(lambdas)):\n",
    "            # alpha = spams.fistaFlat(Xsam,Dsam2,alpha0sam,ind_groupsam,lambda1 = lambdas[i],mode = mode,itermax = itermax,tol = tol,numThreads = numThreads, regul = \"group-lasso-l2\")\n",
    "            # spams.fistaFlat(Y,X,W0,TRUE,numThreads = 1,verbose = TRUE,lambda1 = 0.05, it0 = 10, max_it = 200,L0 = 0.1, tol = 1e-3, intercept = FALSE,pos = FALSE,compute_gram = TRUE, loss = 'square',regul = 'l1')\n",
    "            output = spams.fistaFlat(Ysam, Xsam, W0, True, groups=groups, numThreads=-1, verbose=True,\n",
    "                                     lambda1=lambdas[i], it0=100, max_it=itermax, L0=0.5, tol=tol, intercept=False,\n",
    "                                     pos=False, compute_gram=True, loss='square', regul='group-lasso-l2', ista=False,\n",
    "                                     subgrad=False, a=0.1, b=1000)\n",
    "            coeffs[i, :, :, :] = np.reshape(output[0], (q, n, p))\n",
    "            # print(output[1])\n",
    "        return (coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def construct_Y(self, df_M):\n",
    "        \"\"\" df_M should have shape n x dim x dim\n",
    "        \"\"\"\n",
    "        n = df_M.shape[0]\n",
    "        dim = df_M.shape[1]\n",
    "\n",
    "        #reorg1 = np.swapaxes(df_M, 0, 1)\n",
    "        yvec = np.reshape(df_M, (n * dim * dim))\n",
    "        return (yvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self=experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,groups = experiment.construct_X(replicates[0].dg_M[:36])\n",
    "ytrain = construct_Y(experiment,np.repeat([np.identity(2)], axis = 0, repeats = 36))\n",
    "cs = experiment.get_betas_spam2(xtrain, ytrain, groups, np.asarray([.23*r.lambdas_plot[17]]), 36, 2, itermax, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  13321.46748733,       0.        ,       0.        ,\n",
       "             0.        ,       0.        ,       0.        ,\n",
       "        818168.34223748,       0.        ,       0.        ,\n",
       "       1354159.68289467,   24323.56221832,       0.        ])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.45200400e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.93348079e+04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     0.        ,     0.        ,     0.        ,\n",
       "           0.        ,     0.        , 54367.18892683,     0.        ,\n",
       "           0.        ,     0.        ,     0.        ,     0.        ])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09560884, -0.04127323],\n",
       "       [ 0.08677207,  0.03813768],\n",
       "       [-0.08673297, -0.03815059],\n",
       "       [-0.09410235, -0.04116909],\n",
       "       [-0.08561366, -0.03813062],\n",
       "       [ 0.08554555,  0.03813024],\n",
       "       [ 0.09456983,  0.04098306],\n",
       "       [-0.08600274, -0.0379455 ],\n",
       "       [-0.08603986, -0.03799182],\n",
       "       [-0.02317432,  0.06240675],\n",
       "       [ 0.02319112, -0.06225574],\n",
       "       [-0.02313327,  0.06230341]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[0].dg_M[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00567825,  0.11278897],\n",
       "       [-0.00500645, -0.10389345],\n",
       "       [-0.00496574, -0.10398719],\n",
       "       [-0.00592985, -0.11243577],\n",
       "       [ 0.00525256,  0.1038152 ],\n",
       "       [-0.00521057, -0.10387203],\n",
       "       [-0.00199892, -0.0593743 ],\n",
       "       [-0.00164248, -0.0550863 ],\n",
       "       [ 0.00160336,  0.05522602],\n",
       "       [-0.0505801 ,  0.00353226],\n",
       "       [ 0.05053038, -0.00286617],\n",
       "       [-0.05052673,  0.00292853]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[0].dg_M[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replicates[0].dg_M[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.lambdas_plot[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_betas_sam(self, xtrain, ytrain, groups, lambdas, n, q, max_iter, tol, learning_rate):\n",
    "\n",
    "    p = len(np.unique(groups))\n",
    "    models = GLM(xs=xtrain, ys=ytrain,\n",
    "                 tol=tol,\n",
    "                 group=groups,\n",
    "                 learning_rate=learning_rate,\n",
    "                 max_iter=max_iter,\n",
    "                 # reg_lambda=np.logspace(np.log(100), np.log(0.01), 5, base=np.exp(1)))\n",
    "                 reg_lambda=lambdas,\n",
    "                 parameter=.5)\n",
    "    models.fit()\n",
    "    nlam = len(lambdas)\n",
    "    organizedbetas = np.zeros((nlam, q, n, p))\n",
    "    for l in range(nlam):\n",
    "        organizedbetas[l, :, :, :] = np.reshape(models.fit_[l]['beta'], (q, n, p))\n",
    "    # return(models, organizedbetas)\n",
    "    return (organizedbetas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n",
      "converged 0.410625\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 144 into shape (2,36,12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-521-a5e847310f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_betas_sam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.73\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambdas_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitermax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/manifoldflasso_jmlr/codes/flasso/FlassoExperiment.py\u001b[0m in \u001b[0;36mget_betas_sam\u001b[0;34m(self, xtrain, ytrain, groups, lambdas, n, q, max_iter, tol, learning_rate)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0morganizedbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0morganizedbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;31m# return(models, organizedbetas)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0morganizedbetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    277\u001b[0m            [5, 6]])\n\u001b[1;32m    278\u001b[0m     \"\"\"\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 144 into shape (2,36,12)"
     ]
    }
   ],
   "source": [
    "\n",
    "cs = experiment.get_betas_sam(xtrain, ytrain, groups, np.asarray([.73*r.lambdas_plot[17]]), 36, 2, 10*itermax, .01*tol, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(2*np.reshape(replicates[0].df_M[:,0], (100,1))[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.69287873e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.73108829e+04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selpt = [0,1,4,5,6,36]\n",
    "xtrain,groups = experiment.construct_X(replicates[0].dg_M[selpt])\n",
    "ytrain = construct_Y(experiment,np.repeat([np.identity(2)], axis = 0, repeats = len(selpt)))\n",
    "cs = experiment.get_betas_spam2(xtrain, ytrain, groups, np.asarray([.325*r.lambdas_plot[17]]), len(selpt), 2, itermax, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        ,   0.        , 944.6732851 ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,  20.97637349,   0.        ])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = experiment.get_betas_spam2(xtrain, ytrain, groups, np.asarray([5*r.lambdas_plot[17]]), len(selpt), 2, 10*itermax, .01*tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.07725056e+09, 0.00000000e+00, 0.00000000e+00, 1.00419037e+04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.39502003,  0.        ,  0.        , -0.44825945,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.47909993,  0.        ,  0.        ,\n",
       "        0.13175256,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -5.4081252 ,\n",
       "        0.        ,  0.        ,  0.5810263 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  5.44247813,  0.        ,  0.        ,  0.37022509,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -5.35837659,  0.        ,\n",
       "        0.        ,  0.46282459,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        5.2945989 ,  0.        ,  0.        , -0.46448133,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -5.39502003,  0.        ,  0.        ,\n",
       "       -0.44825945,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.47909993,\n",
       "        0.        ,  0.        ,  0.13175256,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -5.4081252 ,  0.        ,  0.        ,  0.5810263 ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  5.44247813,  0.        ,\n",
       "        0.        ,  0.37022509,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -5.35837659,  0.        ,  0.        ,  0.46282459,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  5.2945989 ,  0.        ,  0.        ,\n",
       "       -0.46448133,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(cs[0], 2* 6* 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.07725056e+09, 0.00000000e+00, 0.00000000e+00, 1.00419037e+04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.norm(cs[0], axis = 1)**2, axis = 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6808333333333334"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6.72 / 4.22\n",
    "\n",
    "4.034 / 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def _grad_L2loss(beta, X, y):\n",
    "        #print(beta.shape,X.shape,y.shape)\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, np.newaxis]\n",
    "        n_samples = np.float(X.shape[0])\n",
    "        z = np.dot(X, beta)\n",
    "        #grad_beta = 1. / n_samples * np.transpose(np.dot(np.transpose(z - y), X))\n",
    "        grad_beta = np.transpose(np.dot(np.transpose(z - y), X))\n",
    "        #print('gb',grad_beta.shape)\n",
    "        return grad_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 24)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_grad_L2loss(beta = np.reshape(cs[0], 2* 6* 12), X =xtrain, y= ytrain).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X =xtrain \n",
    "y= ytrain\n",
    "beta = np.reshape(cs[0], 2* 6* 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        if y.ndim == 1:\n",
    "            y = y[:, np.newaxis]\n",
    "        if beta.ndim == 1:\n",
    "            beta = beta[:, np.newaxis]\n",
    "        n_samples = np.float(X.shape[0])\n",
    "        z = np.dot(X, beta)\n",
    "\n",
    "        #grad_beta = 1. / n_samples * np.transpose(np.dot(np.transpose(z - y), X))\n",
    "        grad_beta = np.transpose(np.dot(np.transpose(z - y), X))\n",
    "        #print('gb',grad_beta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 11, 10, 10,  9,  9,  7,  7,  8,  8, 10, 10, 11, 11,  9,  9,  5,\n",
       "        5,  4,  4,  1,  1,  2,  2,  0,  0, 10, 10, 11, 11,  9,  9,  6,  6,\n",
       "        9,  9, 11, 11, 10, 10, 11, 11,  9,  9, 10, 10,  3,  3,  7,  7,  8,\n",
       "        8,  6,  6,  4,  4,  5,  5,  3,  3,  5,  5,  4,  4,  4,  4,  5,  5,\n",
       "        1,  1,  5,  5,  2,  2,  4,  4,  7,  7,  7,  7,  1,  1,  8,  8,  2,\n",
       "        2,  8,  8,  7,  7,  8,  8,  1,  1,  2,  2,  1,  1,  2,  2,  2,  2,\n",
       "        1,  1,  3,  3,  3,  3,  6,  6,  3,  3,  0,  0,  6,  6,  0,  0,  6,\n",
       "        6,  0,  0,  0,  0,  0,  0,  4,  4,  5,  5,  7,  7,  8,  8,  3,  3,\n",
       "        6,  6, 11, 11,  9,  9, 10, 10])"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(groups)[np.argsort(np.abs(grad_beta[:,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01845065, 0.01845065, 0.01892355, 0.01892355, 0.01959235,\n",
       "       0.01959235, 0.04148805, 0.04148805, 0.04492756, 0.04492756,\n",
       "       0.05345704, 0.05345704, 0.05394403, 0.05394403, 0.0587133 ,\n",
       "       0.0587133 , 0.06396295, 0.06396295, 0.06736519, 0.06736519,\n",
       "       0.07704906, 0.07704906, 0.08047753, 0.08047753, 0.08353886,\n",
       "       0.08353886, 0.09483158, 0.09483158, 0.09543906, 0.09543906,\n",
       "       0.09817889, 0.09817889, 0.1208004 , 0.1208004 , 0.15261671,\n",
       "       0.15261671, 0.15473821, 0.15473821, 0.15562661, 0.15562661,\n",
       "       0.18548191, 0.18548191, 0.18664576, 0.18664576, 0.18711935,\n",
       "       0.18711935, 0.23859117, 0.23859117, 0.43117366, 0.43117375,\n",
       "       0.4322938 , 0.4322939 , 0.46459675, 0.46459685, 0.63217632,\n",
       "       0.63217632, 0.6323596 , 0.6323596 , 0.68790587, 0.68790587,\n",
       "       0.77788072, 0.77788072, 0.77814644, 0.77814644, 0.81126425,\n",
       "       0.81126442, 0.81173586, 0.81173604, 0.81202897, 0.81202915,\n",
       "       0.81215798, 0.81215798, 0.81278935, 0.81278953, 0.8128284 ,\n",
       "       0.8128284 , 0.8160192 , 0.8160192 , 0.81628415, 0.81628415,\n",
       "       0.81632326, 0.81632326, 0.81661235, 0.81661235, 0.81673685,\n",
       "       0.81673685, 0.8167436 , 0.8167436 , 0.81691847, 0.81691847,\n",
       "       0.8180508 , 0.8180508 , 0.81812127, 0.81812127, 0.81846588,\n",
       "       0.81846588, 0.82245924, 0.82245924, 0.8224631 , 0.8224631 ,\n",
       "       0.82553051, 0.82553051, 0.82592577, 0.82592577, 0.84066602,\n",
       "       0.84066602, 0.87029456, 0.87029456, 0.87435995, 0.87435995,\n",
       "       0.87848195, 0.87848214, 0.88140713, 0.88140732, 0.88226391,\n",
       "       0.88226391, 0.88654355, 0.88654355, 0.88952923, 0.88952923,\n",
       "       0.89068037, 0.89068037, 0.89103282, 0.89103282, 0.89331422,\n",
       "       0.89331422, 1.00108688, 1.00108688, 1.00109025, 1.00109025,\n",
       "       1.01343348, 1.01343348, 1.01467897, 1.01467897, 1.09044468,\n",
       "       1.09044468, 1.10435987, 1.10435987, 1.4222245 , 1.4222245 ,\n",
       "       1.45521617, 1.45521617, 1.46968293, 1.46968293])"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(grad_beta[:,0])[np.argsort(np.abs(grad_beta[:,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 83,  11,  82,  10,  81,   9,  91,  19,  92,  20,  70, 142,  71,\n",
       "       143,  69, 141,  17,  89,  16,  88,  13,  85,  14,  86,  12,  84,\n",
       "        34, 106, 107,  35, 105,  33,  18,  90,  45, 117,  47, 119, 118,\n",
       "        46,  59, 131, 129,  57, 130,  58,  15,  87,  67, 139,  68, 140,\n",
       "        66, 138,  40, 112, 113,  41,  39, 111,   5,  77,  76,   4,  64,\n",
       "       136,  65, 137,  61, 133, 125,  53,  62, 134,  52, 124,   7,  79,\n",
       "        55, 127,  37, 109, 128,  56,  38, 110,  80,   8,  43, 115,  44,\n",
       "       116,  25,  97,  98,  26,   1,  73,   2,  74, 122,  50,  49, 121,\n",
       "         3,  75, 123,  51, 126,  54,  63, 135,  60, 132,  78,   6,  48,\n",
       "       120,  42, 114,  36, 108,   0,  72,  96,  24,  28, 100,  29, 101,\n",
       "        31, 103,  32, 104,  27,  99, 102,  30,  95,  23,  93,  21,  94,\n",
       "        22])"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.abs(grad_beta[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.916666666666667"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "83 / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#consider the 11s\n",
    "#0,6 low grad.... \n",
    "#1, 7 big grad\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        #def get_betas_spam2(self, xs, ys, groups, lambdas, n, q, itermax, tol):\n",
    "        xs =xtrain \n",
    "        ys= ytrain\n",
    "        #beta = np.reshape(cs[0], 2* 6* 12)\n",
    "        np.asarray([5*r.lambdas_plot[17]])\n",
    "        \n",
    "        n = len(selpt)\n",
    "        q = 2\n",
    "        # n = xs.shape[0]\n",
    "        p = len(np.unique(groups))\n",
    "        lambdas = np.asarray(lambdas, dtype=np.float64)\n",
    "        yadd = np.expand_dims(ys, 1)\n",
    "        groups = np.asarray(groups, dtype=np.int32) + 1\n",
    "        W0 = np.zeros((xs.shape[1], yadd.shape[1]), dtype=np.float32)\n",
    "        Xsam = np.asfortranarray(xs, dtype=np.float32)\n",
    "        Ysam = np.asfortranarray(yadd, dtype=np.float32)\n",
    "        coeffs = np.zeros((len(lambdas), q, n, p))\n",
    "        for i in range(len(lambdas)):\n",
    "            # alpha = spams.fistaFlat(Xsam,Dsam2,alpha0sam,ind_groupsam,lambda1 = lambdas[i],mode = mode,itermax = itermax,tol = tol,numThreads = numThreads, regul = \"group-lasso-l2\")\n",
    "            # spams.fistaFlat(Y,X,W0,TRUE,numThreads = 1,verbose = TRUE,lambda1 = 0.05, it0 = 10, max_it = 200,L0 = 0.1, tol = 1e-3, intercept = FALSE,pos = FALSE,compute_gram = TRUE, loss = 'square',regul = 'l1')\n",
    "            output = spams.fistaFlat(Ysam, Xsam, W0, True, groups=groups, numThreads=-1, verbose=True,\n",
    "                                     lambda1=lambdas[i], it0=100, max_it=itermax, L0=0.5, tol=tol, intercept=False,\n",
    "                                     pos=False, compute_gram=True, loss='square', regul='group-lasso-l2', ista=False,\n",
    "                                     subgrad=False, a=0.1, b=1000)\n",
    "            #coeffs[i, :, :, :] = np.reshape(output[0], (q, n, p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manifold_env_april2",
   "language": "python",
   "name": "manifold_env_april2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
