{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "import autograd.numpy as np\n",
    "from autograd import jacobian\n",
    "from autograd import elementwise_grad\n",
    "from autograd import grad\n",
    "\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "\n",
    "#import numpy as np\n",
    "from scipy.special import expit\n",
    "from pyglmnet import utils\n",
    "\n",
    "\n",
    "class GradientGroupLasso:\n",
    "    \n",
    "    def __init__(self, dg_M, df_M, reg_l1s, reg_l2, max_iter,learning_rate, tol, beta0_npm= None):\n",
    "        \n",
    "        n = dg_M.shape[0]\n",
    "        d= dg_M.shape[1]\n",
    "        m = df_M.shape[2]\n",
    "        p = dg_M.shape[2]\n",
    "        dummy_beta = np.ones((n,p,m))\n",
    "        \n",
    "        self.dg_M = dg_M\n",
    "        self.df_M = df_M\n",
    "        self.reg_l1s = reg_l1s\n",
    "        self.reg_l2 = reg_l2\n",
    "        self.beta0_npm = beta0_npm\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.m = m \n",
    "        self.d = d\n",
    "        self.dummy_beta = dummy_beta\n",
    "        #self.group = np.asarray(group)\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tol = tol\n",
    "        self.Tau = None\n",
    "        self.alpha = 1.\n",
    "        self.lossresults = {}\n",
    "        self.dls = {}\n",
    "        self.l2loss = {}\n",
    "        self.penalty = {}\n",
    "        \n",
    "    def _prox(self,beta_npm, thresh):\n",
    "        \"\"\"Proximal operator.\"\"\"\n",
    "        \n",
    "        p = self.p\n",
    "        result = np.zeros(beta_npm.shape)\n",
    "        result = np.asarray(result, dtype = float)\n",
    "        for j in range(p):\n",
    "            if np.linalg.norm(beta_npm[:,j,:]) > 0.:\n",
    "                potentialoutput = beta_npm[:,j,:] - (thresh / np.linalg.norm(beta_npm[:,j,:])) * beta_npm[:,j,:]\n",
    "                posind = np.asarray(np.where(beta_npm[:,j,:] > 0.))\n",
    "                negind = np.asarray(np.where(beta_npm[:,j,:] < 0.))\n",
    "                po = beta_npm[:,j,:].copy()\n",
    "                po[posind[0],posind[1]] = np.asarray(np.clip(potentialoutput[posind[0],posind[1]],a_min = 0., a_max = 1e15), dtype = float)\n",
    "                po[negind[0],negind[1]] = np.asarray(np.clip(potentialoutput[negind[0],negind[1]],a_min = -1e15, a_max = 0.), dtype = float)\n",
    "                result[:,j,:] = po\n",
    "        return result\n",
    "\n",
    "    def _grad_L2loss(self, beta_npm):\n",
    "        \n",
    "        df_M = self.df_M\n",
    "        dg_M = self.dg_M\n",
    "        reg_l2 = self.reg_l2\n",
    "        dummy_beta = self.dummy_beta\n",
    "        \n",
    "        df_M_hat = np.einsum('ndp,npm->ndm',dg_M, beta_npm)\n",
    "        error = df_M_hat - df_M\n",
    "        grad_beta = np.einsum('ndm,ndp->npm',error,dg_M) #+ reg_l2 * np.ones()\n",
    "        #if \n",
    "        return grad_beta\n",
    "    \n",
    "    def _L1penalty(self, beta_npm):\n",
    "        \n",
    "        p = self.p\n",
    "        m = self.m\n",
    "        n = self.n \n",
    "        beta_mn_p = rearrange(beta_npm, 'n p m -> (m n) p')#np.reshape(beta_mnp, ((m*n,p)))\n",
    "        L1penalty = np.linalg.norm(beta_mn_p, axis = 0).sum()\n",
    "        \n",
    "        return L1penalty\n",
    "    \n",
    "    def _loss(self,beta_npm, reg_lambda):\n",
    "        \"\"\"Define the objective function for elastic net.\"\"\"\n",
    "        L = self._logL(beta_npm)\n",
    "        P = self._L1penalty(beta_npm)\n",
    "        J = -L + reg_lambda * P\n",
    "        return J\n",
    "    \n",
    "    def _logL(self,beta_npm):\n",
    "        \n",
    "        df_M = self.df_M\n",
    "        dg_M = self.dg_M\n",
    "        \n",
    "        df_M_hat = np.einsum('ndp,npm -> ndm',dg_M, beta_npm)\n",
    "        logL = -0.5 * np.linalg.norm((df_M - df_M_hat))**2\n",
    "        return(logL)\n",
    "    \n",
    "    def _L2loss(self,beta_npm):\n",
    "        output = -self._logL(beta_npm)\n",
    "        return(output)\n",
    "\n",
    "    def fhatlambda(self,learning_rate,beta_npm_new,beta_npm_old):\n",
    "\n",
    "        print('lr',learning_rate)\n",
    "        output = self._L2loss(beta_npm_old) + np.einsum('npm,npm', self._grad_L2loss(beta_npm_old),(beta_npm_new-beta_npm_old)) + (1/(2*learning_rate)) * np.linalg.norm(beta_npm_new-beta_npm_old)**2\n",
    "        \n",
    "        return(output)\n",
    "\n",
    "    def _btalgorithm(self,beta_npm ,learning_rate,b,maxiter_bt,rl):\n",
    "        \n",
    "        grad_beta = self._grad_L2loss(beta_npm = beta_npm)\n",
    "        for i in range(maxiter_bt):\n",
    "            beta_npm_postgrad = beta_npm - learning_rate * grad_beta\n",
    "            beta_npm_postgrad_postprox = self._prox(beta_npm_postgrad, learning_rate * rl)\n",
    "            fz = self._L2loss(beta_npm_postgrad_postprox)\n",
    "            #fhatz = self.fhatlambda(lam,beta_npm_postgrad_postprox, beta_npm_postgrad)\n",
    "            fhatz = self.fhatlambda(learning_rate,beta_npm_postgrad_postprox, beta_npm)\n",
    "            if fz <= fhatz:\n",
    "                #print(i)\n",
    "                break\n",
    "            learning_rate = b*learning_rate    \n",
    "            \n",
    "        return(beta_npm_postgrad_postprox,learning_rate)\n",
    "    \n",
    "    def fit(self, beta0_npm = None):\n",
    "\n",
    "        reg_l1s = self.reg_l1s\n",
    "        n = self.n\n",
    "        m = self.m\n",
    "        p = self.p\n",
    "        \n",
    "        dg_M = self.dg_M\n",
    "        df_M = self.df_M\n",
    "        \n",
    "        tol = self.tol\n",
    "        np.random.RandomState(0)\n",
    "        \n",
    "        if beta0_npm is None:\n",
    "            beta_npm_hat = 1 / (n*m*p) * np.random.normal(0.0, 1.0, [n, p,m])\n",
    "            #1 / (n_features) * np.random.normal(0.0, 1.0, [n_features, n_classes])\n",
    "        else: \n",
    "            beta_npm_hat = beta0_npm\n",
    "            \n",
    "        fit_params = list()\n",
    "        for l, rl in enumerate(reg_l1s):\n",
    "            fit_params.append({'beta': beta_npm_hat})\n",
    "            if l == 0:\n",
    "                fit_params[-1]['beta'] = beta_npm_hat\n",
    "            else:\n",
    "                fit_params[-1]['beta'] = fit_params[-2]['beta']\n",
    "            \n",
    "            alpha = 1.\n",
    "            beta_npm_hat = fit_params[-1]['beta']\n",
    "            #g = np.zeros([n_features, n_classes])\n",
    "            L, DL ,L2,PEN = list(), list() , list(), list()\n",
    "            learning_rate = self.learning_rate\n",
    "            beta_npm_hat_1 = beta_npm_hat.copy()\n",
    "            beta_npm_hat_2 = beta_npm_hat.copy()\n",
    "            for t in range(0, self.max_iter):\n",
    "                #print(t,l,rl)\n",
    "                print(t)\n",
    "                L.append(self._loss(beta_npm_hat, rl))\n",
    "                L2.append(self._L2loss(beta_npm_hat))\n",
    "                PEN.append(self._L1penalty(beta_npm_hat))\n",
    "                w = (t / (t+ 3))\n",
    "                beta_npm_hat_momentumguess = beta_npm_hat + w*(beta_npm_hat_1 - beta_npm_hat_2)\n",
    "                \n",
    "                beta_npm_hat , learning_rate = self._btalgorithm(beta_npm_hat_momentumguess,learning_rate,.5,1000, rl)\n",
    "                #print(beta_npm_hat_momentumguess.max(), beta_npm_hat.max(),self._L2loss(beta_npm_hat), learning_rate)\n",
    "                beta_npm_hat_2 = beta_npm_hat_1.copy()\n",
    "                beta_npm_hat_1 = beta_npm_hat.copy()\n",
    "                \n",
    "                if t > 1:\n",
    "                    DL.append(L[-1] - L[-2])\n",
    "                    if np.abs(DL[-1] / L[-1]) < tol:\n",
    "                        print('converged', rl)\n",
    "                        msg = ('\\tConverged. Loss function:'\n",
    "                               ' {0:.2f}').format(L[-1])\n",
    "                        msg = ('\\tdL/L: {0:.6f}\\n'.format(DL[-1] / L[-1]))\n",
    "                        break\n",
    "\n",
    "            fit_params[-1]['beta'] = beta_npm_hat\n",
    "            self.lossresults[rl] = L\n",
    "            self.l2loss[rl] = L2\n",
    "            self.penalty[rl] = PEN\n",
    "            self.dls[rl] = DL\n",
    "\n",
    "        self.fit_ = fit_params\n",
    "        #self.ynull_ = np.mean(y)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/manifoldflasso_jmlr\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "import random\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from matplotlib.lines import Line2D\n",
    "from pylab import rcParams\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "#from datetime import datetime\n",
    "\n",
    "from shutil import copyfile\n",
    "rcParams['figure.figsize'] = 25, 10\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "now = datetime.datetime.now().strftime(\"%B_%d_%Y_%H_%M_%S\")\n",
    "workingdirectory = os.popen('git rev-parse --show-toplevel').read()[:-1]\n",
    "sys.path.append(workingdirectory)\n",
    "os.chdir(workingdirectory)\n",
    "from codes.experimentclasses.RigidEthanolPCA2 import RigidEthanolPCA2\n",
    "from codes.otherfunctions.get_dictionaries import get_atoms_4\n",
    "from codes.otherfunctions.get_grads import get_grads\n",
    "from codes.otherfunctions.multirun import get_support_recovery_lambda\n",
    "from codes.otherfunctions.multirun import get_lower_interesting_lambda\n",
    "from codes.otherfunctions.multirun import get_coeffs_and_lambdas\n",
    "from codes.otherfunctions.multirun import get_support\n",
    "from codes.otherfunctions.multiplot import plot_support_2d\n",
    "from codes.otherfunctions.multiplot import plot_reg_path_ax_lambdasearch\n",
    "from codes.otherfunctions.multiplot import plot_gs_v_dgnorm\n",
    "from codes.otherfunctions.multiplot import plot_dot_distributions\n",
    "from codes.otherfunctions.multirun import get_cosines\n",
    "from codes.flasso.Replicate import Replicate\n",
    "from codes.otherfunctions.multirun import get_olsnorm_and_supportsbrute\n",
    "from codes.otherfunctions.multiplot import highlight_cell\n",
    "\n",
    "from codes.geometer.RiemannianManifold import RiemannianManifold\n",
    "from codes.geometer.ShapeSpace import ShapeSpace\n",
    "from codes.geometer.TangentBundle import TangentBundle\n",
    "\n",
    "def plot_watch_custom(to_plot, p, ax,colors):\n",
    "    #fig, ax = plt.subplots(figsize = (15,15))\n",
    "    #%matplotlib inline\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize = (15,15))\n",
    "    theta = np.linspace(0, 2*np.pi, 10000)\n",
    "    cmap = plt.get_cmap('twilight_shifted',p)\n",
    "    \n",
    "    angles = np.linspace(0, 2*np.pi, p+1)\n",
    "    \n",
    "    radius = 1.\n",
    "\n",
    "    a = radius*np.cos(theta)\n",
    "    b = radius*np.sin(theta)\n",
    "\n",
    "    #figure, axes = plt.subplots(figsize = (15,15))\n",
    "\n",
    "    #axes.plot(a, b, color= 'gray')\n",
    "    ax.scatter(a, b, color = 'gray', s= .2, alpha = .1)#, '-', color = 'gray')#, s= .1, alpha = .1)#, type = 'line')#,cmap=plt.get_cmap('twilight')) #'hsv','twilight_shifted\n",
    "\n",
    "    #for i in range(to_plot.shape)\n",
    "    if len(to_plot.shape) > 1:\n",
    "        totes = np.sum(to_plot, axis = 0)\n",
    "    else:\n",
    "        totes = to_plot\n",
    "        \n",
    "    for j in range(p):\n",
    "        print(np.cos(angles[j]), np.sin(angles[j]))#r'$test \\frac{1}{}$'.format(g)\n",
    "        ax.scatter(np.cos(angles[j]),np.sin(angles[j]),color=cmap.colors[j], marker  = 'x')\n",
    "        ax.text( x = 1.1*np.cos(angles[j]),\n",
    "                  y = 1.1*np.sin(angles[j]),\n",
    "                  s = r\"$g_{{{}}}$\".format(j),color=colors[j],#cmap.colors[j],\n",
    "                  fontdict = {'fontsize' : 70},\n",
    "                  horizontalalignment='center',\n",
    "         verticalalignment='center')\n",
    "\n",
    "\n",
    "\n",
    "        ax.text( x = .9*np.cos(angles[j]),y = .9*np.sin(angles[j]),s = str(totes[j] / nreps), fontdict = {'fontsize' : 40},\n",
    "                  horizontalalignment='center',\n",
    "         verticalalignment='center')\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(p):\n",
    "        ax.scatter(np.cos(angles[j]),np.sin(angles[j]),color=colors[j], marker  = 'o', s = 200*totes[j] )\n",
    "\n",
    "    if len(to_plot.shape) > 1:\n",
    "        for i in range(p):\n",
    "            for j in range(p):\n",
    "\n",
    "                #point1 = [1, 2]\n",
    "                #point2 = [3, 4]\n",
    "\n",
    "                x_values = [np.cos(angles[j]), np.cos(angles[i])]\n",
    "                #gather x-values\n",
    "\n",
    "                y_values = [np.sin(angles[j]), np.sin(angles[i])]\n",
    "                #gather y-values\n",
    "\n",
    "                ax.plot(x_values, y_values,linewidth = to_plot[i,j], color = 'black')\n",
    "\n",
    "                if to_plot[i,j] > 0 :\n",
    "                    ax.text( x = np.mean(x_values),\n",
    "                      y = np.mean(y_values),\n",
    "                      s = str(to_plot[i,j] / nreps),\n",
    "                      fontdict = {'fontsize' : 40})#,\n",
    "                  #horizontalalignment='left',\n",
    "                # verticalalignment='bottom')\n",
    "\n",
    "                #axes.axline((x1, y1), (x2, y2))\n",
    "    ax.set_aspect(1)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(r\"$\\omega = 25$\")\n",
    "    \n",
    "def plot_cosines(cosines, ax, colors):\n",
    "    p = cosines.shape[0]\n",
    "    sns.heatmap(cosines ,ax = ax, vmin = 0., vmax = 1.)\n",
    "#    ax = sns.heatmap(x, cmap=cmap)\n",
    "    # use matplotlib.colorbar.Colorbar object\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    # here set the labelsize by 20\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "    for xtick, color in zip(ax.get_xticklabels(), colors):\n",
    "        xtick.set_color(color)\n",
    "    for ytick, color in zip(ax.get_yticklabels(), colors):\n",
    "        ytick.set_color(color)\n",
    "    ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 500 / p)\n",
    "    ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 500 / p)\n",
    "    \n",
    "    ax.set_ylabel(r\"$g_{j'}$\", fontsize = 70)\n",
    "    ax.set_xlabel(r\"$g_{j}$\", fontsize = 70)\n",
    "    #ax.set_title(r\"$\\text{hi}$\")\n",
    "    ax.set_title(r\"$\\frac{1}{n'} \\sum_{i = 1}^{n'} \\frac{\\langle grad_{\\mathcal M} g_j (\\xi_i) ,grad_{\\mathcal M} g_{j'} (\\xi_i)\\rangle}{\\|grad_{\\mathcal M} g_j (\\xi_i) \\|_2 \\| grad_{\\mathcal M} g_{j'}(\\xi_i) \\|_2} $\",\n",
    "                fontsize = 70)\n",
    "\n",
    "# def plot_reg_path_ax_lambdasearch_customcolors_norm(ax, coeffs, xaxis,fig, colors):\n",
    "#     p = coeffs.shape[3]\n",
    "#     q = coeffs.shape[1]\n",
    "#     gnames = np.asarray(list(range(p)), dtype=str)\n",
    "\n",
    "#     rcParams['axes.titlesize'] = 30\n",
    "#     plt.rc('text', usetex=True)\n",
    "\n",
    "#     normax = np.sqrt(np.sum(np.sum(np.sum(coeffs ** 2, axis=1), axis=1), axis=1).max())\n",
    "\n",
    "#     for j in range(p):\n",
    "#         toplot = np.linalg.norm(np.linalg.norm(coeffs[:, :, :, j], axis=2), axis=1)\n",
    "#         # axes[0].boxplot(toplot, positions=xaxis, showfliers=False, vert=True, widths=widths,medianprops=dict(linestyle=''))\n",
    "#         ax.plot(xaxis, toplot, 'go--', linewidth=5, markersize=0, alpha=1.,\n",
    "#                      color=colors[j], label=gnames[j])\n",
    "\n",
    "#     kkk = xaxis.copy()\n",
    "#     kkk.sort()\n",
    "\n",
    "#     # xupperindex = np.min(np.where(np.sum(np.sum(np.sum(coeffs**2, axis = 1), axis = 1), axis = 1) ==0)[0])\n",
    "\n",
    "#     #for k in range(1 + q):\n",
    "#     ax.tick_params(labelsize=50)\n",
    "#     ax.set_xscale('symlog')\n",
    "#     ax.set_yscale('symlog')\n",
    "#     ax.set_ylim(bottom=0, top=normax)\n",
    "#     # axes[k].set_xlim(left = 0, right = xaxis[xupperindex])\n",
    "#     #if (k == 0):\n",
    "#     tixx = np.hstack(\n",
    "#         [np.asarray([0]), 10 ** np.linspace(math.floor(np.log10(normax)), math.floor(np.log10(normax)) + 1, 2)])\n",
    "# #    if k != 0:\n",
    "#         # axes[k].set_yticks(tixx)\n",
    "#     ax.set_ylabel(r\"$\\displaystyle \\|\\hat \\beta_{j}\\|_2$\", fontsize = 70)\n",
    "#     ax.set_xlabel(r\"$\\lambda  $\", fontsize = 70)#\\sqrt{nm}\n",
    "#     #ylabel = r\"$\\displaystyle \\|\\hat \\beta_{j}\\|_2$\"\n",
    "#     #ax.l\n",
    "#     #if k == 0:\n",
    "#     #ax.set_title(\"Combined\", fontdict={'fontsize': 50})\n",
    "#     ax.grid(True, which=\"both\", alpha=True)\n",
    "\n",
    "#     #handles, labels = ax.get_legend_handles_labels()\n",
    "#     #by_label = OrderedDict(zip(labels, handles))\n",
    "#     # fig.text(0.5, 0.04, xlabel, ha='center', va='center', fontsize=50)\n",
    "#     # fig.text(0.05, 0.5, ylabel, ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "#     #fig.subplots_adjust(right=0.75)\n",
    "#     #leg_ax = fig.add_axes([.8, 0.15, 0.05, 0.7])\n",
    "#     #leg_ax.axis('off')\n",
    "#     #leg = leg_ax.legend(by_label.values(), gnames, prop={'size': 200 / p})\n",
    "#     # leg.set_title('Torsion', prop={'size': Function})\n",
    "#     #for l in leg.get_lines():\n",
    "#     #    l.set_alpha(1)\n",
    "#     # fig.savefig(filename + 'beta_paths_n' + str(n) + 'nsel' + str(nsel) + 'nreps' + str(\n",
    "#     #    nreps))\n",
    "    \n",
    "\n",
    "def plot_reg_path_ax_lambdasearch_customcolors(axes, coeffs, xaxis,fig, colors):\n",
    "    p = coeffs.shape[3]\n",
    "    q = coeffs.shape[1]\n",
    "    gnames = np.asarray(list(range(p)), dtype=str)\n",
    "\n",
    "    # xlabel = r\"$\\displaystyle \\lambda$\"\n",
    "    # ylabel = r\"$\\displaystyle \\|\\hat \\beta_{j}\\|_2$\"\n",
    "    rcParams['axes.titlesize'] = 30\n",
    "    plt.rc('text', usetex=True)\n",
    "\n",
    "    # maxes = np.zeros(q)\n",
    "    # for k in range(q):\n",
    "    #     maxes[k] = np.linalg.norm(coeffs[:, k, :, :], axis=1).max()\n",
    "    # normax = maxes.max()\n",
    "    normax = np.sqrt(np.sum(np.sum(np.sum(coeffs ** 2, axis=1), axis=1), axis=1).max())\n",
    "\n",
    "    for k in range(q):\n",
    "        for j in range(p):\n",
    "            toplot = np.linalg.norm(coeffs[:, k, :, j], axis=1)\n",
    "            w = .15\n",
    "            widths = np.asarray([width(xaxis[i], w) for i in range(len(xaxis))])\n",
    "            # axes[k+1].boxplot(toplot, positions=xaxis, showfliers=False, vert=True, widths=widths,medianprops=dict(linestyle=''))\n",
    "            axes[k + 1].plot(xaxis, toplot, 'go--', linewidth=5, markersize=0, alpha=1.,\n",
    "                             color=colors[j], label=gnames[j])\n",
    "    for j in range(p):\n",
    "        toplot = np.linalg.norm(np.linalg.norm(coeffs[:, :, :, j], axis=2), axis=1)\n",
    "        # axes[0].boxplot(toplot, positions=xaxis, showfliers=False, vert=True, widths=widths,medianprops=dict(linestyle=''))\n",
    "        axes[0].plot(xaxis, toplot, 'go--', linewidth=5, markersize=0, alpha=1.,\n",
    "                     color=colors[j], label=gnames[j])\n",
    "\n",
    "    kkk = xaxis.copy()\n",
    "    kkk.sort()\n",
    "\n",
    "    # xupperindex = np.min(np.where(np.sum(np.sum(np.sum(coeffs**2, axis = 1), axis = 1), axis = 1) ==0)[0])\n",
    "\n",
    "    for k in range(1 + q):\n",
    "        axes[k].tick_params(labelsize=50)\n",
    "        axes[k].set_xscale('symlog')\n",
    "        axes[k].set_yscale('symlog')\n",
    "        axes[k].set_ylim(bottom=0, top=normax)\n",
    "        # axes[k].set_xlim(left = 0, right = xaxis[xupperindex])\n",
    "        if (k == 0):\n",
    "            tixx = np.hstack(\n",
    "                [np.asarray([0]), 10 ** np.linspace(math.floor(np.log10(normax)), math.floor(np.log10(normax)) + 1, 2)])\n",
    "        if k != 0:\n",
    "            # axes[k].set_yticks(tixx)\n",
    "            axes[k].set_yticklabels([])\n",
    "        if k != q:\n",
    "            axes[k+1].set_title(r\"$\\phi_{{{}}}$\".format(k+1), fontsize = 50)\n",
    "            #axes[k + 1].set_title(r\"$\\phi_{{{}}}$.format(k)\")\n",
    "        if k == 0:\n",
    "            axes[k].set_title(\"Combined\", fontdict={'fontsize': 50})\n",
    "    for k in range(1 + q):\n",
    "        axes[k].grid(True, which=\"both\", alpha=True)\n",
    "        axes[k].set_xlabel(r\"$\\lambda$\", fontsize = 50)\n",
    "        \n",
    "    axes[0].set_ylabel(r\"$\\|\\beta\\|$\", fontsize = 50)\n",
    "        \n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    by_label = OrderedDict(zip(labels, handles))\n",
    "    # fig.text(0.5, 0.04, xlabel, ha='center', va='center', fontsize=50)\n",
    "    # fig.text(0.05, 0.5, ylabel, ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "    fig.subplots_adjust(right=0.75)\n",
    "    leg_ax = fig.add_axes([.8, 0.15, 0.05, 0.7])\n",
    "    leg_ax.axis('off')\n",
    "    leg = leg_ax.legend(by_label.values(), gnames, prop={'size': 200 / p})\n",
    "    # leg.set_title('Torsion', prop={'size': Function})\n",
    "    for l in leg.get_lines():\n",
    "        l.set_alpha(1)\n",
    "    # fig.savefig(filename + 'beta_paths_n' + str(n) + 'nsel' + str(nsel) + 'nreps' + str(\n",
    "    #    nreps))\n",
    "\n",
    "\n",
    "    \n",
    "def get_grads(experiment, Mpca, Mangles, N, selected_points):\n",
    "    dimnoise = experiment.dimnoise\n",
    "    dim = experiment.dim\n",
    "    cores = experiment.cores\n",
    "\n",
    "    tangent_bases = Mpca.get_wlpca_tangent_sel(Mpca, selected_points, dimnoise)\n",
    "    subM = RiemannianManifold(Mpca.data[selected_points], dim)\n",
    "    subM.tb = TangentBundle(subM, tangent_bases)\n",
    "    N.tangent_bundle = TangentBundle(N, np.swapaxes(N.geom.rmetric.Hvv[:,:dim,:],1,2))\n",
    "\n",
    "    df_M = experiment.get_dF_js_idM(Mpca, N, subM.tb, N.tangent_bundle, selected_points, dimnoise)\n",
    "    df_M2 = df_M / np.sum(np.linalg.norm(df_M, axis=1) ** 2, axis=0)**(0.5)\n",
    "    dg_x = experiment.get_dx_g_full(Mangles.data[selected_points])\n",
    "\n",
    "    W = ShapeSpace(experiment.positions, Mangles.data)\n",
    "    dw = W.get_dw(cores, experiment.atoms3, experiment.natoms, selected_points)\n",
    "    dg_w = experiment.project(np.swapaxes(dw, 1, 2),\n",
    "                              experiment.project(dw, dg_x))\n",
    "\n",
    "    dg_w_pca = np.asarray([np.matmul(experiment.projector, dg_w[j].transpose()).transpose() for j in range(len(selected_points))])\n",
    "    dgw_norm = experiment.normalize(dg_w_pca)\n",
    "    dg_M = experiment.project(subM.tb.tangent_bases, dgw_norm)\n",
    "    return (df_M2, dg_M, dg_w, dg_w_pca, dgw_norm)\n",
    "\n",
    "#set parameters\n",
    "n = 10000 #number of data points to simulate\n",
    "nsel = 100 #number of points to analyze with lasso\n",
    "tol = 1e-14 #convergence criteria for lasso\n",
    "n_neighbors = 1000 #number of neighbors in megaman\n",
    "m = 3 #number of embedding dimensions (diffusion maps)\n",
    "diffusion_time = 0.05 #(yuchia suggestion)\n",
    "dim = 2 #manifold dimension\n",
    "dimnoise = 2\n",
    "natoms = 9\n",
    "cores = 3 #number of cores for parallel processing\n",
    "cor = 0.0 #correlation for noise\n",
    "var = 0.0001 #variance scaler for noise\n",
    "cor = 0.0 #correlation for noise\n",
    "var = 10. #variance scaler for noise\n",
    "ii = np.asarray([0,0,0,0,1,1,1,2]) # atom adjacencies for dihedral angle computation\n",
    "jj = np.asarray([1,2,3,4,5,6,7,8])\n",
    "\n",
    "#run experiment\n",
    "atoms4 = np.asarray([[6,1,0,4],[4,0,2,8],[7,6,5,1],[3,0,2,4]],dtype = int)\n",
    "nreps = 25\n",
    "lambda_max = 1\n",
    "max_search = 30\n",
    "\n",
    "folder = workingdirectory + '/Figures/rigidethanol/' + now + 'n' + str(n) + 'nsel' + str(nsel) + 'nreps' + str(nreps)\n",
    "os.mkdir(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from codes.experimentclasses.AtomicRegression import AtomicRegression\n",
    "from codes.geometer.RiemannianManifold import RiemannianManifold\n",
    "from codes.otherfunctions.data_stream import data_stream\n",
    "from codes.geometer.ShapeSpace import compute3angles\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "#this is for use with full dictionaries\n",
    "#all points are members of a different irrational field\n",
    "#in order to avoid set of measure zero\n",
    "#in the noiseless case\n",
    "from codes.experimentclasses.AtomicRegression import AtomicRegression\n",
    "from codes.geometer.RiemannianManifold import RiemannianManifold\n",
    "from codes.otherfunctions.data_stream import data_stream\n",
    "from codes.geometer.ShapeSpace import compute3angles\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "\n",
    "class RigidEthanolPCA2(AtomicRegression):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    cor : string,\n",
    "        Data file to load\n",
    "    xvar : np.array(dtype = int),\n",
    "        List of adjacencies\n",
    "    jj : np.array,\n",
    "        List of adjacencies part 2\n",
    "    d : int,\n",
    "        dimension over which to evaluate the radii (smaller usually better)\n",
    "    rmin : float,\n",
    "        smallest radius ( = rad_bw_ratio * bandwidth) to consider\n",
    "    rmax : float,\n",
    "        largest radius ( = rad_bw_ratio * bandwidth) to consider\n",
    "    ntry : int,\n",
    "        number of radii between rmax and rmin to try\n",
    "    run_parallel : bool,\n",
    "        whether to run the analysis in parallel over radii\n",
    "    search_space : str,\n",
    "        either 'linspace' or 'logspace', choose to search in log or linear space\n",
    "    rad_bw_ratio : float,\n",
    "        the ratio of radius and kernel bandwidth, default to be 3 (radius = 3*h)\n",
    "    Methods\n",
    "    -------\n",
    "    generate_data :\n",
    "        Simulates data\n",
    "    get_atoms_4 :\n",
    "    \tGets atomic tetrahedra based off of ii and jj\n",
    "    get_atoms_3 :\n",
    "    \tGets triples of atoms\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # AtomicRegression(dim, ii, jj, filename)\n",
    "    def __init__(self, dim, cor, xvar,ii,jj, cores, noise, custom_bonds = None):\n",
    "        natoms = 9\n",
    "        n = 10000\n",
    "        self.cor = cor\n",
    "        self.xvar = xvar\n",
    "        self.cores = cores\n",
    "        self.noise = noise\n",
    "        AtomicRegression.__init__(self, dim,n,ii,jj, natoms, cores)\n",
    "        if custom_bonds.any() != None:\n",
    "            self.atoms4 = custom_bonds\n",
    "            self.p = custom_bonds.shape[0]\n",
    "\n",
    "    def generate_data(self, noise=False):\n",
    "        \n",
    "        \n",
    "        n = self.n\n",
    "        d = self.d\n",
    "        cor = self.cor\n",
    "        xvar = self.xvar\n",
    "        natoms = self.natoms\n",
    "        cores = self.cores\n",
    "        atoms3 = self.atoms3\n",
    "        dim = self.dim\n",
    "        #noise = self.noise\n",
    "\n",
    "        positions = np.zeros((n, 9, 3))\n",
    "        # positions[0,0,:] = np.asarray([0.,0.,0.])\n",
    "        # positions[0,1,:] = np.asarray([-10.,0.,0.])\n",
    "        # positions[0,2,:] = np.asarray([1.,10.,0.])\n",
    "        # #positions[0,8,:] = np.asarray([1.,1.,0.])\n",
    "        # positions[0,8,:] = np.asarray([2.,10.,-0])\n",
    "        # positions[0,3,:] = np.asarray([1., np.cos(2/3 * np.pi), np.sin(2/3 * np.pi)])\n",
    "        # positions[0,4,:] = np.asarray([1., np.cos(2/3 * np.pi), np.sin(4/3 * np.pi)])\n",
    "        # positions[0,5,:] = np.asarray([-12.,1.,0.])\n",
    "        # positions[0,6,:] = np.asarray([-12., np.cos(2/3 * np.pi),np.sin(2/3 * np.pi)])\n",
    "        # positions[0,7,:] = np.asarray([-12.,np.cos(2/3 * np.pi), np.sin(4/3 * np.pi)])\n",
    "        positions[0,0,:] = np.asarray([0.,0.,0.])\n",
    "        positions[0,1,:] = np.asarray([-10.,0.,np.sqrt(2)/100])\n",
    "        positions[0,2,:] = np.asarray([0.,10.,np.sqrt(3)/100])\n",
    "        #positions[0,8,:] = np.asarray([1.,1.,0.])\n",
    "        positions[0,8,:] = np.asarray([1.,10.,np.sqrt(5)/100])\n",
    "        positions[0,3,:] = np.asarray([np.sqrt(7)/100, np.cos(2/3 * np.pi), np.sin(2/3 * np.pi)])\n",
    "        positions[0,4,:] = np.asarray([np.sqrt(11)/100, np.cos(2/3 * np.pi), np.sin(4/3 * np.pi)])\n",
    "        positions[0,5,:] = np.asarray([-11.,1.,np.sqrt(13)/100])\n",
    "        positions[0,6,:] = np.asarray([-11. , np.cos(2/3 * np.pi)+ np.sqrt(17)/1000,np.sin(2/3 * np.pi) ])\n",
    "        positions[0,7,:] = np.asarray([-11., np.cos(2/3 * np.pi)+ np.sqrt(19)/100, np.sin(4/3 * np.pi)])\n",
    "\n",
    "        angles1 = np.tile(np.linspace(start=0., stop=2 * math.pi, num=int(np.sqrt(n)), endpoint=False),\n",
    "                          int(np.sqrt(n)))\n",
    "        angles2 = np.repeat(np.linspace(start=0., stop=2 * math.pi, num=int(np.sqrt(n)), endpoint=False),\n",
    "                            int(np.sqrt(n)))\n",
    "        for i in range(1, n):\n",
    "            rotationmatrix1 = np.zeros((3, 3))\n",
    "            rotationmatrix1[1, 1] = 1\n",
    "            rotationmatrix1[0, 0] = np.cos(angles1[i])\n",
    "            rotationmatrix1[0, 2] = -np.sin(angles1[i])\n",
    "            rotationmatrix1[2, 2] = np.cos(angles1[i])\n",
    "            rotationmatrix1[2, 0] = np.sin(angles1[i])\n",
    "            rotationmatrix2 = np.zeros((3, 3))\n",
    "            rotationmatrix2[0, 0] = 1\n",
    "            rotationmatrix2[1, 1] = np.cos(angles2[i])\n",
    "            rotationmatrix2[1, 2] = -np.sin(angles2[i])\n",
    "            rotationmatrix2[2, 2] = np.cos(angles2[i])\n",
    "            rotationmatrix2[2, 1] = np.sin(angles2[i])\n",
    "            positions[i, np.asarray([3, 4]), :] = positions[0, np.asarray([3, 4]), :]\n",
    "            positions[i, np.asarray([2, 8]), :] = np.matmul(rotationmatrix1,\n",
    "                                                            positions[0, np.asarray([2, 8]),\n",
    "                                                            :].transpose()).transpose()\n",
    "            positions[i, np.asarray([1, 5, 6, 7]), :] = np.matmul(rotationmatrix2,\n",
    "                                                                  positions[0, np.asarray([1, 5, 6, 7]),\n",
    "                                                                  :].transpose()).transpose()\n",
    "\n",
    "        covariance = np.identity(natoms)\n",
    "        for i in range(natoms):\n",
    "            for j in range(natoms):\n",
    "                if i != j:\n",
    "                    covariance[i, j] = cor\n",
    "        covariance = xvar * covariance\n",
    "        print(covariance)\n",
    "        if noise == True:\n",
    "            for i in range(n):\n",
    "                for j in range(3):\n",
    "                    \n",
    "                    positions[i, :, j] = np.random.multivariate_normal(positions[i, :, j], covariance, size=1)\n",
    "        self.positions = positions\n",
    "        p = Pool(cores)\n",
    "        results = p.map(lambda i: compute3angles(position=positions[i[0], atoms3[i[1]], :]),\n",
    "                            data_stream(10000, 84))\n",
    "        data = np.reshape(results, (n, (d)))\n",
    "        svd = TruncatedSVD(n_components=50)\n",
    "        svd.fit(data)\n",
    "        data_pca = svd.transform(data)\n",
    "        return (RiemannianManifold(data, dim), RiemannianManifold(data_pca,dim), svd.components_)\n",
    "    \n",
    "def plot_watch_custom(to_plot, p, ax,colors):\n",
    "    #fig, ax = plt.subplots(figsize = (15,15))\n",
    "    #%matplotlib inline\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize = (15,15))\n",
    "    theta = np.linspace(0, 2*np.pi, 10000)\n",
    "    cmap = plt.get_cmap('twilight_shifted',p)\n",
    "    \n",
    "    angles = np.linspace(0, 2*np.pi, p+1)\n",
    "    \n",
    "    radius = 1.\n",
    "\n",
    "    a = radius*np.cos(theta)\n",
    "    b = radius*np.sin(theta)\n",
    "\n",
    "    #figure, axes = plt.subplots(figsize = (15,15))\n",
    "\n",
    "    #axes.plot(a, b, color= 'gray')\n",
    "    ax.scatter(a, b, color = 'gray', s= .2, alpha = .1)#, '-', color = 'gray')#, s= .1, alpha = .1)#, type = 'line')#,cmap=plt.get_cmap('twilight')) #'hsv','twilight_shifted\n",
    "\n",
    "    #for i in range(to_plot.shape)\n",
    "    if len(to_plot.shape) > 1:\n",
    "        totes = np.sum(to_plot, axis = 0)\n",
    "    else:\n",
    "        totes = to_plot\n",
    "        \n",
    "    for j in range(p):\n",
    "        print(np.cos(angles[j]), np.sin(angles[j]))#r'$test \\frac{1}{}$'.format(g)\n",
    "        ax.scatter(np.cos(angles[j]),np.sin(angles[j]),color=cmap.colors[j], marker  = 'x')\n",
    "        ax.text( x = 1.1*np.cos(angles[j]),\n",
    "                  y = 1.1*np.sin(angles[j]),\n",
    "                  s = r\"$g_{{{}}}$\".format(j),color=colors[j],#cmap.colors[j],\n",
    "                  fontdict = {'fontsize' : 70},\n",
    "                  horizontalalignment='center',\n",
    "         verticalalignment='center')\n",
    "\n",
    "\n",
    "\n",
    "        ax.text( x = .9*np.cos(angles[j]),y = .9*np.sin(angles[j]),s = str(totes[j] / nreps), fontdict = {'fontsize' : 40},\n",
    "                  horizontalalignment='center',\n",
    "         verticalalignment='center')\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(p):\n",
    "        ax.scatter(np.cos(angles[j]),np.sin(angles[j]),color=colors[j], marker  = 'o', s = 200*totes[j] )\n",
    "\n",
    "    if len(to_plot.shape) > 1:\n",
    "        for i in range(p):\n",
    "            for j in range(p):\n",
    "\n",
    "                #point1 = [1, 2]\n",
    "                #point2 = [3, 4]\n",
    "\n",
    "                x_values = [np.cos(angles[j]), np.cos(angles[i])]\n",
    "                #gather x-values\n",
    "\n",
    "                y_values = [np.sin(angles[j]), np.sin(angles[i])]\n",
    "                #gather y-values\n",
    "\n",
    "                ax.plot(x_values, y_values,linewidth = to_plot[i,j], color = 'black')\n",
    "\n",
    "                if to_plot[i,j] > 0 :\n",
    "                    ax.text( x = np.mean(x_values),\n",
    "                      y = np.mean(y_values),\n",
    "                      s = str(to_plot[i,j] / nreps),\n",
    "                      fontdict = {'fontsize' : 40})#,\n",
    "                  #horizontalalignment='left',\n",
    "                # verticalalignment='bottom')\n",
    "\n",
    "                #axes.axline((x1, y1), (x2, y2))\n",
    "    ax.set_aspect(1)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(r\"$\\omega = 25$\")\n",
    "    \n",
    "def plot_cosines(cosines, ax, colors):\n",
    "    p = cosines.shape[0]\n",
    "    sns.heatmap(cosines ,ax = ax, vmin = 0., vmax = 1.)\n",
    "#    ax = sns.heatmap(x, cmap=cmap)\n",
    "    # use matplotlib.colorbar.Colorbar object\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    # here set the labelsize by 20\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "    for xtick, color in zip(ax.get_xticklabels(), colors):\n",
    "        xtick.set_color(color)\n",
    "    for ytick, color in zip(ax.get_yticklabels(), colors):\n",
    "        ytick.set_color(color)\n",
    "    ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 500 / p)\n",
    "    ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 500 / p)\n",
    "    \n",
    "    ax.set_ylabel(r\"$g_{j'}$\", fontsize = 70)\n",
    "    ax.set_xlabel(r\"$g_{j}$\", fontsize = 70)\n",
    "    #ax.set_title(r\"$\\text{hi}$\")\n",
    "    ax.set_title(r\"$\\frac{1}{n'} \\sum_{i = 1}^{n'} \\frac{\\langle grad_{\\mathcal M} g_j (\\xi_i) ,grad_{\\mathcal M} g_{j'} (\\xi_i)\\rangle}{\\|grad_{\\mathcal M} g_j (\\xi_i) \\|_2 \\| grad_{\\mathcal M} g_{j'}(\\xi_i) \\|_2} $\",\n",
    "                fontsize = 70)\n",
    "\n",
    "# def plot_reg_path_ax_lambdasearch_customcolors_norm(ax, coeffs, xaxis,fig, colors):\n",
    "#     p = coeffs.shape[3]\n",
    "#     q = coeffs.shape[1]\n",
    "#     gnames = np.asarray(list(range(p)), dtype=str)\n",
    "\n",
    "#     rcParams['axes.titlesize'] = 30\n",
    "#     plt.rc('text', usetex=True)\n",
    "\n",
    "#     normax = np.sqrt(np.sum(np.sum(np.sum(coeffs ** 2, axis=1), axis=1), axis=1).max())\n",
    "\n",
    "#     for j in range(p):\n",
    "#         toplot = np.linalg.norm(np.linalg.norm(coeffs[:, :, :, j], axis=2), axis=1)\n",
    "#         # axes[0].boxplot(toplot, positions=xaxis, showfliers=False, vert=True, widths=widths,medianprops=dict(linestyle=''))\n",
    "#         ax.plot(xaxis, toplot, 'go--', linewidth=5, markersize=0, alpha=1.,\n",
    "#                      color=colors[j], label=gnames[j])\n",
    "\n",
    "#     kkk = xaxis.copy()\n",
    "#     kkk.sort()\n",
    "\n",
    "#     # xupperindex = np.min(np.where(np.sum(np.sum(np.sum(coeffs**2, axis = 1), axis = 1), axis = 1) ==0)[0])\n",
    "\n",
    "#     #for k in range(1 + q):\n",
    "#     ax.tick_params(labelsize=50)\n",
    "#     ax.set_xscale('symlog')\n",
    "#     ax.set_yscale('symlog')\n",
    "#     ax.set_ylim(bottom=0, top=normax)\n",
    "#     # axes[k].set_xlim(left = 0, right = xaxis[xupperindex])\n",
    "#     #if (k == 0):\n",
    "#     tixx = np.hstack(\n",
    "#         [np.asarray([0]), 10 ** np.linspace(math.floor(np.log10(normax)), math.floor(np.log10(normax)) + 1, 2)])\n",
    "# #    if k != 0:\n",
    "#         # axes[k].set_yticks(tixx)\n",
    "#     ax.set_ylabel(r\"$\\displaystyle \\|\\hat \\beta_{j}\\|_2$\", fontsize = 70)\n",
    "#     ax.set_xlabel(r\"$\\lambda  $\", fontsize = 70)#\\sqrt{nm}\n",
    "#     #ylabel = r\"$\\displaystyle \\|\\hat \\beta_{j}\\|_2$\"\n",
    "#     #ax.l\n",
    "#     #if k == 0:\n",
    "#     #ax.set_title(\"Combined\", fontdict={'fontsize': 50})\n",
    "#     ax.grid(True, which=\"both\", alpha=True)\n",
    "\n",
    "#     #handles, labels = ax.get_legend_handles_labels()\n",
    "#     #by_label = OrderedDict(zip(labels, handles))\n",
    "#     # fig.text(0.5, 0.04, xlabel, ha='center', va='center', fontsize=50)\n",
    "#     # fig.text(0.05, 0.5, ylabel, ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "#     #fig.subplots_adjust(right=0.75)\n",
    "#     #leg_ax = fig.add_axes([.8, 0.15, 0.05, 0.7])\n",
    "#     #leg_ax.axis('off')\n",
    "#     #leg = leg_ax.legend(by_label.values(), gnames, prop={'size': 200 / p})\n",
    "#     # leg.set_title('Torsion', prop={'size': Function})\n",
    "#     #for l in leg.get_lines():\n",
    "#     #    l.set_alpha(1)\n",
    "#     # fig.savefig(filename + 'beta_paths_n' + str(n) + 'nsel' + str(nsel) + 'nreps' + str(\n",
    "#     #    nreps))\n",
    "    \n",
    "\n",
    "def plot_reg_path_ax_lambdasearch_customcolors(axes, coeffs, xaxis,fig, colors):\n",
    "    p = coeffs.shape[3]\n",
    "    q = coeffs.shape[1]\n",
    "    gnames = np.asarray(list(range(p)), dtype=str)\n",
    "\n",
    "    # xlabel = r\"$\\displaystyle \\lambda$\"\n",
    "    # ylabel = r\"$\\displaystyle \\|\\hat \\beta_{j}\\|_2$\"\n",
    "    rcParams['axes.titlesize'] = 30\n",
    "    plt.rc('text', usetex=True)\n",
    "\n",
    "    # maxes = np.zeros(q)\n",
    "    # for k in range(q):\n",
    "    #     maxes[k] = np.linalg.norm(coeffs[:, k, :, :], axis=1).max()\n",
    "    # normax = maxes.max()\n",
    "    normax = np.sqrt(np.sum(np.sum(np.sum(coeffs ** 2, axis=1), axis=1), axis=1).max())\n",
    "\n",
    "    for k in range(q):\n",
    "        for j in range(p):\n",
    "            toplot = np.linalg.norm(coeffs[:, k, :, j], axis=1)\n",
    "            w = .15\n",
    "            widths = np.asarray([width(xaxis[i], w) for i in range(len(xaxis))])\n",
    "            # axes[k+1].boxplot(toplot, positions=xaxis, showfliers=False, vert=True, widths=widths,medianprops=dict(linestyle=''))\n",
    "            axes[k + 1].plot(xaxis, toplot, 'go--', linewidth=5, markersize=0, alpha=1.,\n",
    "                             color=colors[j], label=gnames[j])\n",
    "    for j in range(p):\n",
    "        toplot = np.linalg.norm(np.linalg.norm(coeffs[:, :, :, j], axis=2), axis=1)\n",
    "        # axes[0].boxplot(toplot, positions=xaxis, showfliers=False, vert=True, widths=widths,medianprops=dict(linestyle=''))\n",
    "        axes[0].plot(xaxis, toplot, 'go--', linewidth=5, markersize=0, alpha=1.,\n",
    "                     color=colors[j], label=gnames[j])\n",
    "\n",
    "    kkk = xaxis.copy()\n",
    "    kkk.sort()\n",
    "\n",
    "    # xupperindex = np.min(np.where(np.sum(np.sum(np.sum(coeffs**2, axis = 1), axis = 1), axis = 1) ==0)[0])\n",
    "\n",
    "    for k in range(1 + q):\n",
    "        axes[k].tick_params(labelsize=50)\n",
    "        axes[k].set_xscale('symlog')\n",
    "        axes[k].set_yscale('symlog')\n",
    "        axes[k].set_ylim(bottom=0, top=normax)\n",
    "        # axes[k].set_xlim(left = 0, right = xaxis[xupperindex])\n",
    "        if (k == 0):\n",
    "            tixx = np.hstack(\n",
    "                [np.asarray([0]), 10 ** np.linspace(math.floor(np.log10(normax)), math.floor(np.log10(normax)) + 1, 2)])\n",
    "        if k != 0:\n",
    "            # axes[k].set_yticks(tixx)\n",
    "            axes[k].set_yticklabels([])\n",
    "        if k != q:\n",
    "            axes[k+1].set_title(r\"$\\phi_{{{}}}$\".format(k+1), fontsize = 50)\n",
    "            #axes[k + 1].set_title(r\"$\\phi_{{{}}}$.format(k)\")\n",
    "        if k == 0:\n",
    "            axes[k].set_title(\"Combined\", fontdict={'fontsize': 50})\n",
    "    for k in range(1 + q):\n",
    "        axes[k].grid(True, which=\"both\", alpha=True)\n",
    "        axes[k].set_xlabel(r\"$\\lambda$\", fontsize = 50)\n",
    "        \n",
    "    axes[0].set_ylabel(r\"$\\|\\beta\\|$\", fontsize = 50)\n",
    "        \n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    by_label = OrderedDict(zip(labels, handles))\n",
    "    # fig.text(0.5, 0.04, xlabel, ha='center', va='center', fontsize=50)\n",
    "    # fig.text(0.05, 0.5, ylabel, ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "    fig.subplots_adjust(right=0.75)\n",
    "    leg_ax = fig.add_axes([.8, 0.15, 0.05, 0.7])\n",
    "    leg_ax.axis('off')\n",
    "    leg = leg_ax.legend(by_label.values(), gnames, prop={'size': 200 / p})\n",
    "    # leg.set_title('Torsion', prop={'size': Function})\n",
    "    for l in leg.get_lines():\n",
    "        l.set_alpha(1)\n",
    "    # fig.savefig(filename + 'beta_paths_n' + str(n) + 'nsel' + str(nsel) + 'nreps' + str(\n",
    "    #    nreps))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.e-06 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 1.e-06 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 1.e-06 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 1.e-06 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 1.e-06 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 1.e-06 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 1.e-06 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 1.e-06 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 1.e-06]]\n"
     ]
    }
   ],
   "source": [
    "new_MN = True\n",
    "new_grad = True\n",
    "savename = 'rigidethanol_jmlrresub'\n",
    "savefolder = 'rigidethanol'\n",
    "loadfolder = 'rigidethanol'\n",
    "loadname = 'rigidethanol_jmlrresub'\n",
    "var = 0.000001#var = 0.01 breaks\n",
    "if new_MN == True:\n",
    "    experiment = RigidEthanolPCA2(dim, cor, var, ii, jj, cores, True, atoms4)\n",
    "    experiment.M, experiment.Mpca, projector = experiment.generate_data(noise=True)\n",
    "    experiment.q = m\n",
    "    experiment.m = m\n",
    "    experiment.dimnoise = dimnoise\n",
    "    experiment.projector = projector\n",
    "    experiment.Mpca.geom = experiment.Mpca.compute_geom(diffusion_time, n_neighbors)\n",
    "    experiment.N = experiment.Mpca.get_embedding3(experiment.Mpca.geom, m, diffusion_time, dim)\n",
    "    # with open(workingdirectory + '/untracked_data/embeddings/' + savefolder + '/' + savename + '.pkl' ,\n",
    "    #          'wb') as output:\n",
    "    #      pickle.dump(experiment, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "atoms4,p = get_atoms_4(natoms,ii,jj)\n",
    "experiment.p = p\n",
    "experiment.atoms4 = atoms4\n",
    "#experiment.itermax = itermax\n",
    "experiment.tol = tol\n",
    "experiment.dnoise = dim\n",
    "experiment.nreps = nreps\n",
    "experiment.nsel = nsel\n",
    "experiment.folder = folder\n",
    "\n",
    "replicates = {}\n",
    "selected_points_save = np.zeros((nreps,nsel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-gradient acquisition\n",
      "2021-02-05 11:31:52.879091\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('pre-gradient acquisition')\n",
    "print(datetime.datetime.now())\n",
    "for i in range(1):#nreps):\n",
    "    print(i)\n",
    "    selected_points = np.random.choice(list(range(n)),nsel,replace = False)\n",
    "    selected_points_save[i] = selected_points\n",
    "    replicates[i] = Replicate()\n",
    "    replicates[i].nsel = nsel\n",
    "    replicates[i].selected_points = selected_points\n",
    "    replicates[i].df_M,replicates[i].dg_M,replicates[i].dg_w ,replicates[i].dg_w_pca ,replicates[i].dgw_norm  = get_grads(experiment, experiment.Mpca, experiment.M, experiment.N, selected_points)\n",
    "    replicates[i].dg_M = np.swapaxes(replicates[i].dg_M, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-gradient descent\n",
      "2021-02-05 11:32:11.579705\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "savename = 'rigidethanol_010521_p12rep5n500_papernorm_noise_p0001'\n",
    "savefolder = 'rigidethanol'\n",
    "loadfolder = 'rigidethanol'\n",
    "loadname = 'rigidethanol_010521_p12rep5n500_papernorm_noise_p0001'\n",
    "\n",
    "# with open(workingdirectory + '/untracked_data/embeddings/' + savefolder + '/' + savename + 'replicates.pkl' ,\n",
    "#          'wb') as output:\n",
    "#      pickle.dump(replicates, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "selected_points_save = np.asarray(selected_points_save, dtype = int)\n",
    "gl_itermax = 500\n",
    "lambdas_start = [0.,.0005 * np.sqrt(nsel * p)]\n",
    "max_search = 30\n",
    "reg_l2 = 0.\n",
    "card = dim\n",
    "tol = 1e-14\n",
    "learning_rate = 100\n",
    "\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "#from codes.flasso.GradientGroupLasso import batch_stream, get_sr_lambda_sam_parallel\n",
    "\n",
    "print('pre-gradient descent')\n",
    "print(datetime.datetime.now())\n",
    "cores = 16\n",
    "# pcor = Pool(cores)\n",
    "# results = pcor.map(lambda replicate: get_sr_lambda_sam_parallel(replicate, gl_itermax, lambdas_start,reg_l2, max_search, card, tol,learning_rate), batch_stream(replicates))\n",
    "\n",
    "results = {}\n",
    "for r in range(nreps):#nreps):\n",
    "    print(r)\n",
    "    results[r] = Replicate()\n",
    "    #results[r] = get_sr_lambda_sam_parallel(replicates[r], gl_itermax, lambdas_start,reg_l2, max_search, card, tol,learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.5731865294897025"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 0 \n",
    "np.linalg.norm(np.einsum('n d m, n d p -> n p m ' ,replicates[r].df_M , replicates[r].dg_M), axis = tuple([0,2])).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "lr 0.5\n",
      "lr 0.25\n",
      "lr 0.125\n",
      "lr 0.0625\n",
      "lr 0.03125\n",
      "1\n",
      "lr 0.03125\n",
      "2\n",
      "lr 0.03125\n",
      "converged 7.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max over n\n",
    "r = 0 \n",
    "GGL = GradientGroupLasso(replicates[r].dg_M, replicates[r].df_M, np.asarray([7.58]), np.asarray([0.]), 500,.5, 1e-14, beta0_npm= None)\n",
    "GGL.fit()\n",
    "np.linalg.norm(GGL.fit_[0]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#repeat the covariate matrx m times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r = 0 \n",
    "# GGL = GradientGroupLasso(replicates[r].dg_M[:1], replicates[r].df_M[:1], np.asarray([.8655]), np.asarray([0.]), 500,.5, 1e-14, beta0_npm= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00494647,  0.01348774, -0.1578278 ]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[r].df_M[:1][:,:1,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.00522825, -0.01425607,  0.16681853]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[r].df_M[:1][:,:1,:3] * replicates[r].dg_M[:1][:,:1][:,:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.einsum('n d m, n d p -> p' ,replicates[r].df_M[:2][:,:1,:1] , replicates[r].dg_M[:2][:,:1][:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b= np.einsum('n d m, n d p -> p' ,replicates[r].df_M[1:2][:,:1,:1] , replicates[r].dg_M[1:2][:,:1][:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c= np.einsum('n d m, n d p -> p' ,replicates[r].df_M[0:1][:,:1,:1] , replicates[r].dg_M[0:1][:,:1][:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17835414])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b #this is the 0:2 lambda !!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.00522825]],\n",
       "\n",
       "       [[-0.17835414]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('n d m, n d p -> n p m ' ,replicates[r].df_M[:2][:,:1,:1] , replicates[r].dg_M[:2][:,:1][:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.00522825, -0.01425607,  0.16681853]],\n",
       "\n",
       "       [[-0.17835414, -0.05975958, -0.23167237]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('n d m, n d p -> n p m ' ,replicates[r].df_M[:2][:,:1,:3] , replicates[r].dg_M[:2][:,:1][:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17843075366427757"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm([-0.00522825,-0.17835414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34221701638579616"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.einsum('n d m, n d p -> n p m ' ,replicates[r].df_M[:2][:,:1,:3] , replicates[r].dg_M[:2][:,:1][:,:,:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "lr 0.5\n",
      "lr 0.25\n",
      "lr 0.125\n",
      "1\n",
      "lr 0.125\n",
      "2\n",
      "lr 0.125\n",
      "3\n",
      "lr 0.125\n",
      "4\n",
      "lr 0.125\n",
      "5\n",
      "lr 0.125\n",
      "6\n",
      "lr 0.125\n",
      "7\n",
      "lr 0.125\n",
      "converged 0.3423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max over n\n",
    "r = 0 \n",
    "GGL = GradientGroupLasso(replicates[r].dg_M[:2][:,:1][:,:,:1], replicates[r].df_M[:2][:,:1,:3], np.asarray([.3423]), np.asarray([0.]), 500,.5, 1e-14, beta0_npm= None)\n",
    "GGL.fit()\n",
    "np.linalg.norm(GGL.fit_[0]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34221701638579616"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.einsum('n d m, n d p -> n p m ' ,replicates[r].df_M[:2][:,:1,:3] , replicates[r].dg_M[:2][:,:1][:,:,:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30578416710841466"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.einsum('n d m, n d p -> n p m ' ,replicates[r].df_M[:2][:,:1,:3] , replicates[r].dg_M[:2][:,:1][:,:,1:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34221702, 0.30578417, 0.30809189, 0.30619914, 0.2774736 ])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.einsum('n d m, n d p -> n p m ' ,replicates[r].df_M[:2][:,:1,:3] , replicates[r].dg_M[:2][:,:1][:,:,:5]), axis = tuple([0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "lr 0.5\n",
      "lr 0.25\n",
      "lr 0.125\n",
      "lr 0.0625\n",
      "1\n",
      "lr 0.0625\n",
      "2\n",
      "lr 0.0625\n",
      "3\n",
      "lr 0.0625\n",
      "4\n",
      "lr 0.0625\n",
      "5\n",
      "lr 0.0625\n",
      "6\n",
      "lr 0.0625\n",
      "7\n",
      "lr 0.0625\n",
      "8\n",
      "lr 0.0625\n",
      "9\n",
      "lr 0.0625\n",
      "converged 0.343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max over n\n",
    "r = 0 \n",
    "GGL = GradientGroupLasso(replicates[r].dg_M[:2][:,:1][:,:,:2], replicates[r].df_M[:2][:,:1,:3], np.asarray([.343]), np.asarray([0.]), 500,.5, 1e-14, beta0_npm= None)\n",
    "GGL.fit()\n",
    "np.linalg.norm(GGL.fit_[0]['beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective function is\n",
    "\\begin{eqnarray*}\n",
    "\\| y_{ik} - \\sum_j \\beta_{ijk} x_{ij} \\|_2^2 = \\lambda \\sum_j  \\| \\beta_{ijk} \\|_2^2 \\\\\n",
    "\\nabla_{\\beta = 0} \\| y_{ik} - \\sum_j \\beta_{ijk} x_{ij} \\|_2^2 = y_{ik} x_{ij}\\\\\n",
    "y_{ik} x_{ij} = \\lambda\n",
    "\\end{eqnarray*}\n",
    "\n",
    "The maximum lambda value is \n",
    "\\begin{eqnarray*}\n",
    "\\lambda_{max} = \\max_j \\| y_{ik}^T x_{ij} \\|_2\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1835823835313286"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1.05696544 * 0.00494647 + 2.62957466*-0.06782623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.05696544]],\n",
       "\n",
       "       [[ 2.62957466]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[r].dg_M[:2][:,:1][:,:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00494647]],\n",
       "\n",
       "       [[-0.06782623]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[r].df_M[:2][:,:1,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#both are improved by moving in the same direction.... larger lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "lr 0.5\n",
      "lr 0.25\n",
      "lr 0.125\n",
      "lr 0.0625\n",
      "lr 0.03125\n",
      "1\n",
      "lr 0.03125\n",
      "2\n",
      "lr 0.03125\n",
      "3\n",
      "lr 0.03125\n",
      "4\n",
      "lr 0.03125\n",
      "5\n",
      "lr 0.03125\n",
      "6\n",
      "lr 0.03125\n",
      "7\n",
      "lr 0.03125\n",
      "8\n",
      "lr 0.03125\n",
      "9\n",
      "lr 0.03125\n",
      "10\n",
      "lr 0.03125\n",
      "11\n",
      "lr 0.03125\n",
      "12\n",
      "lr 0.03125\n",
      "13\n",
      "lr 0.03125\n",
      "14\n",
      "lr 0.03125\n",
      "15\n",
      "lr 0.03125\n",
      "16\n",
      "lr 0.03125\n",
      "17\n",
      "lr 0.03125\n",
      "18\n",
      "lr 0.03125\n",
      "19\n",
      "lr 0.03125\n",
      "converged 0.178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3461122002021633e-05"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 0 \n",
    "GGL = GradientGroupLasso(replicates[r].dg_M[:2][:,:1][:,:,:3], replicates[r].df_M[:2][:,:1,:1], np.asarray([.178]), np.asarray([0.]), 500,.5, 1e-14, beta0_npm= None)\n",
    "GGL.fit()\n",
    "np.linalg.norm(GGL.fit_[0]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "lr 0.5\n",
      "lr 0.25\n",
      "lr 0.125\n",
      "1\n",
      "lr 0.125\n",
      "2\n",
      "lr 0.125\n",
      "3\n",
      "lr 0.125\n",
      "4\n",
      "lr 0.125\n",
      "5\n",
      "lr 0.125\n",
      "6\n",
      "lr 0.125\n",
      "7\n",
      "lr 0.125\n",
      "8\n",
      "lr 0.125\n",
      "9\n",
      "lr 0.125\n",
      "10\n",
      "lr 0.125\n",
      "11\n",
      "lr 0.125\n",
      "converged 0.1785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 0 \n",
    "GGL = GradientGroupLasso(replicates[r].dg_M[:2][:,:1][:,:,:1], replicates[r].df_M[:2][:,:1,:1], np.asarray([.1785]), np.asarray([0.]), 2000,.5, 1e-14, beta0_npm= None)\n",
    "GGL.fit()\n",
    "np.linalg.norm(GGL.fit_[0]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "lr 0.5\n",
      "lr 0.25\n",
      "1\n",
      "lr 0.25\n",
      "2\n",
      "lr 0.25\n",
      "3\n",
      "lr 0.25\n",
      "4\n",
      "lr 0.25\n",
      "5\n",
      "lr 0.25\n",
      "6\n",
      "lr 0.25\n",
      "7\n",
      "lr 0.25\n",
      "8\n",
      "lr 0.25\n",
      "9\n",
      "lr 0.25\n",
      "10\n",
      "lr 0.25\n",
      "11\n",
      "lr 0.25\n",
      "12\n",
      "lr 0.25\n",
      "13\n",
      "lr 0.25\n",
      "14\n",
      "lr 0.25\n",
      "15\n",
      "lr 0.25\n",
      "16\n",
      "lr 0.25\n",
      "17\n",
      "lr 0.25\n",
      "18\n",
      "lr 0.25\n",
      "19\n",
      "lr 0.25\n",
      "20\n",
      "lr 0.25\n",
      "21\n",
      "lr 0.25\n",
      "22\n",
      "lr 0.25\n",
      "23\n",
      "lr 0.25\n",
      "converged 0.00522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0615798366366376e-06"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 0 \n",
    "GGL = GradientGroupLasso(replicates[r].dg_M[:1][:,:1][:,:,:3], replicates[r].df_M[:1][:,:1,:1], np.asarray([.00522]), np.asarray([0.]), 500,.5, 1e-14, beta0_npm= None)\n",
    "GGL.fit()\n",
    "np.linalg.norm(GGL.fit_[0]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "lr 0.5\n",
      "1\n",
      "lr 0.5\n",
      "2\n",
      "lr 0.5\n",
      "3\n",
      "lr 0.5\n",
      "4\n",
      "lr 0.5\n",
      "5\n",
      "lr 0.5\n",
      "lr 0.25\n",
      "6\n",
      "lr 0.25\n",
      "7\n",
      "lr 0.25\n",
      "8\n",
      "lr 0.25\n",
      "9\n",
      "lr 0.25\n",
      "10\n",
      "lr 0.25\n",
      "11\n",
      "lr 0.25\n",
      "12\n",
      "lr 0.25\n",
      "13\n",
      "lr 0.25\n",
      "14\n",
      "lr 0.25\n",
      "15\n",
      "lr 0.25\n",
      "16\n",
      "lr 0.25\n",
      "17\n",
      "lr 0.25\n",
      "18\n",
      "lr 0.25\n",
      "19\n",
      "lr 0.25\n",
      "20\n",
      "lr 0.25\n",
      "21\n",
      "lr 0.25\n",
      "22\n",
      "lr 0.25\n",
      "23\n",
      "lr 0.25\n",
      "24\n",
      "lr 0.25\n",
      "25\n",
      "lr 0.25\n",
      "26\n",
      "lr 0.25\n",
      "27\n",
      "lr 0.25\n",
      "28\n",
      "lr 0.25\n",
      "29\n",
      "lr 0.25\n",
      "30\n",
      "lr 0.25\n",
      "31\n",
      "lr 0.25\n",
      "32\n",
      "lr 0.25\n",
      "33\n",
      "lr 0.25\n",
      "34\n",
      "lr 0.25\n",
      "35\n",
      "lr 0.25\n",
      "36\n",
      "lr 0.25\n",
      "37\n",
      "lr 0.25\n",
      "38\n",
      "lr 0.25\n",
      "39\n",
      "lr 0.25\n",
      "40\n",
      "lr 0.25\n",
      "41\n",
      "lr 0.25\n",
      "42\n",
      "lr 0.25\n",
      "43\n",
      "lr 0.25\n",
      "44\n",
      "lr 0.25\n",
      "45\n",
      "lr 0.25\n",
      "46\n",
      "lr 0.25\n",
      "47\n",
      "lr 0.25\n",
      "48\n",
      "lr 0.25\n",
      "49\n",
      "lr 0.25\n",
      "50\n",
      "lr 0.25\n",
      "51\n",
      "lr 0.25\n",
      "52\n",
      "lr 0.25\n",
      "53\n",
      "lr 0.25\n",
      "54\n",
      "lr 0.25\n",
      "55\n",
      "lr 0.25\n",
      "56\n",
      "lr 0.25\n",
      "57\n",
      "lr 0.25\n",
      "58\n",
      "lr 0.25\n",
      "59\n",
      "lr 0.25\n",
      "60\n",
      "lr 0.25\n",
      "61\n",
      "lr 0.25\n",
      "62\n",
      "lr 0.25\n",
      "63\n",
      "lr 0.25\n",
      "64\n",
      "lr 0.25\n",
      "65\n",
      "lr 0.25\n",
      "66\n",
      "lr 0.25\n",
      "67\n",
      "lr 0.25\n",
      "68\n",
      "lr 0.25\n",
      "69\n",
      "lr 0.25\n",
      "70\n",
      "lr 0.25\n",
      "71\n",
      "lr 0.25\n",
      "72\n",
      "lr 0.25\n",
      "73\n",
      "lr 0.25\n",
      "74\n",
      "lr 0.25\n",
      "75\n",
      "lr 0.25\n",
      "76\n",
      "lr 0.25\n",
      "77\n",
      "lr 0.25\n",
      "78\n",
      "lr 0.25\n",
      "79\n",
      "lr 0.25\n",
      "80\n",
      "lr 0.25\n",
      "81\n",
      "lr 0.25\n",
      "82\n",
      "lr 0.25\n",
      "83\n",
      "lr 0.25\n",
      "84\n",
      "lr 0.25\n",
      "85\n",
      "lr 0.25\n",
      "86\n",
      "lr 0.25\n",
      "87\n",
      "lr 0.25\n",
      "88\n",
      "lr 0.25\n",
      "89\n",
      "lr 0.25\n",
      "90\n",
      "lr 0.25\n",
      "91\n",
      "lr 0.25\n",
      "92\n",
      "lr 0.25\n",
      "93\n",
      "lr 0.25\n",
      "94\n",
      "lr 0.25\n",
      "95\n",
      "lr 0.25\n",
      "96\n",
      "lr 0.25\n",
      "97\n",
      "lr 0.25\n",
      "98\n",
      "lr 0.25\n",
      "99\n",
      "lr 0.25\n",
      "100\n",
      "lr 0.25\n",
      "101\n",
      "lr 0.25\n",
      "102\n",
      "lr 0.25\n",
      "103\n",
      "lr 0.25\n",
      "104\n",
      "lr 0.25\n",
      "105\n",
      "lr 0.25\n",
      "106\n",
      "lr 0.25\n",
      "107\n",
      "lr 0.25\n",
      "converged 0.00523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 0 \n",
    "GGL = GradientGroupLasso(replicates[r].dg_M[:1][:,:1][:,:,:3], replicates[r].df_M[:1][:,:1,:1], np.asarray([.00523]), np.asarray([0.]), 500,.5, 1e-14, beta0_npm= None)\n",
    "GGL.fit()\n",
    "np.linalg.norm(GGL.fit_[0]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#m makes a difference... p may not make a difference, depends on max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "lr 0.5\n",
      "lr 0.25\n",
      "lr 0.125\n",
      "lr 0.0625\n",
      "lr 0.03125\n",
      "1\n",
      "lr 0.03125\n",
      "2\n",
      "lr 0.03125\n",
      "3\n",
      "lr 0.03125\n",
      "4\n",
      "lr 0.03125\n",
      "5\n",
      "lr 0.03125\n",
      "6\n",
      "lr 0.03125\n",
      "7\n",
      "lr 0.03125\n",
      "8\n",
      "lr 0.03125\n",
      "9\n",
      "lr 0.03125\n",
      "10\n",
      "lr 0.03125\n",
      "11\n",
      "lr 0.03125\n",
      "12\n",
      "lr 0.03125\n",
      "13\n",
      "lr 0.03125\n",
      "14\n",
      "lr 0.03125\n",
      "15\n",
      "lr 0.03125\n",
      "16\n",
      "lr 0.03125\n",
      "17\n",
      "lr 0.03125\n",
      "18\n",
      "lr 0.03125\n",
      "19\n",
      "lr 0.03125\n",
      "20\n",
      "lr 0.03125\n",
      "21\n",
      "lr 0.03125\n",
      "22\n",
      "lr 0.03125\n",
      "23\n",
      "lr 0.03125\n",
      "24\n",
      "lr 0.03125\n",
      "25\n",
      "lr 0.03125\n",
      "26\n",
      "lr 0.03125\n",
      "27\n",
      "lr 0.03125\n",
      "28\n",
      "lr 0.03125\n",
      "converged 0.179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 0 \n",
    "GGL = GradientGroupLasso(replicates[r].dg_M[:2][:,:1][:,:,:3], replicates[r].df_M[:2][:,:1,:1], np.asarray([.179]), np.asarray([0.]), 500,.5, 1e-14, beta0_npm= None)\n",
    "GGL.fit()\n",
    "np.linalg.norm(GGL.fit_[0]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(GGL.fit_[0]['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00494647,  0.01348774, -0.1578278 ],\n",
       "        [-0.11964988,  0.1085518 , -0.06214833]]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[r].df_M[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3173332412132229"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = experiment.construct_Y_js(replicates[r].df_M[:1], 2)\n",
    "xs,gs = experiment.construct_X_js(np.swapaxes(replicates[r].dg_M[:1],1,2))\n",
    "sums = np.zeros(12)\n",
    "for i in range(36):\n",
    "    sums[i%12] += (xs.transpose() @ ys)[i]\n",
    "    \n",
    "np.abs(sums).max() / np.sqrt(1*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = len(np.unique(groups))\n",
    "lambdas = np.asarray(lambdas, dtype=np.float64)\n",
    "yadd = np.expand_dims(ys, 1)\n",
    "groups = np.asarray(groups, dtype=np.int32) + 1\n",
    "W0 = np.zeros((xs.shape[1], yadd.shape[1]), dtype=np.float32)\n",
    "Xsam = np.asfortranarray(xs, dtype=np.float32)\n",
    "Ysam = np.asfortranarray(yadd, dtype=np.float32)\n",
    "coeffs = np.zeros((len(lambdas), q, n, p))\n",
    "\n",
    "# alpha = spams.fistaFlat(Xsam,Dsam2,alpha0sam,ind_groupsam,lambda1 = lambdas[i],mode = mode,itermax = itermax,tol = tol,numThreads = numThreads, regul = \"group-lasso-l2\")\n",
    "# spams.fistaFlat(Y,X,W0,TRUE,numThreads = 1,verbose = TRUE,lambda1 = 0.05, it0 = 10, max_it = 200,L0 = 0.1, tol = 1e-3, intercept = FALSE,pos = FALSE,compute_gram = TRUE, loss = 'square',regul = 'l1')\n",
    "#output = spams.fistaFlat(Ysam, ssp.csc_matrix(Xsam), W0, True, groups=groups, numThreads=-1, verbose=True,\n",
    "output = spams.fistaFlat(Ysam, Xsam, W0, True, groups=groups, numThreads=-1, verbose=True,\n",
    "                         lambda1=lambdas[i], it0=100, max_it=itermax, L0=0.5, tol=tol, intercept=False,\n",
    "                         pos=False, compute_gram=True, loss='square', regul='group-lasso-l2', ista=False,\n",
    "                         subgrad=False, a=.1, b=1000)#b = 1000, a =.1\n",
    "coeffs[i, :, :, :] = np.reshape(output[0], (q, n, p))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manifold_env_april2",
   "language": "python",
   "name": "manifold_env_april2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
