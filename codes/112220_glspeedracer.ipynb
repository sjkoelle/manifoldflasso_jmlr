{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/manifoldflasso_jmlr\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "import random\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from matplotlib.lines import Line2D\n",
    "from pylab import rcParams\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "from shutil import copyfile\n",
    "rcParams['figure.figsize'] = 25, 10\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "now = datetime.datetime.now().strftime(\"%B_%d_%Y_%H_%M_%S\")\n",
    "workingdirectory = os.popen('git rev-parse --show-toplevel').read()[:-1]\n",
    "sys.path.append(workingdirectory)\n",
    "os.chdir(workingdirectory)\n",
    "from codes.experimentclasses.RigidEthanolPCA import RigidEthanolPCA\n",
    "from codes.otherfunctions.get_dictionaries import get_all_atoms_4\n",
    "from codes.otherfunctions.get_grads import get_grads\n",
    "from codes.otherfunctions.multirun import get_support_recovery_lambda\n",
    "from codes.otherfunctions.multirun import get_lower_interesting_lambda\n",
    "from codes.otherfunctions.multirun import get_coeffs_and_lambdas\n",
    "from codes.otherfunctions.multirun import get_support\n",
    "from codes.otherfunctions.multiplot import plot_support_2d\n",
    "from codes.otherfunctions.multiplot import plot_reg_path_ax_lambdasearch\n",
    "from codes.otherfunctions.multiplot import plot_gs_v_dgnorm\n",
    "from codes.otherfunctions.multiplot import plot_dot_distributions\n",
    "from codes.otherfunctions.multirun import get_cosines\n",
    "from codes.flasso.Replicate import Replicate\n",
    "from codes.otherfunctions.multirun import get_olsnorm_and_supportsbrute\n",
    "from codes.otherfunctions.multiplot import highlight_cell\n",
    "\n",
    "#set parameters\n",
    "n = 10000 #number of data points to simulate\n",
    "nsel = 100 #number of points to analyze with lasso\n",
    "itermax = 1000 #maximum iterations per lasso run\n",
    "tol = 1e-10 #convergence criteria for lasso\n",
    "#lambdas = np.asarray([0,.01,.1,1,10,100], dtype = np.float16)#lambda values for lasso\n",
    "lambdas = np.asarray(np.hstack([np.asarray([0]),np.logspace(-3,1,11)]), dtype = np.float16)\n",
    "n_neighbors = 1000 #number of neighbors in megaman\n",
    "m = 3 #number of embedding dimensions (diffusion maps)\n",
    "#diffusion_time = 1. #diffusion time controls gaussian kernel radius per gradients paper\n",
    "diffusion_time = 0.05 #(yuchia suggestion)\n",
    "dim = 2 #manifold dimension\n",
    "dimnoise = 2\n",
    "natoms = 9\n",
    "cores = 3 #number of cores for parallel processing\n",
    "cor = 0.0 #correlation for noise\n",
    "var = 0.00001 #variance scaler for noise\n",
    "cor = 0.0 #correlation for noise\n",
    "var = 0.00001 #variance scaler for noise\n",
    "ii = np.asarray([0,0,0,0,1,1,1,2]) # atom adjacencies for dihedral angle computation\n",
    "jj = np.asarray([1,2,3,4,5,6,7,8])\n",
    "\n",
    "#run experiment\n",
    "atoms4 = np.asarray([[6,1,0,4],[4,0,2,8],[7,6,5,1],[3,0,2,4]],dtype = int)\n",
    "nreps = 25\n",
    "lambda_max = 1\n",
    "max_search = 30\n",
    "\n",
    "new_MN = True\n",
    "new_grad = True\n",
    "savename = 'rigidethanol_110120_alltorsions'\n",
    "savefolder = 'rigidethanol'\n",
    "loadfolder = 'rigidethanol'\n",
    "loadname = 'rigidethanol_110120_alltorsions'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from codes.otherfunctions.get_dictionaries import get_atoms_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atoms4, p = get_atoms_4(9,ii,jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment.p = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-2:\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/queues.py\", line 346, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/queues.py\", line 345, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/queues.py\", line 345, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/connection.py\", line 219, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/connection.py\", line 410, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/multiprocess/connection.py\", line 382, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if new_MN == True:\n",
    "    experiment = RigidEthanolPCA(dim, cor, var, ii, jj, cores, False, atoms4)\n",
    "    experiment.M, experiment.Mpca, projector = experiment.generate_data(noise=False)\n",
    "    experiment.q = m\n",
    "    experiment.m = m\n",
    "    experiment.dimnoise = dimnoise\n",
    "    experiment.projector = projector\n",
    "    experiment.Mpca.geom = experiment.Mpca.compute_geom(diffusion_time, n_neighbors)\n",
    "    experiment.N = experiment.Mpca.get_embedding3(experiment.Mpca.geom, m, diffusion_time, dim)\n",
    "    # with open(workingdirectory + '/untracked_data/embeddings/' + savefolder + '/' + savename + '.pkl' ,\n",
    "    #          'wb') as output:\n",
    "    #      pickle.dump(experiment, output, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import matplotlib.colors\n",
    "import spams\n",
    "from collections import OrderedDict\n",
    "from pylab import rcParams\n",
    "from codes.flasso.GLMaccelerated import GLM\n",
    "\n",
    "rcParams['figure.figsize'] = 25, 10\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    output = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return (output)\n",
    "\n",
    "\n",
    "class FlassoExperiment:\n",
    "    \"\"\"\n",
    "    FlassoExperiment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        2 + 2\n",
    "\n",
    "    def get_norms(self, differential):\n",
    "        n = differential.shape[0]\n",
    "        # could be p, or q\n",
    "        p = differential.shape[1]\n",
    "        d = differential.shape[2]\n",
    "\n",
    "        differential_normalized = np.zeros(differential.shape)\n",
    "        vectornorms = np.zeros((n, p))\n",
    "        for i in range(n):\n",
    "            for j in range(p):\n",
    "                if np.linalg.norm(differential[i, j, :]) > 0:\n",
    "                    vectornorms[i, j] = np.linalg.norm(differential[i, j, :])\n",
    "\n",
    "        psum = np.sum(vectornorms, axis=0)\n",
    "        return (psum / n)\n",
    "\n",
    "    def _flatten_coefficient(self, coeff):\n",
    "        n = coeff.shape[1]\n",
    "        p = coeff.shape[2]\n",
    "        q = coeff.shape[0]\n",
    "\n",
    "        output = np.zeros((n * p * q))\n",
    "        for k in range(q):\n",
    "            for i in range(n):\n",
    "                output[((k * n * p) + (i * p)):((k * n * p) + (i + 1) * p)] = coeff[k, i, :]\n",
    "        return (output)\n",
    "\n",
    "    def get_l2loss(self, coeffs, ys, xs):\n",
    "\n",
    "        n = coeffs.shape[2]\n",
    "        nlam = coeffs.shape[0]\n",
    "        output = np.zeros(nlam)\n",
    "        for i in range(nlam):\n",
    "            coeffvec = self._flatten_coefficient(coeffs[i])\n",
    "            output[i] = np.sum((ys - np.dot(coeffvec, xs.transpose())) ** 2)\n",
    "        output = output / n\n",
    "        return (output)\n",
    "\n",
    "    def normalize(self, differential):\n",
    "        n = differential.shape[0]\n",
    "        # could be p, or q\n",
    "        p = differential.shape[1]\n",
    "        d = differential.shape[2]\n",
    "\n",
    "        gammas = np.sum(np.sum(differential ** 2, axis=2), axis=0) ** (.5)\n",
    "        normed = np.swapaxes(differential, 1, 2) / gammas\n",
    "        #print(normed.shape)\n",
    "        normed = np.swapaxes(normed, 1, 2)\n",
    "    #\n",
    "    #     differential_normalized = np.zeros(differential.shape)\n",
    "    #     vectornorms = np.zeros((n, p))\n",
    "    #     for i in range(n):\n",
    "    #         for j in range(p):\n",
    "    #             if np.linalg.norm(differential[i, j, :]) > 0:\n",
    "    #                 vectornorms[i, j] = np.linalg.norm(differential[i, j, :])\n",
    "    #     # psum = np.sum(vectornorms, axis = 0)\n",
    "    #     psum = np.sqrt(np.sum(vectornorms ** 2, axis=0))#np.sum(vectornorms ** 2, axis=0)#\n",
    "    #     for j in range(p):\n",
    "    #         if psum[j] > 0:\n",
    "    #             differential_normalized[:, j, :] = (differential[:, j, :] / psum[j])  # *n\n",
    "    #\n",
    "    #     return (differential_normalized)\n",
    "        return(normed)\n",
    "\n",
    "\n",
    "    def get_betas_sam(self, xtrain, ytrain, groups, lambdas, n, q, max_iter, tol, learning_rate):\n",
    "\n",
    "        p = len(np.unique(groups))\n",
    "        models = GLM(xs=xtrain, ys=ytrain,\n",
    "                     tol=tol,\n",
    "                     group=groups,\n",
    "                     learning_rate=learning_rate,\n",
    "                     max_iter=max_iter,\n",
    "                     # reg_lambda=np.logspace(np.log(100), np.log(0.01), 5, base=np.exp(1)))\n",
    "                     reg_lambda=lambdas,\n",
    "                     parameter=.5)\n",
    "        models.fit()\n",
    "        nlam = len(lambdas)\n",
    "        organizedbetas = np.zeros((nlam, q, n, p))\n",
    "        for l in range(nlam):\n",
    "            organizedbetas[l, :, :, :] = np.reshape(models.fit_[l]['beta'], (q, n, p))\n",
    "        # return(models, organizedbetas)\n",
    "        return (organizedbetas)\n",
    "\n",
    "    def construct_X(self, dg_M):\n",
    "        \"\"\" dg_M should have shape n x p x dim\n",
    "        \"\"\"\n",
    "        n = dg_M.shape[0]\n",
    "        dim = dg_M.shape[2]\n",
    "        p = dg_M.shape[1]\n",
    "\n",
    "        xmat = np.zeros((n * dim, n * p))\n",
    "        for i in range(n):\n",
    "            xmat[(i * dim):(i * dim + dim), (i * p):(i * p + p)] = dg_M[i, :, :].transpose()\n",
    "        b = [xmat] * dim\n",
    "        xmatq = scipy.linalg.block_diag(*b)\n",
    "        groups = np.tile(np.tile(np.asarray(np.linspace(start=0, stop=(p - 1), num=p), dtype=int), n), dim)\n",
    "\n",
    "        return (xmatq, list(groups))\n",
    "\n",
    "    def construct_X_js(self, dg_M):\n",
    "        \"\"\" dg_M should have shape n x p x dim\n",
    "        \"\"\"\n",
    "        n = dg_M.shape[0]\n",
    "        dim = dg_M.shape[2]\n",
    "        p = dg_M.shape[1]\n",
    "        q = self.q\n",
    "\n",
    "        xmat = np.zeros((n * dim, n * p))\n",
    "        for i in range(n):\n",
    "            xmat[(i * dim):(i * dim + dim), (i * p):(i * p + p)] = dg_M[i, :, :].transpose()\n",
    "        b = [xmat] * q\n",
    "        xmatq = scipy.linalg.block_diag(*b)\n",
    "        groups = np.zeros(n * p * q)\n",
    "        groups = np.tile(np.tile(np.asarray(np.linspace(start=0, stop=(p - 1), num=p), dtype=int), n), q)\n",
    "\n",
    "        return (xmatq, list(groups))\n",
    "\n",
    "    def construct_X_js_subset(self, dg_M, selind):\n",
    "        dg_M_subset = np.zeros(dg_M.shape)\n",
    "        dg_M_subset[:, selind, :] = dg_M[:, selind, :]\n",
    "        output = self.construct_X_js(dg_M_subset)\n",
    "        return (output)\n",
    "\n",
    "    def construct_Y(self, df_M):\n",
    "        \"\"\" df_M should have shape n x dim x dim\n",
    "        \"\"\"\n",
    "        n = df_M.shape[0]\n",
    "        dim = df_M.shape[1]\n",
    "\n",
    "        #reorg1 = np.swapaxes(df_M, 0, 1)\n",
    "        yvec = np.reshape(np.swapaxes(df_M,0,1), (n * dim * dim))\n",
    "        return (yvec)\n",
    "\n",
    "    def construct_Y_js(self, df_M, dim=None):\n",
    "        \"\"\" df_M should have shape n x dim x q\n",
    "        \"\"\"\n",
    "        n = df_M.shape[0]\n",
    "        q = self.q\n",
    "        if dim == None:\n",
    "            dim = self.dim\n",
    "\n",
    "        reorg1 = np.swapaxes(df_M, 0, 2)\n",
    "        reorg2 = np.swapaxes(reorg1, 2, 1)\n",
    "        # yvec = np.reshape(reorg2, (n*dim*dim))\n",
    "        yvec = np.reshape(reorg2, (n * dim * q))\n",
    "        return (yvec)\n",
    "\n",
    "    def plot_convergence(self, models, name='lossplot.pdf'):\n",
    "        for key in list(models.keys()):\n",
    "            # key = list(models.keys())[0]\n",
    "            xval = np.log(np.asarray(list(range(len(list(models[key].lossresults.values())[0])))) + 1)\n",
    "            y = list(models[key].lossresults.values())[0]\n",
    "            plt.plot(xval, y)\n",
    "        plt.legend(list(models.keys()), loc='upper right')\n",
    "        plt.savefig(name)\n",
    "\n",
    "    def plot_convergence_sam(self, models, name='lossplot.pdf'):\n",
    "        for key in list(models.lossresults.keys()):\n",
    "            # key = list(models.keys())[0]\n",
    "            xval = np.log(np.asarray(list(range(len(models.lossresults[key])))) + 1)\n",
    "            y = models.lossresults[key]\n",
    "            plt.plot(xval, y)\n",
    "        plt.legend(list(models.lossresults.keys()), loc='upper right')\n",
    "        plt.savefig(name)\n",
    "\n",
    "    def plot_bh(self, coeffs, nsample_pts, p, name='beta'):\n",
    "        dim = self.dim\n",
    "        # p = self.p\n",
    "        n = nsample_pts\n",
    "        nlam = coeffs.shape[0]\n",
    "\n",
    "        for l in range(len(lambdas)):\n",
    "            if dim > 1:\n",
    "                fig, axes = plt.subplots(1, q, figsize=(15, 30))\n",
    "                for k in range(q):\n",
    "                    tempplot = axes[k].imshow(coeffs[l, k, :, :])\n",
    "                    plt.colorbar(tempplot, ax=axes[k])\n",
    "            if dim == 1:\n",
    "                k = 0\n",
    "                fig, ax = plt.subplots(figsize=(5, 5))\n",
    "                ax.imshow(coeffs[l, k, :, :])\n",
    "            fig.savefig('lambda' + name + 'heatmap.pdf')\n",
    "\n",
    "    def compute_penalty2(self, coeffs):\n",
    "        n = coeffs.shape[2]\n",
    "        nlam = coeffs.shape[0]\n",
    "        q = coeffs.shape[1]\n",
    "        p = coeffs.shape[3]\n",
    "\n",
    "        # p = self.p\n",
    "        pen = np.zeros(nlam)\n",
    "        for l in range(nlam):\n",
    "            norm2 = np.zeros(p)\n",
    "            for j in range(p):\n",
    "                norm2[j] = np.linalg.norm(coeffs[l, :, :, j])\n",
    "            pen[l] = np.sum(norm2)\n",
    "        pen = pen / n\n",
    "        return (pen)\n",
    "\n",
    "    def plot_penalty(self, coeffs, xaxis, xlabel, xlog, ylog, title, filename):\n",
    "        ylabel = r\"$\\frac{1}{n}\\displaystyle \\|\\beta\\|_{1,2}$ \"\n",
    "\n",
    "        if xlog:\n",
    "            filename = filename + 'xlog'\n",
    "        if ylog:\n",
    "            filename = filename + 'ylog'\n",
    "\n",
    "        pens = self.compute_penalty2(coeffs)\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(15, 15))\n",
    "        axes.plot(xaxis, pens, 'go--', linewidth=5, markersize=0, alpha=1)\n",
    "        axes.set_ylim(bottom=1e-4, top=pens.max())\n",
    "        if xlog:\n",
    "            axes.semilogx()\n",
    "        if ylog:\n",
    "            axes.semilogy()\n",
    "        axes.tick_params(labelsize=50)\n",
    "        fig.text(0.5, 0.04, xlabel, ha='center', va='center', fontsize=50)\n",
    "        fig.text(0.05, 0.5, ylabel, ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "        plt.suptitle(title, fontsize=55)\n",
    "        fig.savefig(filename + 'penalty' + str(n))\n",
    "\n",
    "    def plot_predictions(self, coeffs, xs, ys, xaxis, xlabe, xlog, ylog, title, filename):\n",
    "        2 + 2\n",
    "\n",
    "    def plot_l2loss(self, coeffs, xs, ys, xaxis, xlabel, xlog, ylog, title, filename):\n",
    "\n",
    "        ylabel = r\"$\\displaystyle \\frac{1}{n}\\|y - x\\beta\\|_2^2$\"\n",
    "\n",
    "        if xlog:\n",
    "            filename = filename + 'xlog'\n",
    "        if ylog:\n",
    "            filename = filename + 'ylog'\n",
    "\n",
    "        losses = self.get_l2loss(coeffs, ys, xs)\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(15, 15))\n",
    "        axes.plot(xaxis, losses, 'go--', linewidth=5, markersize=0, alpha=1)\n",
    "        axes.set_ylim(bottom=1e-4, top=losses.max())\n",
    "        if xlog:\n",
    "            axes.semilogx()\n",
    "        if ylog:\n",
    "            axes.semilogy()\n",
    "        axes.tick_params(labelsize=50)\n",
    "        fig.text(0.5, 0.04, xlabel, ha='center', va='center', fontsize=50)\n",
    "        fig.text(0.05, 0.5, ylabel, ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "        plt.suptitle(title, fontsize=55)\n",
    "        fig.savefig(filename + 'loss' + str(n))\n",
    "\n",
    "    def plot_beta_paths_best(self, coeffs, xaxis, gnames, fnames, xlabel, title, filename, xlog, ylog,\n",
    "                             norm_betas=False):\n",
    "        if xlog:\n",
    "            filename = filename + 'xlog'\n",
    "        if ylog:\n",
    "            filename = filename + 'ylog'\n",
    "        if norm_betas:\n",
    "            print(filename)\n",
    "            filename = filename + 'norm'\n",
    "            print(filename)\n",
    "            ylabel = r\"$\\displaystyle \\|\\hat \\beta_{j}\\|_2$\"\n",
    "        else:\n",
    "            ylabel = r\"$\\displaystyle \\hat \\beta_{ij}$\"\n",
    "        rcParams['axes.titlesize'] = 30\n",
    "        plt.rc('text', usetex=True)\n",
    "\n",
    "        p = coeffs.shape[3]\n",
    "        n = coeffs.shape[2]\n",
    "        q = coeffs.shape[1]\n",
    "\n",
    "        norm = matplotlib.colors.Normalize(vmin=0, vmax=p)\n",
    "        cmap = plt.cm.rainbow\n",
    "\n",
    "        if norm_betas:\n",
    "            maxes = np.zeros(q)\n",
    "            for k in range(q):\n",
    "                # for j in range(p):\n",
    "                maxes[k] = np.linalg.norm(coeffs[:, k, :, :], axis=1).max()\n",
    "            normax = maxes.max()\n",
    "        if q > 1:\n",
    "            fig, axes = plt.subplots(1, q, figsize=((15 * q), 15))\n",
    "            for k in range(q):\n",
    "                for j in range(p):\n",
    "                    if norm_betas == False:\n",
    "                        for i in range(n):\n",
    "                            axes[k].plot(xaxis, coeffs[:, k, i, j], 'go--', linewidth=5, markersize=0, alpha=.2,\n",
    "                                         color=cmap(norm(j)), label=gnames[j])\n",
    "                    else:\n",
    "                        axes[k].plot(xaxis, np.linalg.norm(coeffs[:, k, :, j], axis=1), 'go--', linewidth=5,\n",
    "                                     markersize=0, alpha=1, color=cmap(norm(j)), label=gnames[j])\n",
    "                # axes[k].set_title(fnames[k], fontsize=30)\n",
    "                axes[k].tick_params(labelsize=50)\n",
    "                if xlog:\n",
    "                    axes[k].semilogx()\n",
    "                if ylog:\n",
    "                    axes[k].semilogy()\n",
    "                if norm_betas == True:\n",
    "                    axes[k].set_ylim(bottom=1e-4, top=normax)\n",
    "                else:\n",
    "                    if ylog == True:\n",
    "                        axes[k].set_ylim(bottom=1e-4, top=coeffs.max())  # adjust the max leaving min unchanged\n",
    "            handles, labels = axes[0].get_legend_handles_labels()\n",
    "        else:\n",
    "            fig, axes = plt.subplots(1, q, figsize=((15 * q), 15))\n",
    "            for j in range(p):\n",
    "                if norm_betas == False:\n",
    "                    for i in range(n):\n",
    "                        axes.plot(xaxis, coeffs[:, 0, i, j], 'go--', linewidth=5, markersize=0, alpha=.2,\n",
    "                                  color=cmap(norm(j)), label=gnames[j])\n",
    "                else:\n",
    "                    axes.plot(xaxis, np.linalg.norm(coeffs[:, 0, :, j], axis=1), 'go--', linewidth=5, markersize=0,\n",
    "                              alpha=1, color=cmap(norm(j)), label=gnames[j])\n",
    "            # axes.set_title(fnames[0], fontsize=30)\n",
    "            axes.tick_params(labelsize=50)\n",
    "            if xlog:\n",
    "                axes.semilogx()\n",
    "            if ylog:\n",
    "                axes.semilogy()\n",
    "            if norm_betas == True:\n",
    "                axes.set_ylim(bottom=1e-4, top=normax)\n",
    "            else:\n",
    "                if ylog == True:\n",
    "                    axes.set_ylim(bottom=1e-4, top=coeffs.max())  # adjust the max leaving min unchanged\n",
    "            handles, labels = axes.get_legend_handles_labels()\n",
    "\n",
    "        by_label = OrderedDict(zip(labels, handles))\n",
    "        fig.text(0.5, 0.04, xlabel, ha='center', va='center', fontsize=50)\n",
    "        fig.text(0.05, 0.5, ylabel, ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "        plt.suptitle(title, fontsize=55)\n",
    "        fig.subplots_adjust(right=0.75)\n",
    "        leg_ax = fig.add_axes([.96, 0.15, 0.05, 0.7])\n",
    "        leg_ax.axis('off')\n",
    "        # leg = leg_ax.legend(by_label.values(), by_label.keys(), prop={'size': 55})\n",
    "        leg = leg_ax.legend(by_label.values(), by_label.keys(), prop={'size': 25})\n",
    "        leg.set_title('Group', prop={'size': 45})\n",
    "        for l in leg.get_lines():\n",
    "            l.set_alpha(1)\n",
    "        fig.savefig(filename + 'beta_paths_log_n' + str(n))\n",
    "\n",
    "    def plot_beta_paths_best2(self, coeffs, xaxis, gnames, fnames, xlabel, title, filename, xlog, ylog, colors, lines,\n",
    "                              norm_betas=False):\n",
    "        if xlog:\n",
    "            filename = filename + 'xlog'\n",
    "        if ylog:\n",
    "            filename = filename + 'ylog'\n",
    "        if norm_betas:\n",
    "            print(filename)\n",
    "            filename = filename + 'norm'\n",
    "            print(filename)\n",
    "            ylabel = r\"$\\displaystyle \\|\\hat \\beta_{j}\\|_2$\"\n",
    "        else:\n",
    "            ylabel = r\"$\\displaystyle \\hat \\beta_{ij}$\"\n",
    "        rcParams['axes.titlesize'] = 30\n",
    "        plt.rc('text', usetex=True)\n",
    "\n",
    "        p = coeffs.shape[3]\n",
    "        n = coeffs.shape[2]\n",
    "        q = coeffs.shape[1]\n",
    "\n",
    "        norm = matplotlib.colors.Normalize(vmin=0, vmax=p)\n",
    "        cmap = plt.cm.rainbow\n",
    "\n",
    "        if norm_betas:\n",
    "            maxes = np.zeros(q)\n",
    "            for k in range(q):\n",
    "                # or j in range(p):\n",
    "                maxes[k] = np.linalg.norm(coeffs[:, k, :, :], axis=1).max()\n",
    "            normax = maxes.max()\n",
    "        if q > 1:\n",
    "            fig, axes = plt.subplots(1, q, figsize=((15 * q), 15))\n",
    "            for k in range(q):\n",
    "                for j in range(p):\n",
    "                    if norm_betas == False:\n",
    "                        for i in range(n):\n",
    "                            axes[k].plot(xaxis, coeffs[:, k, i, j], 'go--', linewidth=5, markersize=0, alpha=.2,\n",
    "                                         color=colors[j], linestyle=lines[j], label=gnames[j])\n",
    "                    else:\n",
    "                        axes[k].plot(xaxis, np.linalg.norm(coeffs[:, k, :, j], axis=1), 'go--', linewidth=5,\n",
    "                                     markersize=0, alpha=1, color=colors[j], linestyle=lines[j], label=gnames[j])\n",
    "                # axes[k].set_title(fnames[k], fontsize=30)\n",
    "                axes[k].tick_params(labelsize=50)\n",
    "                if xlog:\n",
    "                    axes.set_xscale('symlog')\n",
    "                if ylog:\n",
    "                    axes.set_yscale('symlog')\n",
    "                if norm_betas == True:\n",
    "                    axes[k].set_ylim(bottom=1e-4, top=10 * normax)\n",
    "                else:\n",
    "                    if ylog == True:\n",
    "                        axes[k].set_ylim(bottom=1e-4, top=coeffs.max())  # adjust the max leaving min unchanged\n",
    "            handles, labels = axes[0].get_legend_handles_labels()\n",
    "        else:\n",
    "            fig, axes = plt.subplots(1, q, figsize=((15 * q), 15))\n",
    "            for j in range(p):\n",
    "                if norm_betas == False:\n",
    "                    for i in range(n):\n",
    "                        axes.plot(xaxis, coeffs[:, 0, i, j], 'go--', linewidth=5, markersize=0, alpha=.2,\n",
    "                                  color=colors[j], linestyle=lines[j], label=gnames[j])\n",
    "                else:\n",
    "                    axes.plot(xaxis, np.linalg.norm(coeffs[:, 0, :, j], axis=1), 'go--', linewidth=5, markersize=0,\n",
    "                              alpha=1, color=colors[j], linestyle=lines[j], label=gnames[j])\n",
    "            # axes.set_title(fnames[0], fontsize=30)\n",
    "            axes.tick_params(labelsize=50)\n",
    "            axes.set_xscale('symlog')\n",
    "            axes.set_yscale('symlog')\n",
    "            if norm_betas == True:\n",
    "                axes.set_ylim(bottom=0, top=10 * normax)\n",
    "            else:\n",
    "                if ylog == True:\n",
    "                    axes.set_ylim(bottom=0, top=coeffs.max())  # adjust the max leaving min unchanged\n",
    "            handles, labels = axes.get_legend_handles_labels()\n",
    "\n",
    "        by_label = OrderedDict(zip(labels, handles))\n",
    "        fig.text(0.5, 0.04, xlabel, ha='center', va='center', fontsize=50)\n",
    "        fig.text(0.05, 0.5, ylabel, ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "        plt.suptitle(title, fontsize=55)\n",
    "        fig.subplots_adjust(right=0.75)\n",
    "        leg_ax = fig.add_axes([.96, 0.15, 0.05, 0.7])\n",
    "        leg_ax.axis('off')\n",
    "        # leg = leg_ax.legend(by_label.values(), by_label.keys(), prop={'size': 55})\n",
    "        leg = leg_ax.legend(by_label.values(), by_label.keys(), prop={'size': 25})\n",
    "        leg.set_title('Group', prop={'size': 45})\n",
    "        for l in leg.get_lines():\n",
    "            l.set_alpha(1)\n",
    "        fig.savefig(filename + 'beta_paths_log_n2' + str(n))\n",
    "\n",
    "    def get_cosines(self, dg):\n",
    "        n = dg.shape[0]\n",
    "        p = dg.shape[1]\n",
    "        d = dg.shape[2]\n",
    "\n",
    "        coses = np.zeros((n, p, p))\n",
    "        for i in range(n):\n",
    "            for j in range(p):\n",
    "                for k in range(p):\n",
    "                    coses[i, j, k] = cosine_similarity(dg[i, j, :], dg[i, k,\n",
    "                                                                    :])  # sklearn.metrics.pairwise.cosine_similarity(X = np.reshape(dg[:,i,:], (1,d*n)),Y = np.reshape(dg[:,j,:], (1,d*n)))[0][0]\n",
    "        cos_summary = np.abs(coses).sum(axis=0) / n\n",
    "        return (cos_summary)\n",
    "\n",
    "    def plot_norms(self, norms, filename):\n",
    "        plt.imshow(norms)\n",
    "        plt.colorbar()\n",
    "        plt.savefig(filename + 'norms')\n",
    "\n",
    "    def plot_cosines(self, cos_sumary, filename):\n",
    "        plt.imshow(cos_sumary)\n",
    "        plt.colorbar()\n",
    "        plt.savefig(filename + 'cosines')\n",
    "\n",
    "    def plot_pairwise_solutions(self, coeffs, lambdas, gnames, fnames, title, filename, log):\n",
    "\n",
    "        if log:\n",
    "            filename = filename + 'xlog'\n",
    "            filename = filename + 'ylog'\n",
    "        if norm_betas:\n",
    "            print(filename)\n",
    "            filename = filename + 'norm'\n",
    "            print(filename)\n",
    "\n",
    "        rcParams['axes.titlesize'] = 30\n",
    "        plt.rc('text', usetex=True)\n",
    "        p = coeffs.shape[3]\n",
    "        n = coeffs.shape[2]\n",
    "        nlam = coeffs.shape[0]\n",
    "        fig, axes = plt.subplots(p, q, figsize=((15 * q), (15 * p)))\n",
    "        norm = matplotlib.colors.Normalize(vmin=0, vmax=nlam)\n",
    "        cmap = plt.cm.rainbow\n",
    "        colors = cmap(norm(range(nlam)))\n",
    "        for k1 in range(q):\n",
    "            for k2 in range(q):\n",
    "                for j1 in range(p):\n",
    "                    for j2 in range(p):\n",
    "                        for l in range(nlam):\n",
    "                            axes[(k1 * q + j1), (k2 * q + j2)].plot(coeffs[l, k1, :, j1], coeffs[l, k2, :, j2],\n",
    "                                                                    alpha=.2, color=cmap(norm(l)), labels=lambdas[l])\n",
    "                            axes[(k1 * q + j1), (k2 * q + j2)].set_xlabel(fnames[k1] + gnames[j1], fontsize=30)\n",
    "                            axes[(k1 * q + j1), (k2 * q + j2)].set_ylabel(fnames[k1] + gnames[j1], fontsize=30)\n",
    "                            axes[(k1 * q + j1), (k2 * q + j2)].tick_params(labelsize=50)\n",
    "                            if log:\n",
    "                                axes[(k1 * q + j1), (k2 * q + j2)].semilogx()\n",
    "                                axes[(k1 * q + j1), (k2 * q + j2)].semilogy()\n",
    "\n",
    "        handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "        by_label = OrderedDict(zip(labels, handles))\n",
    "        fig.text(0.5, 0.04, xlabel, ha='center', va='center', fontsize=50)\n",
    "        fig.text(0.06, 0.5, ylabel, ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "        plt.suptitle(title, fontsize=55)\n",
    "        fig.subplots_adjust(right=0.75)\n",
    "        leg_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "        leg_ax.axis('off')\n",
    "        leg = leg_ax.legend(by_label.values(), by_label.keys(), prop={'size': 55})\n",
    "        leg.set_title('Group', prop={'size': 45})\n",
    "        for l in leg.get_lines():\n",
    "            l.set_alpha(1)\n",
    "        fig.savefig(filename + 'beta_paths_log_n' + str(n))\n",
    "\n",
    "    def normalize_xaxis(self, coeff, groups):\n",
    "\n",
    "        # groups = np.asarray(may_experiment.groups)\n",
    "        tempsum = 0\n",
    "        i = 0\n",
    "        ngroups = coeff.shape[3]\n",
    "        for j in range(ngroups):\n",
    "            tempsum = tempsum + np.linalg.norm(coeff[i, :, :, j])\n",
    "        beta0norm = tempsum\n",
    "\n",
    "        xaxis = np.zeros(len(lambdas))\n",
    "        for i in range(len(lambdas)):\n",
    "            tempsum = 0\n",
    "            for j in range(ngroups):\n",
    "                tempsum = tempsum + np.linalg.norm(coeff[i, :, :, j])\n",
    "            xaxis[i] = tempsum / beta0norm\n",
    "        return (xaxis)\n",
    "\n",
    "    def get_betas_spam2(self, xs, ys, groups, lambdas, n, q, itermax, tol):\n",
    "\n",
    "        # n = xs.shape[0]\n",
    "        p = len(np.unique(groups))\n",
    "        lambdas = np.asarray(lambdas, dtype=np.float64)\n",
    "        yadd = np.expand_dims(ys, 1)\n",
    "        groups = np.asarray(groups, dtype=np.int32) + 1\n",
    "        W0 = np.zeros((xs.shape[1], yadd.shape[1]), dtype=np.float32)\n",
    "        Xsam = np.asfortranarray(xs, dtype=np.float32)\n",
    "        Ysam = np.asfortranarray(yadd, dtype=np.float32)\n",
    "        coeffs = np.zeros((len(lambdas), q, n, p))\n",
    "        for i in range(len(lambdas)):\n",
    "            # alpha = spams.fistaFlat(Xsam,Dsam2,alpha0sam,ind_groupsam,lambda1 = lambdas[i],mode = mode,itermax = itermax,tol = tol,numThreads = numThreads, regul = \"group-lasso-l2\")\n",
    "            # spams.fistaFlat(Y,X,W0,TRUE,numThreads = 1,verbose = TRUE,lambda1 = 0.05, it0 = 10, max_it = 200,L0 = 0.1, tol = 1e-3, intercept = FALSE,pos = FALSE,compute_gram = TRUE, loss = 'square',regul = 'l1')\n",
    "            output = spams.fistaFlat(Ysam, Xsam, W0, True, groups=groups, numThreads=-1, verbose=True,\n",
    "                                     lambda1=lambdas[i], it0=100, max_it=itermax, L0=0.5, tol=tol, intercept=False,\n",
    "                                     pos=False, compute_gram=True, loss='square', regul='group-lasso-l2', ista=False,\n",
    "                                     subgrad=False, a=0.1, b=1000)\n",
    "            coeffs[i, :, :, :] = np.reshape(output[0], (q, n, p))\n",
    "            # print(output[1])\n",
    "        return (coeffs)\n",
    "\n",
    "    def plot_coefficient_recovery(self, coeffs, coeffspred, lambdas, filename):\n",
    "\n",
    "        p = coeffs.shape[3]\n",
    "        q = coeffs.shape[1]\n",
    "        nlam = coeffs.shape[0]\n",
    "\n",
    "        norm = matplotlib.colors.Normalize(vmin=0, vmax=nlam)\n",
    "        cmap = plt.cm.rainbow\n",
    "        colors = cmap(norm(range(p)))\n",
    "        organizedbetas = coeffs\n",
    "        ymin = organizedbetas.min() - 0.01\n",
    "        ymax = organizedbetas.max() + 0.01\n",
    "        cmap = plt.cm.rainbow\n",
    "        minimum = lambdas.min()\n",
    "        # eps = minimum / 10000\n",
    "        # lambdas = lambdas + eps\n",
    "\n",
    "        if q > 1:\n",
    "            fig, axes = plt.subplots(nrows=p, ncols=q, figsize=(15, 15))\n",
    "            for k in range(q):\n",
    "                for j in range(p):\n",
    "                    # print(k,j)\n",
    "                    for i in range(nlam):\n",
    "                        axes[j, k].scatter(coeffspred[k, :, j], coeffs[i, k, :, j], alpha=.1, color=cmap(norm(i)))\n",
    "                    axes[j, k].set_ylabel(r\"$\\displaystyle \\widehat{{ d_{{g_{}}} h_{{}}}}$\".format(j, k), fontsize=35)\n",
    "                    # axes[j,k].set_title('function = ' + str(k + 1) + 'group = ' + str(j+1), fontsize = 15)\n",
    "                    axes[j, k].set_xlabel(r\"$\\displaystyle  d_{{g_{}}}^? h_{{}}$\".format(j, k), fontsize=35)\n",
    "                    axes[j, k].tick_params(labelsize=40)\n",
    "                    # axes[j,k].semilogy()\n",
    "                    # axes[j,k].semilogx()\n",
    "        if q == 1:\n",
    "            fig, axes = plt.subplots(nrows=p, ncols=1, figsize=(15, 15))\n",
    "            for j in range(p):\n",
    "                # print(j)\n",
    "                for i in range(nlam):\n",
    "                    axes[j].scatter(coeffspred[0, :, j], coeffs[i, 0, :, j], alpha=.1, color=cmap(norm(i)))\n",
    "                axes[j].set_ylabel(r\"$\\displaystyle \\widehat{{d_{{g_{}}} h}}$\".format(j), fontsize=35)\n",
    "                # axes[j].set_xlabel(predictionlabels[j], fontsize = 35)\n",
    "                axes[j].set_xlabel(r\"$\\displaystyle d_{{g_{}}}^? h$\".format(j), fontsize=35, labelpad=-1)\n",
    "                axes[j].tick_params(labelsize=40)\n",
    "                # axes[j].semilogy()\n",
    "                # axes[j].semilogx()\n",
    "                # axes[j].set_xlabel('Predicted Beta', fontsize = 15)\n",
    "                # axes[j].set_title('group = ' + str(j+1), fontsize = 15)\n",
    "\n",
    "        sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "        sm.set_array([])\n",
    "        fig.subplots_adjust(right=0.8)\n",
    "        cbar_ax = fig.add_axes([.85, 0.15, 0.05, 0.7])\n",
    "        cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "        cbar.ax.tick_params(labelsize=40)\n",
    "        cbar.set_label(r\"$\\displaystyle \\lambda$\", rotation=270, fontsize=50)\n",
    "        # fig.text(0.0, 0.5, 'Estimates', ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "        # fig.text(0.5, 0.04, r\"$\\displaystyle d_g^? h$\", ha='center', va='center', fontsize=50)\n",
    "        plt.suptitle(title, fontsize=55)\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.7, left=0.2, bottom=0.1, right=0.85, top=0.85)\n",
    "        # plt.subplots_adjust(wspace=0.6, hspace=0.6, left=0.1, bottom=0.22, right=0.96, top=0.96)\n",
    "        fig.savefig(filename + 'coefficientrecovery' + str(n))\n",
    "\n",
    "    def plot_coefficient_error_distribution(self, coeffs, coeffspred, lambdas, filename):\n",
    "\n",
    "        p = coeffs.shape[3]\n",
    "        q = coeffs.shape[1]\n",
    "        nlam = coeffs.shape[0]\n",
    "        n_bins = 50\n",
    "\n",
    "        norm = matplotlib.colors.Normalize(vmin=0, vmax=nlam)\n",
    "        cmap = plt.cm.rainbow\n",
    "        colors = cmap(norm(range(p)))\n",
    "        organizedbetas = coeffs\n",
    "        ymin = organizedbetas.min() - 0.01\n",
    "        ymax = organizedbetas.max() + 0.01\n",
    "        cmap = plt.cm.rainbow\n",
    "        minimum = lambdas.min()\n",
    "        # eps = minimum / 10000\n",
    "        # lambdas = lambdas + eps\n",
    "        error = coeffs.copy()\n",
    "        for i in range(nlam):\n",
    "            error[i] = np.abs(coeffs[i]) - np.abs(coeffspred)\n",
    "\n",
    "        if q > 1:\n",
    "            fig, axes = plt.subplots(nrows=p, ncols=q, figsize=((15 * p), 15 * q))\n",
    "            for k in range(q):\n",
    "                for j in range(p):\n",
    "                    # print(k,j)\n",
    "                    for i in range(nlam):\n",
    "                        # axes[j,k].scatter(coeffspred[k,:,j], coeffs[i,k,:,j],  alpha = .1, color = cmap(norm(i)))\n",
    "                        n, bins, patches = axes[j, k].hist(error[i, k, :, j], n_bins, normed=1, histtype='step',\n",
    "                                                           cumulative=True, label='Empirical', color=cmap(norm(i)))\n",
    "                        patches[0].set_xy(patches[0].get_xy()[:-1])\n",
    "                        axes[j, k].set_xlabel(\n",
    "                            r\"$\\displaystyle \\widehat{{ d_{{g_{}}} h_{{}}}} - d_{{g_{}}}^? h_{{}}$\".format(j, k, j, k),\n",
    "                            fontsize=40)\n",
    "                        axes[j, k].tick_params(labelsize=50)\n",
    "                        # axes[j,k].set_ylabel(r\"$\\displaystyle \\widehat{{ d_{{g_{}}} h_{{}}}}$\".format(j,k), fontsize = 15)\n",
    "                        # axes[j,k].set_title('function = ' + str(k + 1) + 'group = ' + str(j+1), fontsize = 15)\n",
    "                        # axes[j,k].set_xlabel(predictionlabels[j,k], fontsize = 35)\n",
    "                        # axes[j,k].semilogy()\n",
    "                        # axes[j,k].semilogx()\n",
    "        if q == 1:\n",
    "            fig, axes = plt.subplots(nrows=p, ncols=1, figsize=(15, 15))\n",
    "            for j in range(p):\n",
    "                print(j)\n",
    "                for i in range(nlam):\n",
    "                    # print(j)\n",
    "                    n, bins, patches = axes[j].hist(error[i, 0, :, j], n_bins, normed=1, histtype='step',\n",
    "                                                    cumulative=True, label='Empirical', color=cmap(norm(i)))\n",
    "                    patches[0].set_xy(patches[0].get_xy()[:-1])\n",
    "                    axes[j].set_xlabel(r\"$\\displaystyle \\widehat{{d_{{g_{}}} h}} - d_{{g_{}}}^? h$\".format(j, j),\n",
    "                                       fontsize=40)\n",
    "                    axes[j].tick_params(labelsize=50)\n",
    "                    # axes[j].scatter(coeffspred[0,:,j], coeffs[i,0,:,j],  alpha = .1, color = cmap(norm(i)))\n",
    "                    # axes[j].set_ylabel(r\"$\\displaystyle \\widehat{{d_{{g_{}}} h}}$\".format(j), fontsize = 25)\n",
    "                    # axes[j].set_xlabel(predictionlabels[j], fontsize = 35)\n",
    "                    # axes[j].semilogy()\n",
    "                    # axes[j].semilogx()\n",
    "                    # axes[j].set_xlabel('Predicted Beta', fontsize = 15)\n",
    "                    # axes[j].set_title('group = ' + str(j+1), fontsize = 15)\n",
    "\n",
    "        sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "        sm.set_array([])\n",
    "        fig.subplots_adjust(right=0.85)\n",
    "        cbar_ax = fig.add_axes([.85, 0.15, 0.05, 0.7])\n",
    "        cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "        cbar.ax.tick_params(labelsize=40)\n",
    "        cbar.set_label(r\"$\\displaystyle \\lambda$\", rotation=270, fontsize=60)\n",
    "        # fig.text(0.0, 0.5, 'Estimates', ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "        fig.text(0.05, 0.5, r\"ECDF\", ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "        # fig.text(0.5, 0.04, r\"$\\displaystyle d_g^? h$\", ha='center', va='center', fontsize=50)\n",
    "        plt.suptitle(title, fontsize=55)\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.85)\n",
    "        fig.savefig(filename + 'coefficientrecovery.png')\n",
    "\n",
    "    def plot_coefficient_distribution(self, coeffs, lambdas, filename):\n",
    "\n",
    "        p = coeffs.shape[3]\n",
    "        q = coeffs.shape[1]\n",
    "        nlam = coeffs.shape[0]\n",
    "        n_bins = 50\n",
    "\n",
    "        norm = matplotlib.colors.Normalize(vmin=0, vmax=nlam)\n",
    "        cmap = plt.cm.rainbow\n",
    "        colors = cmap(norm(range(p)))\n",
    "        organizedbetas = coeffs\n",
    "        ymin = organizedbetas.min() - 0.01\n",
    "        ymax = organizedbetas.max() + 0.01\n",
    "        cmap = plt.cm.rainbow\n",
    "        minimum = lambdas.min()\n",
    "\n",
    "        if q < 1:\n",
    "            fig, axes = plt.subplots(nrows=p, ncols=q, figsize=(15, 15))\n",
    "            for k in range(q):\n",
    "                for j in range(p):\n",
    "                    # print(k,j)\n",
    "                    for i in range(nlam):\n",
    "                        # axes[j,k].scatter(coeffspred[k,:,j], coeffs[i,k,:,j],  alpha = .1, color = cmap(norm(i)))\n",
    "                        n, bins, patches = axes[j, k].hist(coeffs[i, k, :, j], n_bins, normed=1, histtype='step',\n",
    "                                                           cumulative=True, label='Empirical', color=cmap(norm(i)))\n",
    "                        patches[0].set_xy(patches[0].get_xy()[:-1])\n",
    "                        axes[j, k].set_xlabel(r\"$\\displaystyle \\widehat{{ d_{{g_{}}} h_{{}}}}$\".format(j, k),\n",
    "                                              fontsize=15)\n",
    "                        # axes[j,k].set_ylabel(r\"$\\displaystyle \\widehat{{ d_{{g_{}}} h_{{}}}}$\".format(j,k), fontsize = 15)\n",
    "                        # axes[j,k].set_title('function = ' + str(k + 1) + 'group = ' + str(j+1), fontsize = 15)\n",
    "                        # axes[j,k].set_xlabel(predictionlabels[j,k], fontsize = 35)\n",
    "                        # axes[j,k].semilogy()\n",
    "                        # axes[j,k].semilogx()\n",
    "        if q == 1:\n",
    "            fig, axes = plt.subplots(nrows=p, ncols=1, figsize=(15, 15))\n",
    "            for j in range(p):\n",
    "                print(j)\n",
    "                for i in range(nlam):\n",
    "                    # print(j)\n",
    "                    n, bins, patches = axes[j].hist(coeffs[i, 0, :, j], n_bins, normed=1, histtype='step',\n",
    "                                                    cumulative=True, label='Empirical', color=cmap(norm(i)))\n",
    "                    patches[0].set_xy(patches[0].get_xy()[:-1])\n",
    "                    axes[j].set_xlabel(r\"$\\displaystyle \\widehat{{d_{{g_{}}} h}}$\".format(j), fontsize=25)\n",
    "                    # axes[j].scatter(coeffspred[0,:,j], coeffs[i,0,:,j],  alpha = .1, color = cmap(norm(i)))\n",
    "                    # axes[j].set_ylabel(r\"$\\displaystyle \\widehat{{d_{{g_{}}} h}}$\".format(j), fontsize = 25)\n",
    "                    # axes[j].set_xlabel(predictionlabels[j], fontsize = 35)\n",
    "                    # axes[j].semilogy()\n",
    "                    # axes[j].semilogx()\n",
    "                    # axes[j].set_xlabel('Predicted Beta', fontsize = 15)\n",
    "                    # axes[j].set_title('group = ' + str(j+1), fontsize = 15)\n",
    "\n",
    "        sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "        sm.set_array([])\n",
    "        fig.subplots_adjust(right=0.9)\n",
    "        cbar_ax = fig.add_axes([1, 0.15, 0.05, 0.7])\n",
    "        cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "        cbar.set_label(r\"$\\displaystyle \\lambda$\", rotation=270, fontsize=30)\n",
    "        # fig.text(0.0, 0.5, 'Estimates', ha='center', va='center', rotation='vertical', fontsize=60)\n",
    "        fig.text(0.0, 0.5, r\"$\\displaystyle \\frac{1}{n} \\sum_{i=1}^n 1_{\\widehat{ d_g h} |_i < x}$\", ha='center',\n",
    "                 va='center', rotation='vertical', fontsize=60)\n",
    "        # fig.text(0.5, 0.04, r\"$\\displaystyle d_g^? h$\", ha='center', va='center', fontsize=50)\n",
    "        plt.suptitle(title, fontsize=55)\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.3)\n",
    "        fig.savefig(filename + 'coefficientrecovery' + str(n))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atoms4, p = get_all_atoms_4(9)\n",
    "\n",
    "experiment.atoms4 = atoms4\n",
    "experiment.p = p\n",
    "\n",
    "i  = 0 \n",
    "# replicates = {}\n",
    "# selected_points_save = np.zeros((nreps,nsel))\n",
    "# selected_points = np.random.choice(list(range(n)),nsel,replace = False)\n",
    "# selected_points_save[i] = selected_points\n",
    "# replicates[i] = Replicate()\n",
    "# replicates[i].nsel = nsel\n",
    "# replicates[i].selected_points = selected_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "i  = 0\n",
    "replicates = {}\n",
    "selected_points_save = np.zeros((nreps,nsel))\n",
    "selected_points = np.random.choice(list(range(n)),nsel,replace = False)\n",
    "selected_points_save[i] = selected_points\n",
    "replicates[i] = Replicate()\n",
    "replicates[i].nsel = nsel\n",
    "replicates[i].selected_points = selected_points\n",
    "replicates[i].df_M,replicates[i].dg_M,replicates[i].dg_w ,replicates[i].dg_w_pca ,replicates[i].dgw_norm  = get_grads(experiment, experiment.Mpca, experiment.M, experiment.N, selected_points)\n",
    "replicates[i].xtrain, replicates[i].groups = experiment.construct_X_js(replicates[i].dg_M)\n",
    "replicates[i].ytrain = experiment.construct_Y_js(replicates[i].df_M,dimnoise)\n",
    "replicates[i].coeff_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(workingdirectory + '/untracked_data/embeddings/re_test_exp.pkl' ,\n",
    "         'wb') as output:\n",
    "     pickle.dump(experiment, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(workingdirectory + '/untracked_data/embeddings/re_test_replicate.pkl' ,\n",
    "         'wb') as output:\n",
    "     pickle.dump(replicates[0], output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 756, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(3, 0), dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(np.where(np.isnan(replicates[0].dg_w_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = replicates[i].xtrain\n",
    "Y = replicates[i].ytrain\n",
    "group = replicates[i].groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glm = GLM(X, Y, reg_lambda = np.asarray([0.05]), group = group,max_iter = 100, learning_rate = .1, tol = 1e-3,parameter=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226800,)\n"
     ]
    }
   ],
   "source": [
    "        self = glm\n",
    "        group  = self.group\n",
    "        print(group.shape)\n",
    "        lambdas = self.reg_lambda\n",
    "        parameter = self.parameter\n",
    "        X = self.xs\n",
    "        #print(X.shape)\n",
    "        y = self.ys\n",
    "        \n",
    "        np.random.RandomState(0)\n",
    "        group = np.asarray(group, dtype = np.int64)\n",
    "\n",
    "        #print(group.shape[0])\n",
    "        group.dtype = np.int64\n",
    "        #print(group.shape[0])\n",
    "        #print(X.shape[1])\n",
    "        if group.shape[0] != X.shape[1]:\n",
    "            raise ValueError('group should be (n_features,)')\n",
    "\n",
    "        # type check for data matrix\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError('Input data should be of type ndarray (got %s).'\n",
    "                             % type(X))\n",
    "\n",
    "        n_features = np.float(X.shape[1])\n",
    "        n_features = np.int64(n_features)\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, np.newaxis]\n",
    "            self.ys = y\n",
    "        #print(y.shape)\n",
    "        n_classes = 1\n",
    "        n_classes = np.int64(n_classes)\n",
    "\n",
    "        beta_hat = 1 / (n_features) * np.random.normal(0.0, 1.0, [n_features, n_classes])\n",
    "        fit_params = list()\n",
    "        \n",
    "        for l, rl in enumerate(lambdas):\n",
    "            fit_params.append({'beta': beta_hat})\n",
    "            if l == 0:\n",
    "                fit_params[-1]['beta'] = beta_hat\n",
    "            else:\n",
    "                fit_params[-1]['beta'] = fit_params[-2]['beta']\n",
    "            tol = self.tol\n",
    "            alpha = 1.\n",
    "            beta = np.zeros([n_features, n_classes])\n",
    "            beta = fit_params[-1]['beta']\n",
    "            #print('losser',self._L2loss(beta,X,y))\n",
    "            g = np.zeros([n_features, n_classes])\n",
    "            L, DL ,L2,PEN = list(), list() , list(), list()\n",
    "            lamb = self.learning_rate\n",
    "            bm1 = beta.copy()\n",
    "            bm2 = beta.copy()\n",
    "            break\n",
    "        # Return\n",
    "        #return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.group_ids = {}\n",
    "for i in range(experiment.p):\n",
    "    self.group_ids[i] = np.where(glm.group == i)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.09 s ± 20.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#2n-4p-2d 513 us\n",
    "#for t in range(0, self.max_iter):\n",
    "t = 0\n",
    "L.append(self._loss(beta, rl, X, y))\n",
    "L2.append(self._L2loss(beta,X,y))\n",
    "PEN.append(self._L1penalty(beta))\n",
    "w = (t / (t+ 3))\n",
    "yk = beta + w*(bm1 - bm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484 ms ± 9.55 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "self._L1penalty(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.5 ms ± 2.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "_L1penalty(self, beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glm.p = experiment.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def _L1penalty(self, beta):\n",
    "        \"\"\"The L1 penalty\"\"\"\n",
    "        # Compute the L1 penalty\n",
    "        group = self.group\n",
    "        gs = np.asarray(list(range(self.p)))\n",
    "        #group_ids = np.unique(self.group)\n",
    "        L1penalty = 0.0\n",
    "        for j in gs:\n",
    "            L1penalty += np.linalg.norm(beta[self.group_ids[j]], 2)\n",
    "        return L1penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Compute the L1 penalty\n",
    "        group = self.group\n",
    "        gs = np.asarray(list(range(self.p)))\n",
    "        #group_ids = np.unique(self.group)\n",
    "        L1penalty = 0.0\n",
    "        for j in gs:\n",
    "            L1penalty += np.linalg.norm(beta[self.group_ids[j]], 2)\n",
    "        #return L1penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.reshape(beta, ((n*m), p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.6 µs ± 1.31 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.linalg.norm(beta[self.group_ids[j]], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4 µs ± 43.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.linalg.norm(beta[self.group_ids[j]],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "L.append(self._loss(beta, rl, X, y))\n",
    "L2.append(self._L2loss(beta,X,y))\n",
    "PEN.append(self._L1penalty(beta))\n",
    "w = (t / (t+ 3))\n",
    "yk = beta + w*(bm1 - bm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-e44f1ec30536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#2n-4p-2d 411 us\\nbet = yk\\nlam = lamb\\nb=  .5\\nmaxx = 1000\\n#rl = rl\\n\\nX = self.xs\\ny = self.ys\\n#print('beginbt', np.linalg.norm(y))\\n#print('beginbt',self._L2loss(bet,X,y))\\n#print(np.linalg.norm(bet))\\ngrad_beta = self._grad_L2loss(beta = bet, X = X, y = y)\\nfor i in range(maxx):\\n    betn = bet - lam * grad_beta\\n    z = self._prox(betn, lam * rl)\\n    fz = self._L2loss(z,X,y)\\n    #print(fz,'fz')\\n    fhatz = self.fhatlambda(lam,z, bet)\\n    if fz <= fhatz:\\n    #print(fhatz - fz)\\n    #if 0 <= 1:\\n        break\\n    lam = b*lam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2165\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/manifoldflasso_jmlr/codes/flasso/GLMaccelerated.py\u001b[0m in \u001b[0;36m_prox\u001b[0;34m(self, beta, thresh)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mgid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m#print(self.group)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0midxs_to_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;31m#print('idx',idxs_to_update)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m#print('norm', np.linalg.norm(beta[idxs_to_update]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#2n-4p-2d 411 us\n",
    "bet = yk\n",
    "lam = lamb\n",
    "b=  .5\n",
    "maxx = 1000\n",
    "#rl = rl\n",
    "\n",
    "X = self.xs\n",
    "y = self.ys\n",
    "#print('beginbt', np.linalg.norm(y))\n",
    "#print('beginbt',self._L2loss(bet,X,y))\n",
    "#print(np.linalg.norm(bet))\n",
    "grad_beta = self._grad_L2loss(beta = bet, X = X, y = y)\n",
    "for i in range(maxx):\n",
    "    betn = bet - lam * grad_beta\n",
    "    z = self._prox(betn, lam * rl)\n",
    "    fz = self._L2loss(z,X,y)\n",
    "    #print(fz,'fz')\n",
    "    fhatz = self.fhatlambda(lam,z, bet)\n",
    "    if fz <= fhatz:\n",
    "    #print(fhatz - fz)\n",
    "    #if 0 <= 1:\n",
    "        break\n",
    "    lam = b*lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.05 ms ± 94.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#2n-4p-2d 411 us\n",
    "bet = yk\n",
    "lam = lamb\n",
    "b=  .5\n",
    "maxx = 1000\n",
    "#rl = rl\n",
    "\n",
    "X = self.xs\n",
    "y = self.ys\n",
    "#print('beginbt', np.linalg.norm(y))\n",
    "#print('beginbt',self._L2loss(bet,X,y))\n",
    "#print(np.linalg.norm(bet))\n",
    "grad_beta = self._grad_L2loss(beta = bet, X = X, y = y)\n",
    "for i in range(maxx):\n",
    "    betn = bet - lam * grad_beta\n",
    "    z = self._prox(betn, lam * rl)\n",
    "    fz = self._L2loss(z,X,y)\n",
    "    #print(fz,'fz')\n",
    "    fhatz = self.fhatlambda(lam,z, bet)\n",
    "    if fz <= fhatz:\n",
    "    #print(fhatz - fz)\n",
    "    #if 0 <= 1:\n",
    "        break\n",
    "    lam = b*lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "(3600,)\n",
      "converged 0.05\n",
      "31.9 ms ± 2.32 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "glm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'lambdas' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6e422dce28af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# n = xs.shape[0]\\nxs = replicates[0].xtrain\\nys = replicates[0].ytrain\\ngroups = replicates[0].groups\\nq = 3\\np = len(np.unique(groups))\\nlambdas = np.asarray(lambdas, dtype=np.float64)\\nyadd = np.expand_dims(ys, 1)\\ngroups = np.asarray(groups, dtype=np.int32) + 1\\nW0 = np.zeros((xs.shape[1], yadd.shape[1]), dtype=np.float32)\\nXsam = np.asfortranarray(xs, dtype=np.float32)\\nYsam = np.asfortranarray(yadd, dtype=np.float32)\\ncoeffs = np.zeros((len(lambdas), q, n, p))\\n    # print(output[1])'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2165\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'lambdas' referenced before assignment"
     ]
    }
   ],
   "source": [
    "        %%timeit\n",
    "        # n = xs.shape[0]\n",
    "        xs = replicates[0].xtrain\n",
    "        ys = replicates[0].ytrain\n",
    "        groups = replicates[0].groups\n",
    "        q = 3\n",
    "        p = len(np.unique(groups))\n",
    "        lambdas = np.asarray(lambdas, dtype=np.float64)\n",
    "        yadd = np.expand_dims(ys, 1)\n",
    "        groups = np.asarray(groups, dtype=np.int32) + 1\n",
    "        W0 = np.zeros((xs.shape[1], yadd.shape[1]), dtype=np.float32)\n",
    "        Xsam = np.asfortranarray(xs, dtype=np.float32)\n",
    "        Ysam = np.asfortranarray(yadd, dtype=np.float32)\n",
    "        coeffs = np.zeros((len(lambdas), q, n, p))\n",
    "            # print(output[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 ms ± 2.38 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "        %%timeit\n",
    "        for i in range(len(lambdas)):\n",
    "            # alpha = spams.fistaFlat(Xsam,Dsam2,alpha0sam,ind_groupsam,lambda1 = lambdas[i],mode = mode,itermax = itermax,tol = tol,numThreads = numThreads, regul = \"group-lasso-l2\")\n",
    "            # spams.fistaFlat(Y,X,W0,TRUE,numThreads = 1,verbose = TRUE,lambda1 = 0.05, it0 = 10, max_it = 200,L0 = 0.1, tol = 1e-3, intercept = FALSE,pos = FALSE,compute_gram = TRUE, loss = 'square',regul = 'l1')\n",
    "            output = spams.fistaFlat(Ysam, Xsam, W0, True, groups=groups, numThreads=-1, verbose=True,\n",
    "                                     lambda1=lambdas[i], it0=100, max_it=itermax, L0=0.5, tol=tol, intercept=False,\n",
    "                                     pos=False, compute_gram=True, loss='square', regul='group-lasso-l2', ista=False,\n",
    "                                     subgrad=False, a=0.1, b=1000)\n",
    "            #coeffs[i, :, :, :] = np.reshape(output[0], (q, n, p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-501af50e6bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreplicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_M\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdg_M\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdg_w\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mreplicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdg_w_pca\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mreplicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdgw_norm\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mget_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/manifoldflasso_jmlr/codes/otherfunctions/get_grads.py\u001b[0m in \u001b[0;36mget_grads\u001b[0;34m(experiment, Mpca, Mangles, N, selected_points)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdf_M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dF_js_idM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtangent_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mdf_M2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_M\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_M\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mdg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dx_g_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMangles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapeSpace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMangles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/manifoldflasso_jmlr/codes/experimentclasses/AtomicRegression.py\u001b[0m in \u001b[0;36mget_dx_g_full\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dx_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/manifoldflasso_jmlr/codes/experimentclasses/AtomicRegression.py\u001b[0m in \u001b[0;36mget_dx_g\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0ma4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# fitin = g4(a4)[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mfitin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradg4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mfaceindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     should be scalar-valued. The gradient has the same type as the argument.\"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/manifoldflasso_jmlr/codes/experimentclasses/AtomicRegression.py\u001b[0m in \u001b[0;36mg4\u001b[0;34m(self, angles4)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mtilded2star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtilded2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtilded2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtilded2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtilded2star\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtilded2star\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtilded2star\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtilded2star\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtilded1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtilded2star\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtilded1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtilded2star\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtilded1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtilded1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtilded1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtilded1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marccos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mca\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mab\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/numpy/numpy_boxes.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__neg__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mboxed_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_constructor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_top_boxed_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0margvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf_wrapped\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnotrace_primitives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_constructor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/util.py\u001b[0m in \u001b[0;36msubvals\u001b[0;34m(x, ivs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mivs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mivs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "replicates[i].df_M,replicates[i].dg_M,replicates[i].dg_w ,replicates[i].dg_w_pca ,replicates[i].dgw_norm  = get_grads(experiment, experiment.Mpca, experiment.M, experiment.N, selected_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from codes.geometer.RiemannianManifold import RiemannianManifold\n",
    "from codes.geometer.ShapeSpace import ShapeSpace\n",
    "from codes.geometer.TangentBundle import TangentBundle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #def get_grads(experiment, Mpca, Mangles, N, selected_points):\n",
    "    Mpca = experiment.Mpca\n",
    "    Mangles = experiment.M\n",
    "    N =experiment.N#, selected_points\n",
    "    dimnoise = experiment.dimnoise\n",
    "    dim = experiment.dim\n",
    "    cores = experiment.cores\n",
    "\n",
    "    tangent_bases = Mpca.get_wlpca_tangent_sel(Mpca, selected_points, dimnoise)\n",
    "    subM = RiemannianManifold(Mpca.data[selected_points], dim)\n",
    "    subM.tb = TangentBundle(subM, tangent_bases)\n",
    "    N.tangent_bundle = TangentBundle(N, np.swapaxes(N.geom.rmetric.Hvv[:,:dim,:],1,2))\n",
    "\n",
    "    df_M = experiment.get_dF_js_idM(Mpca, N, subM.tb, N.tangent_bundle, selected_points, dimnoise)\n",
    "    df_M2 = df_M / np.sum(np.linalg.norm(df_M, axis=1) ** 2, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1f2670942811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dx_g_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMangles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/manifoldflasso_jmlr/codes/experimentclasses/AtomicRegression.py\u001b[0m in \u001b[0;36mget_dx_g_full\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dx_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/manifoldflasso_jmlr/codes/experimentclasses/AtomicRegression.py\u001b[0m in \u001b[0;36mget_dx_g\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0ma4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# fitin = g4(a4)[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mfitin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradg4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mfaceindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n\u001b[1;32m     28\u001b[0m                         \"Try jacobian, elementwise_grad or holomorphic_grad.\")\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0munary_to_nary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mingrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_outgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36madd_outgrads\u001b[0;34m(prev_g_flagged, g)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msparse_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_g_mutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mboxed_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_constructor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_top_boxed_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0margvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    dg_x = experiment.get_dx_g_full(Mangles.data[selected_points])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def get_dx_g_full(self, data):\n",
    "        d = self.d\n",
    "        p = self.p\n",
    "        n = data.shape[0]\n",
    "\n",
    "        output = np.zeros((n, p, d))\n",
    "        for i in range(n):\n",
    "            print(i)\n",
    "            output[i, :, :] = self.get_dx_g(data[i]).transpose()\n",
    "        return (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "dg_x = get_dx_g_full(experiment, Mangles.data[selected_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "W = ShapeSpace(experiment.positions, Mangles.data)\n",
    "dw = W.get_dw(cores, experiment.atoms3, experiment.natoms, selected_points)\n",
    "dg_w = experiment.project(np.swapaxes(dw, 1, 2),\n",
    "                          experiment.project(dw, dg_x))\n",
    "\n",
    "dg_w_pca = np.asarray([np.matmul(experiment.projector, dg_w[j].transpose()).transpose() for j in range(len(selected_points))])\n",
    "dgw_norm = experiment.normalize(dg_w_pca)\n",
    "dg_M = experiment.project(subM.tb.tangent_bases, dgw_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replicates[i].xtrain, replicates[i].groups = experiment.construct_X_js(dg_M)\n",
    "replicates[i].ytrain = experiment.construct_Y_js(df_M2,dimnoise)\n",
    "replicates[i].coeff_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 226800)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[i].xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 226800)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[i].xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = replicates[i].xtrain\n",
    "Y = replicates[i].ytrain\n",
    "group = replicates[i].groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glm = GLM(X, Y, reg_lambda = np.asarray([0.05]), group = group,max_iter = 100, learning_rate = .1, tol = 1e-3,parameter=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 226800)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226800,)\n"
     ]
    }
   ],
   "source": [
    "        self = glm\n",
    "        group  = self.group\n",
    "        print(group.shape)\n",
    "        lambdas = self.reg_lambda\n",
    "        parameter = self.parameter\n",
    "        X = self.xs\n",
    "        #print(X.shape)\n",
    "        y = self.ys\n",
    "        \n",
    "        np.random.RandomState(0)\n",
    "        group = np.asarray(group, dtype = np.int64)\n",
    "\n",
    "        #print(group.shape[0])\n",
    "        group.dtype = np.int64\n",
    "        #print(group.shape[0])\n",
    "        #print(X.shape[1])\n",
    "        if group.shape[0] != X.shape[1]:\n",
    "            raise ValueError('group should be (n_features,)')\n",
    "\n",
    "        # type check for data matrix\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError('Input data should be of type ndarray (got %s).'\n",
    "                             % type(X))\n",
    "\n",
    "        n_features = np.float(X.shape[1])\n",
    "        n_features = np.int64(n_features)\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, np.newaxis]\n",
    "            self.ys = y\n",
    "        #print(y.shape)\n",
    "        n_classes = 1\n",
    "        n_classes = np.int64(n_classes)\n",
    "\n",
    "        beta_hat = 1 / (n_features) * np.random.normal(0.0, 1.0, [n_features, n_classes])\n",
    "        fit_params = list()\n",
    "        \n",
    "        for l, rl in enumerate(lambdas):\n",
    "            fit_params.append({'beta': beta_hat})\n",
    "            if l == 0:\n",
    "                fit_params[-1]['beta'] = beta_hat\n",
    "            else:\n",
    "                fit_params[-1]['beta'] = fit_params[-2]['beta']\n",
    "            tol = self.tol\n",
    "            alpha = 1.\n",
    "            beta = np.zeros([n_features, n_classes])\n",
    "            beta = fit_params[-1]['beta']\n",
    "            #print('losser',self._L2loss(beta,X,y))\n",
    "            g = np.zeros([n_features, n_classes])\n",
    "            L, DL ,L2,PEN = list(), list() , list(), list()\n",
    "            lamb = self.learning_rate\n",
    "            bm1 = beta.copy()\n",
    "            bm2 = beta.copy()\n",
    "            break\n",
    "        # Return\n",
    "        #return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539 ms ± 23.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#2n-4p-2d 513 us\n",
    "#for t in range(0, self.max_iter):\n",
    "t = 0\n",
    "L.append(self._loss(beta, rl, X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 ms ± 333 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "L2.append(self._L2loss(beta,X,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465 ms ± 18.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "PEN.append(self._L1penalty(beta))\n",
    "w = (t / (t+ 3))\n",
    "yk = beta + w*(bm1 - bm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226800, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 3600)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3.12 ms (2-4-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.08 s ± 20.8 (600 * 226800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self = glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571 ms ± 8.25 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "L.append(self._loss(beta, rl, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490 ms ± 15.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "PEN.append(self._L1penalty(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 s ± 27.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#2n-4p-2d 513 us\n",
    "#for t in range(0, self.max_iter):\n",
    "t = 0\n",
    "L.append(self._loss(beta, rl, X, y))\n",
    "L2.append(self._L2loss(beta,X,y))\n",
    "PEN.append(self._L1penalty(beta))\n",
    "w = (t / (t+ 3))\n",
    "yk = beta + w*(bm1 - bm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 ms ± 2.68 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#2n-4p-2d 411 us\n",
    "bet = yk\n",
    "lam = lamb\n",
    "b=  .5\n",
    "maxx = 1000\n",
    "#rl = rl\n",
    "\n",
    "X = self.xs\n",
    "y = self.ys\n",
    "#print('beginbt', np.linalg.norm(y))\n",
    "#print('beginbt',self._L2loss(bet,X,y))\n",
    "#print(np.linalg.norm(bet))\n",
    "grad_beta = self._grad_L2loss(beta = bet, X = X, y = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 ms ± 5.68 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "maxx = 1\n",
    "for i in range(maxx):\n",
    "    betn = bet - lam * grad_beta\n",
    "    z = self._prox(betn, lam * rl)\n",
    "\n",
    "    #lam = b*lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.5 ms ± 3.99 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "    %%timeit\n",
    "    fz = self._L2loss(z,X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 ms ± 24.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "    %%timeit\n",
    "    #print(fz,'fz')\n",
    "    fhatz = self.fhatlambda(lam,z, bet)\n",
    "    #if fz <= fhatz:\n",
    "    #print(fhatz - fz)\n",
    "    #if 0 <= 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        #%%timeit\n",
    "        # n = xs.shape[0]\n",
    "        xs = replicates[0].xtrain\n",
    "        ys = replicates[0].ytrain\n",
    "        groups = replicates[0].groups\n",
    "        q = 3\n",
    "        p = len(np.unique(groups))\n",
    "        lambdas = np.asarray(lambdas, dtype=np.float64)\n",
    "        yadd = np.expand_dims(ys, 1)\n",
    "        groups = np.asarray(groups, dtype=np.int32) + 1\n",
    "        W0 = np.zeros((xs.shape[1], yadd.shape[1]), dtype=np.float32)\n",
    "        Xsam = np.asfortranarray(xs, dtype=np.float32)\n",
    "        Ysam = np.asfortranarray(yadd, dtype=np.float32)\n",
    "        coeffs = np.zeros((len(lambdas), q, n, p))\n",
    "            # print(output[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226800,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            %%timeit\n",
    "            #for i in range(len(lambdas)):\n",
    "            # alpha = spams.fistaFlat(Xsam,Dsam2,alpha0sam,ind_groupsam,lambda1 = lambdas[i],mode = mode,itermax = itermax,tol = tol,numThreads = numThreads, regul = \"group-lasso-l2\")\n",
    "            # spams.fistaFlat(Y,X,W0,TRUE,numThreads = 1,verbose = TRUE,lambda1 = 0.05, it0 = 10, max_it = 200,L0 = 0.1, tol = 1e-3, intercept = FALSE,pos = FALSE,compute_gram = TRUE, loss = 'square',regul = 'l1')\n",
    "            output = spams.fistaFlat(Ysam, Xsam, W0, True, groups=groups, numThreads=-1, verbose=True,\n",
    "                                     lambda1=lambdas[i], it0=100, max_it=1, L0=0.5, tol=tol, intercept=False,\n",
    "                                     pos=False, compute_gram=True, loss='square', regul='group-lasso-l2', ista=False,\n",
    "                                     subgrad=False, a=0.1, b=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The true champion\n",
    "\n",
    "import autograd.numpy as np\n",
    "from autograd import jacobian\n",
    "from autograd import elementwise_grad\n",
    "from autograd import grad\n",
    "\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "\n",
    "#import numpy as np\n",
    "from scipy.special import expit\n",
    "from pyglmnet import utils\n",
    "\n",
    "\n",
    "class GLM:\n",
    "    \n",
    "    def __init__(self, xs, ys, reg_lambda, group,max_iter, learning_rate, tol,parameter):\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.group = np.asarray(group)\n",
    "        #print(self.group.shape)\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tol = tol\n",
    "        self.Tau = None\n",
    "        self.alpha = 1.\n",
    "        self.lossresults = {}\n",
    "        self.dls = {}\n",
    "        self.parameter = parameter\n",
    "        self.l2loss = {}\n",
    "        self.penalty = {}\n",
    "        \n",
    "    def _prox(self,beta, thresh):\n",
    "        \"\"\"Proximal operator.\"\"\"\n",
    "        \n",
    "        #print(thresh, beta)\n",
    "        #print('beginprox', beta[0:2],thresh)\n",
    "        group_ids = np.unique(self.group)\n",
    "        result = np.zeros(beta.shape)\n",
    "        result = np.asarray(result, dtype = float)\n",
    "        #print('gids',group_ids)\n",
    "        for i in range(len(group_ids)):\n",
    "            gid = i \n",
    "            #print(self.group)\n",
    "            idxs_to_update = np.where(self.group == gid)[0]\n",
    "            #print('idx',idxs_to_update)\n",
    "            #print('norm', np.linalg.norm(beta[idxs_to_update]))\n",
    "            if np.linalg.norm(beta[idxs_to_update]) > 0.:\n",
    "                #print('in here', len(idxs_to_update))\n",
    "                potentialoutput = beta[idxs_to_update] - (thresh / np.linalg.norm(beta[idxs_to_update])) * beta[idxs_to_update]\n",
    "                posind = np.where(beta[idxs_to_update] > 0.)[0]\n",
    "                negind = np.where(beta[idxs_to_update] < 0.)[0]\n",
    "                po = beta[idxs_to_update].copy()\n",
    "                #print('potention', potentialoutput[0:2])\n",
    "                po[posind] = np.asarray(np.clip(potentialoutput[posind],a_min = 0., a_max = 1e15), dtype = float)\n",
    "                po[negind] = np.asarray(np.clip(potentialoutput[negind],a_min = -1e15, a_max = 0.), dtype = float)\n",
    "                result[idxs_to_update] = po\n",
    "        #print('end', result[0:2])\n",
    "        return result\n",
    "\n",
    "    def _grad_L2loss(self, beta, X, y):\n",
    "        #print(beta.shape,X.shape,y.shape)\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, np.newaxis]\n",
    "        n_samples = np.float(X.shape[0])\n",
    "        z = np.dot(X, beta)\n",
    "        #grad_beta = 1. / n_samples * np.transpose(np.dot(np.transpose(z - y), X))\n",
    "        grad_beta = np.transpose(np.dot(np.transpose(z - y), X))\n",
    "        #print('gb',grad_beta.shape)\n",
    "        return grad_beta\n",
    "    \n",
    "    def _loss(self,beta, reg_lambda, X, y):\n",
    "        \"\"\"Define the objective function for elastic net.\"\"\"\n",
    "        L = self._logL(beta, X, y)\n",
    "        P = self._L1penalty(beta)\n",
    "        J = -L + reg_lambda * P\n",
    "        return J\n",
    "    \n",
    "    def _logL(self,beta, X, y):\n",
    "        \"\"\"The log likelihood.\"\"\"\n",
    "        #print('beginlogL', np.linalg.norm(beta), np.linalg.norm(X), np.linalg.norm(y),y.shape,beta.shape,X.shape,)\n",
    "        l = np.dot(X, beta)\n",
    "        logL = -0.5 * np.sum((y - l)**2)\n",
    "        #print('endlogL',logL)\n",
    "        return logL\n",
    "    \n",
    "    def _L2loss(self,beta,X,y):\n",
    "        #print('beginl2', np.linalg.norm(beta), np.linalg.norm(X), np.linalg.norm(y), y.shape)\n",
    "        output = -self._logL(beta, X, y)\n",
    "        #print('outl2',output)\n",
    "        return(output)\n",
    "    \n",
    "    def _L1penalty(self, beta):\n",
    "        \"\"\"The L1 penalty\"\"\"\n",
    "        # Compute the L1 penalty\n",
    "        group = self.group\n",
    "        group_ids = np.unique(self.group)\n",
    "        L1penalty = 0.0\n",
    "        for group_id in group_ids:\n",
    "            L1penalty += np.linalg.norm(beta[self.group == group_id], 2)\n",
    "        return L1penalty\n",
    "    \n",
    "    #def fhatlambda(self,lamb,x,y):\n",
    "    def fhatlambda(self,lamb,betanew,betaold):\n",
    "        xs = self.xs\n",
    "        ys = self.ys\n",
    "        #print(ys.shape,'fhatlam')\n",
    "        #print(self._L2loss(betaold,xs,ys),self._L2loss(betanew,xs,ys),'old','new') \n",
    "        output = self._L2loss(betaold,xs,ys) + np.dot(self._grad_L2loss(betaold,xs,ys).transpose(),(betanew-betaold)) + (1/(2*lamb)) * np.linalg.norm(betanew-betaold)**2\n",
    "        return(output)\n",
    "    \n",
    "    #_btalgorithm(yk,lamb,.5,1000, rl)\n",
    "    def _btalgorithm(self,bet,lam,b,maxx,rl):\n",
    "        \n",
    "        #print('lam',lam)\n",
    "        X = self.xs\n",
    "        y = self.ys\n",
    "        #print('beginbt', np.linalg.norm(y))\n",
    "        #print('beginbt',self._L2loss(bet,X,y))\n",
    "        #print(np.linalg.norm(bet))\n",
    "        grad_beta = self._grad_L2loss(beta = bet, X = X, y = y)\n",
    "        for i in range(maxx):\n",
    "            betn = bet - lam * grad_beta\n",
    "            z = self._prox(betn, lam * rl)\n",
    "            fz = self._L2loss(z,X,y)\n",
    "            #print(fz,'fz')\n",
    "            fhatz = self.fhatlambda(lam,z, bet)\n",
    "            if fz <= fhatz:\n",
    "            #print(fhatz - fz)\n",
    "            #if 0 <= 1:\n",
    "                break\n",
    "            lam = b*lam\n",
    "        return(z,lam)\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "\n",
    "        group  = self.group\n",
    "        print(group.shape)\n",
    "        lambdas = self.reg_lambda\n",
    "        parameter = self.parameter\n",
    "        X = self.xs\n",
    "        #print(X.shape)\n",
    "        y = self.ys\n",
    "        \n",
    "        np.random.RandomState(0)\n",
    "        group = np.asarray(group, dtype = np.int64)\n",
    "\n",
    "        #print(group.shape[0])\n",
    "        group.dtype = np.int64\n",
    "        #print(group.shape[0])\n",
    "        #print(X.shape[1])\n",
    "        if group.shape[0] != X.shape[1]:\n",
    "            raise ValueError('group should be (n_features,)')\n",
    "\n",
    "        # type check for data matrix\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError('Input data should be of type ndarray (got %s).'\n",
    "                             % type(X))\n",
    "\n",
    "        n_features = np.float(X.shape[1])\n",
    "        n_features = np.int64(n_features)\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, np.newaxis]\n",
    "            self.ys = y\n",
    "        #print(y.shape)\n",
    "        n_classes = 1\n",
    "        n_classes = np.int64(n_classes)\n",
    "\n",
    "        beta_hat = 1 / (n_features) * np.random.normal(0.0, 1.0, [n_features, n_classes])\n",
    "        fit_params = list()\n",
    "        \n",
    "        for l, rl in enumerate(lambdas):\n",
    "            fit_params.append({'beta': beta_hat})\n",
    "            if l == 0:\n",
    "                fit_params[-1]['beta'] = beta_hat\n",
    "            else:\n",
    "                fit_params[-1]['beta'] = fit_params[-2]['beta']\n",
    "            tol = self.tol\n",
    "            alpha = 1.\n",
    "            beta = np.zeros([n_features, n_classes])\n",
    "            beta = fit_params[-1]['beta']\n",
    "            #print('losser',self._L2loss(beta,X,y))\n",
    "            g = np.zeros([n_features, n_classes])\n",
    "            L, DL ,L2,PEN = list(), list() , list(), list()\n",
    "            lamb = self.learning_rate\n",
    "            bm1 = beta.copy()\n",
    "            bm2 = beta.copy()\n",
    "            for t in range(0, self.max_iter):\n",
    "                L.append(self._loss(beta, rl, X, y))\n",
    "                L2.append(self._L2loss(beta,X,y))\n",
    "                PEN.append(self._L1penalty(beta))\n",
    "                w = (t / (t+ 3))\n",
    "                yk = beta + w*(bm1 - bm2)\n",
    "                #print('losser',self._L2loss(yk,X,y))\n",
    "                #print('beforebt',np.linalg.norm(yk),np.linalg.norm(X),np.linalg.norm(y))\n",
    "                beta , lamb = self._btalgorithm(yk,lamb,.5,1000, rl)\n",
    "                #X = self.xs\n",
    "                #y = self.ys\n",
    "                #print('losser2',self._L2loss(beta,X,y))\n",
    "                bm2 = bm1.copy()\n",
    "                bm1 = beta.copy()\n",
    "                if t > 1:\n",
    "                    DL.append(L[-1] - L[-2])\n",
    "                    if np.abs(DL[-1] / L[-1]) < tol:\n",
    "                        print('converged', rl)\n",
    "                        msg = ('\\tConverged. Loss function:'\n",
    "                               ' {0:.2f}').format(L[-1])\n",
    "                        msg = ('\\tdL/L: {0:.6f}\\n'.format(DL[-1] / L[-1]))\n",
    "                        break\n",
    "                    \n",
    "            #print(beta)\n",
    "            fit_params[-1]['beta'] = beta\n",
    "            self.lossresults[rl] = L\n",
    "            self.l2loss[rl] = L2\n",
    "            self.penalty[rl] = PEN\n",
    "            self.dls[rl] = DL\n",
    "            #print(L)\n",
    "        # Update the estimated variables\n",
    "        \n",
    "        self.fit_ = fit_params\n",
    "        self.ynull_ = np.mean(y)\n",
    "\n",
    "        # Return\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting group-lasso\n",
      "  Downloading group_lasso-1.4.1-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: numpy in /Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages (from group-lasso) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages (from group-lasso) (0.20.0)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages (from scikit-learn->group-lasso) (1.1.0)\n",
      "Installing collected packages: group-lasso\n",
      "Successfully installed group-lasso-1.4.1\n"
     ]
    }
   ],
   "source": [
    "pip install einops\n",
    "import sys\n",
    "!{sys.executable} -m pip install group-lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from group_lasso import GroupLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[0].groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@array_function_dispatch(_norm_dispatcher)\n",
    "def norm(x, ord=None, axis=None, keepdims=False):\n",
    "    \"\"\"\n",
    "    Matrix or vector norm.\n",
    "    This function is able to return one of eight different matrix norms,\n",
    "    or one of an infinite number of vector norms (described below), depending\n",
    "    on the value of the ``ord`` parameter.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        Input array.  If `axis` is None, `x` must be 1-D or 2-D, unless `ord`\n",
    "        is None. If both `axis` and `ord` are None, the 2-norm of\n",
    "        ``x.ravel`` will be returned.\n",
    "    ord : {non-zero int, inf, -inf, 'fro', 'nuc'}, optional\n",
    "        Order of the norm (see table under ``Notes``). inf means numpy's\n",
    "        `inf` object. The default is None.\n",
    "    axis : {None, int, 2-tuple of ints}, optional.\n",
    "        If `axis` is an integer, it specifies the axis of `x` along which to\n",
    "        compute the vector norms.  If `axis` is a 2-tuple, it specifies the\n",
    "        axes that hold 2-D matrices, and the matrix norms of these matrices\n",
    "        are computed.  If `axis` is None then either a vector norm (when `x`\n",
    "        is 1-D) or a matrix norm (when `x` is 2-D) is returned. The default\n",
    "        is None.\n",
    "        .. versionadded:: 1.8.0\n",
    "    keepdims : bool, optional\n",
    "        If this is set to True, the axes which are normed over are left in the\n",
    "        result as dimensions with size one.  With this option the result will\n",
    "        broadcast correctly against the original `x`.\n",
    "        .. versionadded:: 1.10.0\n",
    "    Returns\n",
    "    -------\n",
    "    n : float or ndarray\n",
    "        Norm of the matrix or vector(s).\n",
    "    See Also\n",
    "    --------\n",
    "    scipy.linalg.norm : Similar function in SciPy.\n",
    "    Notes\n",
    "    -----\n",
    "    For values of ``ord < 1``, the result is, strictly speaking, not a\n",
    "    mathematical 'norm', but it may still be useful for various numerical\n",
    "    purposes.\n",
    "    The following norms can be calculated:\n",
    "    =====  ============================  ==========================\n",
    "    ord    norm for matrices             norm for vectors\n",
    "    =====  ============================  ==========================\n",
    "    None   Frobenius norm                2-norm\n",
    "    'fro'  Frobenius norm                --\n",
    "    'nuc'  nuclear norm                  --\n",
    "    inf    max(sum(abs(x), axis=1))      max(abs(x))\n",
    "    -inf   min(sum(abs(x), axis=1))      min(abs(x))\n",
    "    0      --                            sum(x != 0)\n",
    "    1      max(sum(abs(x), axis=0))      as below\n",
    "    -1     min(sum(abs(x), axis=0))      as below\n",
    "    2      2-norm (largest sing. value)  as below\n",
    "    -2     smallest singular value       as below\n",
    "    other  --                            sum(abs(x)**ord)**(1./ord)\n",
    "    =====  ============================  ==========================\n",
    "    The Frobenius norm is given by [1]_:\n",
    "        :math:`||A||_F = [\\\\sum_{i,j} abs(a_{i,j})^2]^{1/2}`\n",
    "    The nuclear norm is the sum of the singular values.\n",
    "    Both the Frobenius and nuclear norm orders are only defined for\n",
    "    matrices and raise a ValueError when ``x.ndim != 2``.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] G. H. Golub and C. F. Van Loan, *Matrix Computations*,\n",
    "           Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from numpy import linalg as LA\n",
    "    >>> a = np.arange(9) - 4\n",
    "    >>> a\n",
    "    array([-4, -3, -2, ...,  2,  3,  4])\n",
    "    >>> b = a.reshape((3, 3))\n",
    "    >>> b\n",
    "    array([[-4, -3, -2],\n",
    "           [-1,  0,  1],\n",
    "           [ 2,  3,  4]])\n",
    "    >>> LA.norm(a)\n",
    "    7.745966692414834\n",
    "    >>> LA.norm(b)\n",
    "    7.745966692414834\n",
    "    >>> LA.norm(b, 'fro')\n",
    "    7.745966692414834\n",
    "    >>> LA.norm(a, np.inf)\n",
    "    4.0\n",
    "    >>> LA.norm(b, np.inf)\n",
    "    9.0\n",
    "    >>> LA.norm(a, -np.inf)\n",
    "    0.0\n",
    "    >>> LA.norm(b, -np.inf)\n",
    "    2.0\n",
    "    >>> LA.norm(a, 1)\n",
    "    20.0\n",
    "    >>> LA.norm(b, 1)\n",
    "    7.0\n",
    "    >>> LA.norm(a, -1)\n",
    "    -4.6566128774142013e-010\n",
    "    >>> LA.norm(b, -1)\n",
    "    6.0\n",
    "    >>> LA.norm(a, 2)\n",
    "    7.745966692414834\n",
    "    >>> LA.norm(b, 2)\n",
    "    7.3484692283495345\n",
    "    >>> LA.norm(a, -2)\n",
    "    0.0\n",
    "    >>> LA.norm(b, -2)\n",
    "    1.8570331885190563e-016 # may vary\n",
    "    >>> LA.norm(a, 3)\n",
    "    5.8480354764257312 # may vary\n",
    "    >>> LA.norm(a, -3)\n",
    "    0.0\n",
    "    Using the `axis` argument to compute vector norms:\n",
    "    >>> c = np.array([[ 1, 2, 3],\n",
    "    ...               [-1, 1, 4]])\n",
    "    >>> LA.norm(c, axis=0)\n",
    "    array([ 1.41421356,  2.23606798,  5.        ])\n",
    "    >>> LA.norm(c, axis=1)\n",
    "    array([ 3.74165739,  4.24264069])\n",
    "    >>> LA.norm(c, ord=1, axis=1)\n",
    "    array([ 6.,  6.])\n",
    "    Using the `axis` argument to compute matrix norms:\n",
    "    >>> m = np.arange(8).reshape(2,2,2)\n",
    "    >>> LA.norm(m, axis=(1,2))\n",
    "    array([  3.74165739,  11.22497216])\n",
    "    >>> LA.norm(m[0, :, :]), LA.norm(m[1, :, :])\n",
    "    (3.7416573867739413, 11.224972160321824)\n",
    "    \"\"\"\n",
    "    x = asarray(x)\n",
    "\n",
    "    if not issubclass(x.dtype.type, (inexact, object_)):\n",
    "        x = x.astype(float)\n",
    "\n",
    "    # Immediately handle some default, simple, fast, and common cases.\n",
    "    if axis is None:\n",
    "        ndim = x.ndim\n",
    "        if ((ord is None) or\n",
    "            (ord in ('f', 'fro') and ndim == 2) or\n",
    "            (ord == 2 and ndim == 1)):\n",
    "\n",
    "            x = x.ravel(order='K')\n",
    "            if isComplexType(x.dtype.type):\n",
    "                sqnorm = dot(x.real, x.real) + dot(x.imag, x.imag)\n",
    "            else:\n",
    "                sqnorm = dot(x, x)\n",
    "            ret = sqrt(sqnorm)\n",
    "            if keepdims:\n",
    "                ret = ret.reshape(ndim*[1])\n",
    "            return ret\n",
    "\n",
    "    # Normalize the `axis` argument to a tuple.\n",
    "    nd = x.ndim\n",
    "    if axis is None:\n",
    "        axis = tuple(range(nd))\n",
    "    elif not isinstance(axis, tuple):\n",
    "        try:\n",
    "            axis = int(axis)\n",
    "        except Exception as e:\n",
    "            raise TypeError(\"'axis' must be None, an integer or a tuple of integers\") from e\n",
    "        axis = (axis,)\n",
    "\n",
    "    if len(axis) == 1:\n",
    "        if ord == Inf:\n",
    "            return abs(x).max(axis=axis, keepdims=keepdims)\n",
    "        elif ord == -Inf:\n",
    "            return abs(x).min(axis=axis, keepdims=keepdims)\n",
    "        elif ord == 0:\n",
    "            # Zero norm\n",
    "            return (x != 0).astype(x.real.dtype).sum(axis=axis, keepdims=keepdims)\n",
    "        elif ord == 1:\n",
    "            # special case for speedup\n",
    "            return add.reduce(abs(x), axis=axis, keepdims=keepdims)\n",
    "        elif ord is None or ord == 2:\n",
    "            # special case for speedup\n",
    "            s = (x.conj() * x).real\n",
    "            return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n",
    "        # None of the str-type keywords for ord ('fro', 'nuc')\n",
    "        # are valid for vectors\n",
    "\n",
    "        else:\n",
    "            absx = abs(x)\n",
    "            absx **= ord\n",
    "            ret = add.reduce(absx, axis=axis, keepdims=keepdims)\n",
    "            ret **= (1 / ord)\n",
    "            return ret\n",
    "    elif len(axis) == 2:\n",
    "        row_axis, col_axis = axis\n",
    "        row_axis = normalize_axis_index(row_axis, nd)\n",
    "        col_axis = normalize_axis_index(col_axis, nd)\n",
    "        if row_axis == col_axis:\n",
    "            raise ValueError('Duplicate axes given.')\n",
    "        if ord == 2:\n",
    "            ret =  _multi_svd_norm(x, row_axis, col_axis, amax)\n",
    "        elif ord == -2:\n",
    "            ret = _multi_svd_norm(x, row_axis, col_axis, amin)\n",
    "        elif ord == 1:\n",
    "            if col_axis > row_axis:\n",
    "                col_axis -= 1\n",
    "            ret = add.reduce(abs(x), axis=row_axis).max(axis=col_axis)\n",
    "        elif ord == Inf:\n",
    "            if row_axis > col_axis:\n",
    "                row_axis -= 1\n",
    "            ret = add.reduce(abs(x), axis=col_axis).max(axis=row_axis)\n",
    "        elif ord == -1:\n",
    "            if col_axis > row_axis:\n",
    "                col_axis -= 1\n",
    "            ret = add.reduce(abs(x), axis=row_axis).min(axis=col_axis)\n",
    "        elif ord == -Inf:\n",
    "            if row_axis > col_axis:\n",
    "                row_axis -= 1\n",
    "            ret = add.reduce(abs(x), axis=col_axis).min(axis=row_axis)\n",
    "        elif ord in [None, 'fro', 'f']:\n",
    "            ret = sqrt(add.reduce((x.conj() * x).real, axis=axis))\n",
    "        elif ord == 'nuc':\n",
    "            ret = _multi_svd_norm(x, row_axis, col_axis, sum)\n",
    "\n",
    "        if keepdims:\n",
    "            ret_shape = list(x.shape)\n",
    "            ret_shape[axis[0]] = 1\n",
    "            ret_shape[axis[1]] = 1\n",
    "            ret = ret.reshape(ret_shape)\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 756, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[0].dg_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 756, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates[0].dg_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = replicates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Replicate' object has no attribute 'dg_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-b372950c2218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdg_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Replicate' object has no attribute 'dg_x'"
     ]
    }
   ],
   "source": [
    "r.dg_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    def get_g_sub(self, x, atom4):\n",
    "        atoms3 = self.atoms3\n",
    "        combos = np.asarray([[0, 1, 2], [1, 2, 3], [0, 2, 3], [0, 1, 3]])\n",
    "        angles4 = []\n",
    "        # get identities of triangles on boundary of tetrahedron\n",
    "        actived = np.zeros(4)\n",
    "        for i in range(4):\n",
    "            actived[i] = np.where([set(item).issubset(atom4[combos[i, :]]) for item in atoms3])[0][0]\n",
    "        actived = np.asarray(actived, dtype=int)\n",
    "        naive = np.reshape(x, (int(x.shape[0] / 3), 3))[actived, :]\n",
    "        for i in range(4):\n",
    "            a = atoms3[actived[i]]\n",
    "            b = atom4[np.in1d(atom4, atoms3[actived[i]])]\n",
    "            for j in range(3):\n",
    "                angles4.append(naive[i, np.where(a == b[j])[0]])\n",
    "        # the jth position in the ith row contains the gradient corresponding to the jth position in the truncated atom4\n",
    "        a4 = np.reshape(angles4, (4, 3))\n",
    "        fitin = self.g4(a4)\n",
    "        # plus the lowest index first\n",
    "        return(fitin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.get_g_sub(experiment.M.data[42], experiment.atoms4[684])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_points_save[0][46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.dg_w_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "         46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "         46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "         46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "         46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "         46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "         46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "         46,  46,  46,  46,  46,  46,  46,  46,  46],\n",
       "       [684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684,\n",
       "        684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684,\n",
       "        684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684,\n",
       "        684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 684, 685, 685,\n",
       "        685, 685, 685, 685, 685, 685, 685, 685, 685, 685, 685, 685, 685,\n",
       "        685, 685, 685, 685, 685, 685, 685, 685, 685, 685, 685, 685, 685,\n",
       "        685, 685, 685, 685, 685, 685, 685, 685, 685, 685, 685, 685, 685,\n",
       "        685, 685, 685, 685, 685, 685, 685, 685, 685],\n",
       "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,   0,   1,\n",
       "          2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
       "         41,  42,  43,  44,  45,  46,  47,  48,  49]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(np.where(np.isnan(replicates[0].dg_w_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  99,  99,  99],\n",
       "       [684, 684, 685, ..., 684, 685, 685],\n",
       "       [  0,   1,   0, ...,   1,   0,   1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(np.where(np.isnan(replicates[0].dg_M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1200)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(np.where(np.isnan(replicates[0].xtrain))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620 ms ± 32.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x.conj() * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(add.reduce((x.conj() * x).real, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.core import (\n",
    "    array, asarray, zeros, empty, empty_like, intc, single, double,\n",
    "    csingle, cdouble, inexact, complexfloating, newaxis, all, Inf, dot,\n",
    "    add, multiply, sqrt, fastCopyAndTranspose, sum, isfinite,\n",
    "    finfo, errstate, geterrobj, moveaxis, amin, amax, product, abs,\n",
    "    atleast_2d, intp, asanyarray, object_, matmul,\n",
    "    swapaxes, divide, count_nonzero, isnan, sign, argsort, sort\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.78 s ± 1.14 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "gl = GroupLasso(\n",
    "    groups=np.asarray(replicates[0].groups),\n",
    "    group_reg=5,\n",
    "    l1_reg=0,\n",
    "    frobenius_lipschitz=True,\n",
    "    scale_reg=\"inverse_group_size\",\n",
    "    subsampling_scheme=1,\n",
    "    supress_warning=True,\n",
    "    n_iter=1,\n",
    "    tol=1e-3,\n",
    ")\n",
    "gl.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n",
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 s ± 1.04 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/manifold_env_april/lib/python3.5/site-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "gl = GroupLasso(\n",
    "    groups=np.asarray(replicates[0].groups),\n",
    "    group_reg=5,\n",
    "    l1_reg=0,\n",
    "    frobenius_lipschitz=True,\n",
    "    scale_reg=\"inverse_group_size\",\n",
    "    subsampling_scheme=1,\n",
    "    supress_warning=True,\n",
    "    n_iter=2,\n",
    "    tol=1e-3,\n",
    ")\n",
    "gl.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manifold_env_april2",
   "language": "python",
   "name": "manifold_env_april2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
